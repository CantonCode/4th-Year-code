{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Linear Regression 16164571",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyNO5yVuUnHKrOeAT8ySdtDf",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/CantonCode/4th-Year-code/blob/main/Linear_Regression.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CpgDkOguAhRe"
      },
      "source": [
        "# For this assignment I have used a data set found on google which is based off Youtube. It has two datasets, X which contains likes disliked and subscribers of a video and its creator and Y which contains the views on the video.\n",
        "\n",
        "# The purpose of this linear regression is to predict the number of views based on the number of likes dislikes and subribers a video has."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lsDO2GME2L4D"
      },
      "source": [
        "#Importing relevant packages to use for my project\n",
        "import tensorflow as tf\n",
        "\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dense\n",
        "from keras.optimizers import Adam\n",
        "from keras.callbacks import EarlyStopping\n",
        "\n",
        "import pandas as pd\n",
        "\n",
        "import sklearn\n",
        "from sklearn import preprocessing\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import r2_score\n",
        "\n",
        "from matplotlib import pyplot as plt\n",
        "\n",
        "import seaborn as sns"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ODY7MMUuCvEB"
      },
      "source": [
        "# In order to use the data it must be imported ffrom the files it is contained in. We use pandas built in CSV reader to do this and organise the data into two data frames"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2enIrBVb2eHa"
      },
      "source": [
        "#Using pandas the read in the data and convert them to data frames\n",
        "dataX = pd.read_csv('../StatsX.csv')\n",
        "\n",
        "dataY = pd.read_csv('../StatsY.csv')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-MINn4-4C6r-"
      },
      "source": [
        "# In order to check that the data has been imported properly and holds the desired format it is important to print out some of the data. Here you can see that we print out both data sets and we can confirm its contents and format is correct."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9BRZtfNm3fgp",
        "outputId": "2cee21cc-1165-49d7-da6e-cd3ca10210e8",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "#Printing out the dataY frame to check its contents\n",
        "print(dataY)\n",
        "print(dataX)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "        Views\n",
            "0     1988888\n",
            "1     2617005\n",
            "2      932230\n",
            "3     1165800\n",
            "4      551165\n",
            "...       ...\n",
            "3359   193093\n",
            "3360    21784\n",
            "3361     5427\n",
            "3362   150226\n",
            "3363    29077\n",
            "\n",
            "[3364 rows x 1 columns]\n",
            "       Likes  Dislikes  Subscribers\n",
            "0     104460      3365      7300000\n",
            "1     103203      3570      3300000\n",
            "2      22485       612      1800000\n",
            "3      23077      1337       465000\n",
            "4      12315       522     11000000\n",
            "...      ...       ...          ...\n",
            "3359    4833        47       465000\n",
            "3360     118        16        19000\n",
            "3361      29         2         6100\n",
            "3362     321        34         3400\n",
            "3363     143         7       116000\n",
            "\n",
            "[3364 rows x 3 columns]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "40vaxyz9Ekl6"
      },
      "source": [
        "# Once the data is imported it is important to pre process the data to get it setup for input into our model. To do this I used a module from SKLearn train_test_split() to organise the data into testing and training data to feed into the model.\n",
        "\n",
        "\n",
        "# We use the training data to minimise the cost while the testing data is a seperate chunk of data used for testing the models overall preformance. \n",
        "\n",
        "# We define the test size to 0.2 which means 80% of the data will be randomly selected for training while the other 20% will be selected for testing \n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_Yp8ANBv3iEa"
      },
      "source": [
        "\n",
        "x_train, x_test, y_train, y_test = train_test_split(dataX, dataY, test_size = 0.2)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KiDfGko4GJFl"
      },
      "source": [
        "It is then important to make sure we scale and normalize our data. This is especially important where inputs and outputs for different features vary greatly.\n",
        "\n",
        "As you can see above when printing out our data the number of subsribers vs dislikes varies a lot and in a neural network this would cause for an under represtentaion of these perameters.\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VV-d4XFLIQ6H"
      },
      "source": [
        "# From here we can work on our model that we will be using. In this model I use different learning rates to show how they can effect the learning algorithim\n",
        "\n",
        "# I create a model that as 3 inputs, this correlates with the data we are feeding in : likes, dislikes and subsribers. The model will then have one output layers : Views\n",
        "\n",
        "# I use the adam optimiser along with the mean squared error to adjust the models weights.\n",
        "\n",
        "# The model is then ran and accuracy is graphed. We can see the R score on each iteration improve as the models learning rate is increased \n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_mgYpC2D5zB1",
        "outputId": "d47c84cf-3971-4a61-9c91-e51a41450ba5",
        "colab": {
          "background_save": true,
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "LR = [100,1000,10000,15000]\n",
        "\n",
        "for i in LR:\n",
        "    #Defines linear regression model and its structure\n",
        "    model = Sequential()\n",
        "    model.add(Dense(1, input_shape=(3,)))\n",
        "    \n",
        "    #Compiles model\n",
        "    model.compile(Adam(lr=i), 'mean_squared_error')\n",
        "    \n",
        "    #Fits model\n",
        "    history = model.fit(x_train, y_train, epochs = 500, validation_split = 0.1)\n",
        "    history_dict=history.history\n",
        "    \n",
        "    #Plots model's training cost/loss and model's validation split cost/loss\n",
        "    loss_values = history_dict['loss']\n",
        "    val_loss_values=history_dict['val_loss']\n",
        "    plt.figure()\n",
        "    plt.plot(loss_values)\n",
        "    plt.plot(val_loss_values)\n",
        "\n",
        "    y_train_pred = model.predict(x_train)\n",
        "    y_test_pred = model.predict(x_test)\n",
        "\n",
        "    # Calculates and prints r2 score of training and testing data\n",
        "    print(\"Training Set R2 is:\\t{:0.3f}\".format(r2_score(y_train, y_train_pred)))\n",
        "    print(\"TEsting Set R2 is:\\t{:0.3f}\".format(r2_score(y_test, y_test_pred)))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/500\n",
            "76/76 [==============================] - 0s 2ms/step - loss: 50428117260435456.0000 - val_loss: 71955030218899456.0000\n",
            "Epoch 2/500\n",
            "76/76 [==============================] - 0s 1ms/step - loss: 67181006565670912.0000 - val_loss: 16666926608547840.0000\n",
            "Epoch 3/500\n",
            "76/76 [==============================] - 0s 989us/step - loss: 8123784074625024.0000 - val_loss: 11866638156562432.0000\n",
            "Epoch 4/500\n",
            "76/76 [==============================] - 0s 991us/step - loss: 7715168939147264.0000 - val_loss: 27976633134612480.0000\n",
            "Epoch 5/500\n",
            "76/76 [==============================] - 0s 1ms/step - loss: 311891316625637376.0000 - val_loss: 460825217489436672.0000\n",
            "Epoch 6/500\n",
            "76/76 [==============================] - 0s 1ms/step - loss: 381908045283721216.0000 - val_loss: 691661602067316736.0000\n",
            "Epoch 7/500\n",
            "76/76 [==============================] - 0s 996us/step - loss: 269509094744784896.0000 - val_loss: 93929491654508544.0000\n",
            "Epoch 8/500\n",
            "76/76 [==============================] - 0s 1ms/step - loss: 100620303377367040.0000 - val_loss: 36248583380402176.0000\n",
            "Epoch 9/500\n",
            "76/76 [==============================] - 0s 1ms/step - loss: 11593668288839680.0000 - val_loss: 6590228420624384.0000\n",
            "Epoch 10/500\n",
            "76/76 [==============================] - 0s 1ms/step - loss: 4123790837547008.0000 - val_loss: 14840317819748352.0000\n",
            "Epoch 11/500\n",
            "76/76 [==============================] - 0s 1ms/step - loss: 4137624390336512.0000 - val_loss: 9867400673492992.0000\n",
            "Epoch 12/500\n",
            "76/76 [==============================] - 0s 1ms/step - loss: 4305486476214272.0000 - val_loss: 10406163518586880.0000\n",
            "Epoch 13/500\n",
            "76/76 [==============================] - 0s 998us/step - loss: 6116696465080320.0000 - val_loss: 15011213494714368.0000\n",
            "Epoch 14/500\n",
            "76/76 [==============================] - 0s 1ms/step - loss: 4039343995879424.0000 - val_loss: 12519571969802240.0000\n",
            "Epoch 15/500\n",
            "76/76 [==============================] - 0s 1ms/step - loss: 25216910488502272.0000 - val_loss: 19549082666139648.0000\n",
            "Epoch 16/500\n",
            "76/76 [==============================] - 0s 1ms/step - loss: 3459254975463424.0000 - val_loss: 5311979044470784.0000\n",
            "Epoch 17/500\n",
            "76/76 [==============================] - 0s 1ms/step - loss: 4369561751126016.0000 - val_loss: 11415775038406656.0000\n",
            "Epoch 18/500\n",
            "76/76 [==============================] - 0s 1ms/step - loss: 9803684833656832.0000 - val_loss: 8147981920370688.0000\n",
            "Epoch 19/500\n",
            "76/76 [==============================] - 0s 1ms/step - loss: 4352411678277632.0000 - val_loss: 6806553575292928.0000\n",
            "Epoch 20/500\n",
            "76/76 [==============================] - 0s 1ms/step - loss: 7261244046180352.0000 - val_loss: 9405889257668608.0000\n",
            "Epoch 21/500\n",
            "76/76 [==============================] - 0s 1ms/step - loss: 6951162976665600.0000 - val_loss: 14827638002548736.0000\n",
            "Epoch 22/500\n",
            "76/76 [==============================] - 0s 1ms/step - loss: 20834989432111104.0000 - val_loss: 9623574306357248.0000\n",
            "Epoch 23/500\n",
            "76/76 [==============================] - 0s 1ms/step - loss: 14856969407954944.0000 - val_loss: 110436803319693312.0000\n",
            "Epoch 24/500\n",
            "76/76 [==============================] - 0s 1ms/step - loss: 20010145257881600.0000 - val_loss: 46161754446626816.0000\n",
            "Epoch 25/500\n",
            "76/76 [==============================] - 0s 1ms/step - loss: 50345318880903168.0000 - val_loss: 22337534348492800.0000\n",
            "Epoch 26/500\n",
            "76/76 [==============================] - 0s 1ms/step - loss: 11067952480649216.0000 - val_loss: 8518451840679936.0000\n",
            "Epoch 27/500\n",
            "76/76 [==============================] - 0s 1ms/step - loss: 17727695483830272.0000 - val_loss: 597431256543657984.0000\n",
            "Epoch 28/500\n",
            "76/76 [==============================] - 0s 1ms/step - loss: 66395976738275328.0000 - val_loss: 94605656945852416.0000\n",
            "Epoch 29/500\n",
            "76/76 [==============================] - 0s 1ms/step - loss: 47605198465531904.0000 - val_loss: 21406514287738880.0000\n",
            "Epoch 30/500\n",
            "76/76 [==============================] - 0s 1ms/step - loss: 86342706804031488.0000 - val_loss: 22783448590581760.0000\n",
            "Epoch 31/500\n",
            "76/76 [==============================] - 0s 1ms/step - loss: 26920285928161280.0000 - val_loss: 306109191133593600.0000\n",
            "Epoch 32/500\n",
            "76/76 [==============================] - 0s 1ms/step - loss: 32124356066803712.0000 - val_loss: 11963126744350720.0000\n",
            "Epoch 33/500\n",
            "76/76 [==============================] - 0s 1ms/step - loss: 25527110206488576.0000 - val_loss: 67206084879712256.0000\n",
            "Epoch 34/500\n",
            "76/76 [==============================] - 0s 1ms/step - loss: 9479115228839936.0000 - val_loss: 7307278042529792.0000\n",
            "Epoch 35/500\n",
            "76/76 [==============================] - 0s 991us/step - loss: 15255794702352384.0000 - val_loss: 15233645556006912.0000\n",
            "Epoch 36/500\n",
            "76/76 [==============================] - 0s 1ms/step - loss: 59292925464412160.0000 - val_loss: 15068874504404992.0000\n",
            "Epoch 37/500\n",
            "76/76 [==============================] - 0s 1ms/step - loss: 98371200803143680.0000 - val_loss: 35806199601430528.0000\n",
            "Epoch 38/500\n",
            "76/76 [==============================] - 0s 1ms/step - loss: 31181514108567552.0000 - val_loss: 71283645226156032.0000\n",
            "Epoch 39/500\n",
            "76/76 [==============================] - 0s 1ms/step - loss: 175351969823588352.0000 - val_loss: 48533834819436544.0000\n",
            "Epoch 40/500\n",
            "76/76 [==============================] - 0s 1ms/step - loss: 29596179402588160.0000 - val_loss: 393362516903723008.0000\n",
            "Epoch 41/500\n",
            "76/76 [==============================] - 0s 994us/step - loss: 33501472905756672.0000 - val_loss: 9373285087182848.0000\n",
            "Epoch 42/500\n",
            "76/76 [==============================] - 0s 1ms/step - loss: 6992518679887872.0000 - val_loss: 43482210249998336.0000\n",
            "Epoch 43/500\n",
            "76/76 [==============================] - 0s 1ms/step - loss: 7390477464633344.0000 - val_loss: 7836792212422656.0000\n",
            "Epoch 44/500\n",
            "76/76 [==============================] - 0s 1ms/step - loss: 4639983629500416.0000 - val_loss: 16846013859889152.0000\n",
            "Epoch 45/500\n",
            "76/76 [==============================] - 0s 1ms/step - loss: 18369907984957440.0000 - val_loss: 10694093831143424.0000\n",
            "Epoch 46/500\n",
            "76/76 [==============================] - 0s 1ms/step - loss: 17940959937429504.0000 - val_loss: 11345690835812352.0000\n",
            "Epoch 47/500\n",
            "76/76 [==============================] - 0s 1ms/step - loss: 4506977082277888.0000 - val_loss: 5649531261681664.0000\n",
            "Epoch 48/500\n",
            "76/76 [==============================] - 0s 1ms/step - loss: 7634868619968512.0000 - val_loss: 5873636749606912.0000\n",
            "Epoch 49/500\n",
            "76/76 [==============================] - 0s 1ms/step - loss: 10016182635593728.0000 - val_loss: 14185211826798592.0000\n",
            "Epoch 50/500\n",
            "76/76 [==============================] - 0s 1ms/step - loss: 10989895745011712.0000 - val_loss: 23686388155154432.0000\n",
            "Epoch 51/500\n",
            "76/76 [==============================] - 0s 1ms/step - loss: 107882809607061504.0000 - val_loss: 8072952062935040.0000\n",
            "Epoch 52/500\n",
            "76/76 [==============================] - 0s 1ms/step - loss: 37891309586874368.0000 - val_loss: 15033573094457344.0000\n",
            "Epoch 53/500\n",
            "76/76 [==============================] - 0s 1ms/step - loss: 10801454054899712.0000 - val_loss: 8902110531813376.0000\n",
            "Epoch 54/500\n",
            "76/76 [==============================] - 0s 982us/step - loss: 6404260631674880.0000 - val_loss: 10623893664432128.0000\n",
            "Epoch 55/500\n",
            "76/76 [==============================] - 0s 1ms/step - loss: 85980288873660416.0000 - val_loss: 66884619462508544.0000\n",
            "Epoch 56/500\n",
            "76/76 [==============================] - 0s 1ms/step - loss: 292605504717324288.0000 - val_loss: 15486342104350720.0000\n",
            "Epoch 57/500\n",
            "76/76 [==============================] - 0s 1ms/step - loss: 46766614690922496.0000 - val_loss: 139577838595473408.0000\n",
            "Epoch 58/500\n",
            "76/76 [==============================] - 0s 979us/step - loss: 44828321720041472.0000 - val_loss: 223364189454860288.0000\n",
            "Epoch 59/500\n",
            "76/76 [==============================] - 0s 1ms/step - loss: 98211848926527488.0000 - val_loss: 18338773767028736.0000\n",
            "Epoch 60/500\n",
            "76/76 [==============================] - 0s 1ms/step - loss: 29499907710648320.0000 - val_loss: 5614651295399936.0000\n",
            "Epoch 61/500\n",
            "76/76 [==============================] - 0s 1ms/step - loss: 124660163046014976.0000 - val_loss: 467949262563442688.0000\n",
            "Epoch 62/500\n",
            "76/76 [==============================] - 0s 1ms/step - loss: 81487916290801664.0000 - val_loss: 55460182548807680.0000\n",
            "Epoch 63/500\n",
            "76/76 [==============================] - 0s 1ms/step - loss: 132991239959085056.0000 - val_loss: 125743628675973120.0000\n",
            "Epoch 64/500\n",
            "76/76 [==============================] - 0s 1ms/step - loss: 89692489237135360.0000 - val_loss: 69426926569127936.0000\n",
            "Epoch 65/500\n",
            "76/76 [==============================] - 0s 1ms/step - loss: 55879027759513600.0000 - val_loss: 22931831120723968.0000\n",
            "Epoch 66/500\n",
            "76/76 [==============================] - 0s 1ms/step - loss: 77528317221142528.0000 - val_loss: 48497361957158912.0000\n",
            "Epoch 67/500\n",
            "76/76 [==============================] - 0s 1ms/step - loss: 23813386043129856.0000 - val_loss: 100806026353180672.0000\n",
            "Epoch 68/500\n",
            "76/76 [==============================] - 0s 1ms/step - loss: 11740039700545536.0000 - val_loss: 6295355293433856.0000\n",
            "Epoch 69/500\n",
            "76/76 [==============================] - 0s 985us/step - loss: 5549017752666112.0000 - val_loss: 10155922617794560.0000\n",
            "Epoch 70/500\n",
            "76/76 [==============================] - 0s 1ms/step - loss: 5109587837452288.0000 - val_loss: 5590521095389184.0000\n",
            "Epoch 71/500\n",
            "76/76 [==============================] - 0s 1ms/step - loss: 5547523104047104.0000 - val_loss: 53400264694038528.0000\n",
            "Epoch 72/500\n",
            "76/76 [==============================] - 0s 1ms/step - loss: 15655032313610240.0000 - val_loss: 19585233405870080.0000\n",
            "Epoch 73/500\n",
            "76/76 [==============================] - 0s 1ms/step - loss: 12999119027044352.0000 - val_loss: 69069739908923392.0000\n",
            "Epoch 74/500\n",
            "76/76 [==============================] - 0s 1ms/step - loss: 11623373356400640.0000 - val_loss: 13576103859847168.0000\n",
            "Epoch 75/500\n",
            "76/76 [==============================] - 0s 1ms/step - loss: 13863974042861568.0000 - val_loss: 32914215584923648.0000\n",
            "Epoch 76/500\n",
            "76/76 [==============================] - 0s 1ms/step - loss: 126190760541290496.0000 - val_loss: 125611481122209792.0000\n",
            "Epoch 77/500\n",
            "76/76 [==============================] - 0s 1ms/step - loss: 325238150836256768.0000 - val_loss: 427340999614791680.0000\n",
            "Epoch 78/500\n",
            "76/76 [==============================] - 0s 1ms/step - loss: 389512370780635136.0000 - val_loss: 53502622354636800.0000\n",
            "Epoch 79/500\n",
            "76/76 [==============================] - 0s 1ms/step - loss: 22175246861729792.0000 - val_loss: 7296169109618688.0000\n",
            "Epoch 80/500\n",
            "76/76 [==============================] - 0s 1ms/step - loss: 8236901702041600.0000 - val_loss: 38508195739598848.0000\n",
            "Epoch 81/500\n",
            "76/76 [==============================] - 0s 1ms/step - loss: 10543451074461696.0000 - val_loss: 4644911567601664.0000\n",
            "Epoch 82/500\n",
            "76/76 [==============================] - 0s 1ms/step - loss: 5868262671777792.0000 - val_loss: 12654171949891584.0000\n",
            "Epoch 83/500\n",
            "76/76 [==============================] - 0s 1ms/step - loss: 11936554855432192.0000 - val_loss: 12146268444819456.0000\n",
            "Epoch 84/500\n",
            "76/76 [==============================] - 0s 1ms/step - loss: 4009789520609280.0000 - val_loss: 13092099700293632.0000\n",
            "Epoch 85/500\n",
            "76/76 [==============================] - 0s 1ms/step - loss: 39947525179834368.0000 - val_loss: 127795094035103744.0000\n",
            "Epoch 86/500\n",
            "76/76 [==============================] - 0s 1ms/step - loss: 51220517251710976.0000 - val_loss: 5897529115803648.0000\n",
            "Epoch 87/500\n",
            "76/76 [==============================] - 0s 1ms/step - loss: 66367694378631168.0000 - val_loss: 376661038357020672.0000\n",
            "Epoch 88/500\n",
            "76/76 [==============================] - 0s 1ms/step - loss: 20944962069725184.0000 - val_loss: 35517264266526720.0000\n",
            "Epoch 89/500\n",
            "76/76 [==============================] - 0s 1ms/step - loss: 9784447675138048.0000 - val_loss: 6996869481758720.0000\n",
            "Epoch 90/500\n",
            "76/76 [==============================] - 0s 1ms/step - loss: 7814669909622784.0000 - val_loss: 6844700401074176.0000\n",
            "Epoch 91/500\n",
            "76/76 [==============================] - 0s 1ms/step - loss: 10496536072945664.0000 - val_loss: 25273041416093696.0000\n",
            "Epoch 92/500\n",
            "76/76 [==============================] - 0s 1ms/step - loss: 7250254298611712.0000 - val_loss: 64628537566429184.0000\n",
            "Epoch 93/500\n",
            "76/76 [==============================] - 0s 1ms/step - loss: 10027813407031296.0000 - val_loss: 38860155424604160.0000\n",
            "Epoch 94/500\n",
            "76/76 [==============================] - 0s 2ms/step - loss: 25582345633398784.0000 - val_loss: 69534558449565696.0000\n",
            "Epoch 95/500\n",
            "76/76 [==============================] - 0s 1ms/step - loss: 12003489773256704.0000 - val_loss: 26350683070398464.0000\n",
            "Epoch 96/500\n",
            "76/76 [==============================] - 0s 1ms/step - loss: 8003982404354048.0000 - val_loss: 10757968584769536.0000\n",
            "Epoch 97/500\n",
            "76/76 [==============================] - 0s 1ms/step - loss: 6822718221582336.0000 - val_loss: 7405364358152192.0000\n",
            "Epoch 98/500\n",
            "76/76 [==============================] - 0s 1ms/step - loss: 8054045616898048.0000 - val_loss: 4946445115326464.0000\n",
            "Epoch 99/500\n",
            "76/76 [==============================] - 0s 1ms/step - loss: 96347858889867264.0000 - val_loss: 473111778893496320.0000\n",
            "Epoch 100/500\n",
            "76/76 [==============================] - 0s 1ms/step - loss: 60656066479783936.0000 - val_loss: 8200299990745088.0000\n",
            "Epoch 101/500\n",
            "76/76 [==============================] - 0s 1ms/step - loss: 17226628492951552.0000 - val_loss: 105693527337336832.0000\n",
            "Epoch 102/500\n",
            "76/76 [==============================] - 0s 1ms/step - loss: 532162150374834176.0000 - val_loss: 645312582751617024.0000\n",
            "Epoch 103/500\n",
            "76/76 [==============================] - 0s 1ms/step - loss: 56199204686528512.0000 - val_loss: 15795861070020608.0000\n",
            "Epoch 104/500\n",
            "76/76 [==============================] - 0s 1ms/step - loss: 12971261869162496.0000 - val_loss: 12008020963753984.0000\n",
            "Epoch 105/500\n",
            "76/76 [==============================] - 0s 1ms/step - loss: 12360510003478528.0000 - val_loss: 14506973596745728.0000\n",
            "Epoch 106/500\n",
            "76/76 [==============================] - 0s 1ms/step - loss: 6809044119453696.0000 - val_loss: 12397812868186112.0000\n",
            "Epoch 107/500\n",
            "76/76 [==============================] - 0s 1ms/step - loss: 3960728914493440.0000 - val_loss: 5284616344698880.0000\n",
            "Epoch 108/500\n",
            "76/76 [==============================] - 0s 1ms/step - loss: 3963498363092992.0000 - val_loss: 5719970335948800.0000\n",
            "Epoch 109/500\n",
            "76/76 [==============================] - 0s 1ms/step - loss: 14345197211090944.0000 - val_loss: 57540664706990080.0000\n",
            "Epoch 110/500\n",
            "76/76 [==============================] - 0s 1ms/step - loss: 26840040906686464.0000 - val_loss: 19413185605926912.0000\n",
            "Epoch 111/500\n",
            "76/76 [==============================] - 0s 1ms/step - loss: 20815531082776576.0000 - val_loss: 16369460394852352.0000\n",
            "Epoch 112/500\n",
            "76/76 [==============================] - 0s 1ms/step - loss: 43370206092853248.0000 - val_loss: 16452508956229632.0000\n",
            "Epoch 113/500\n",
            "76/76 [==============================] - 0s 1ms/step - loss: 7749674706403328.0000 - val_loss: 8636036770955264.0000\n",
            "Epoch 114/500\n",
            "76/76 [==============================] - 0s 1ms/step - loss: 10393404244492288.0000 - val_loss: 26596037372149760.0000\n",
            "Epoch 115/500\n",
            "76/76 [==============================] - 0s 1ms/step - loss: 33792190652088320.0000 - val_loss: 12458041194577920.0000\n",
            "Epoch 116/500\n",
            "76/76 [==============================] - 0s 1ms/step - loss: 25013112142823424.0000 - val_loss: 637101910951723008.0000\n",
            "Epoch 117/500\n",
            "76/76 [==============================] - 0s 1ms/step - loss: 331702969969934336.0000 - val_loss: 125484959975604224.0000\n",
            "Epoch 118/500\n",
            "76/76 [==============================] - 0s 1ms/step - loss: 110777729233715200.0000 - val_loss: 11052127673647104.0000\n",
            "Epoch 119/500\n",
            "76/76 [==============================] - 0s 1ms/step - loss: 30174745857097728.0000 - val_loss: 16300928822935552.0000\n",
            "Epoch 120/500\n",
            "76/76 [==============================] - 0s 1ms/step - loss: 8725872991272960.0000 - val_loss: 20255851746951168.0000\n",
            "Epoch 121/500\n",
            "76/76 [==============================] - 0s 1ms/step - loss: 8854946959065088.0000 - val_loss: 5246380935217152.0000\n",
            "Epoch 122/500\n",
            "76/76 [==============================] - 0s 1ms/step - loss: 17153222133153792.0000 - val_loss: 7583945340223488.0000\n",
            "Epoch 123/500\n",
            "76/76 [==============================] - 0s 1ms/step - loss: 7338893833666560.0000 - val_loss: 9634813162029056.0000\n",
            "Epoch 124/500\n",
            "76/76 [==============================] - 0s 1ms/step - loss: 32197196564660224.0000 - val_loss: 11002717296132096.0000\n",
            "Epoch 125/500\n",
            "76/76 [==============================] - 0s 1ms/step - loss: 44744191900647424.0000 - val_loss: 13433585033805824.0000\n",
            "Epoch 126/500\n",
            "76/76 [==============================] - 0s 1ms/step - loss: 11049809465049088.0000 - val_loss: 8353322159308800.0000\n",
            "Epoch 127/500\n",
            "76/76 [==============================] - 0s 1ms/step - loss: 70317320534228992.0000 - val_loss: 144196053720104960.0000\n",
            "Epoch 128/500\n",
            "76/76 [==============================] - 0s 1ms/step - loss: 31862272867434496.0000 - val_loss: 21630279936376832.0000\n",
            "Epoch 129/500\n",
            "76/76 [==============================] - 0s 1ms/step - loss: 11286245267210240.0000 - val_loss: 93515551296454656.0000\n",
            "Epoch 130/500\n",
            "76/76 [==============================] - 0s 1ms/step - loss: 101741719338352640.0000 - val_loss: 6593094237552640.0000\n",
            "Epoch 131/500\n",
            "76/76 [==============================] - 0s 1ms/step - loss: 35987792966189056.0000 - val_loss: 33336284168585216.0000\n",
            "Epoch 132/500\n",
            "76/76 [==============================] - 0s 1ms/step - loss: 146601475924033536.0000 - val_loss: 314731733117304832.0000\n",
            "Epoch 133/500\n",
            "76/76 [==============================] - 0s 1ms/step - loss: 47763845967511552.0000 - val_loss: 10755447438966784.0000\n",
            "Epoch 134/500\n",
            "76/76 [==============================] - 0s 1ms/step - loss: 51291929672941568.0000 - val_loss: 349932116844216320.0000\n",
            "Epoch 135/500\n",
            "76/76 [==============================] - 0s 1ms/step - loss: 279571859521929216.0000 - val_loss: 325830134768599040.0000\n",
            "Epoch 136/500\n",
            "76/76 [==============================] - 0s 1ms/step - loss: 155598831113732096.0000 - val_loss: 171938398536204288.0000\n",
            "Epoch 137/500\n",
            "76/76 [==============================] - 0s 1ms/step - loss: 39428151964598272.0000 - val_loss: 17263293555015680.0000\n",
            "Epoch 138/500\n",
            "76/76 [==============================] - 0s 1ms/step - loss: 8967389739745280.0000 - val_loss: 4914897506795520.0000\n",
            "Epoch 139/500\n",
            "76/76 [==============================] - 0s 1ms/step - loss: 4290199882301440.0000 - val_loss: 8671988868448256.0000\n",
            "Epoch 140/500\n",
            "76/76 [==============================] - 0s 1ms/step - loss: 8038195040092160.0000 - val_loss: 8214613506129920.0000\n",
            "Epoch 141/500\n",
            "76/76 [==============================] - 0s 1ms/step - loss: 7080030249156608.0000 - val_loss: 22314214823559168.0000\n",
            "Epoch 142/500\n",
            "76/76 [==============================] - 0s 1ms/step - loss: 6596536116969472.0000 - val_loss: 8283451094466560.0000\n",
            "Epoch 143/500\n",
            "76/76 [==============================] - 0s 1ms/step - loss: 8102973884334080.0000 - val_loss: 5101857970061312.0000\n",
            "Epoch 144/500\n",
            "76/76 [==============================] - 0s 1ms/step - loss: 6426949333286912.0000 - val_loss: 15122613135212544.0000\n",
            "Epoch 145/500\n",
            "76/76 [==============================] - 0s 1ms/step - loss: 23881010303205376.0000 - val_loss: 13070987788550144.0000\n",
            "Epoch 146/500\n",
            "76/76 [==============================] - 0s 1ms/step - loss: 11109639433224192.0000 - val_loss: 5902990166720512.0000\n",
            "Epoch 147/500\n",
            "76/76 [==============================] - 0s 1ms/step - loss: 21626341451366400.0000 - val_loss: 6558388217446400.0000\n",
            "Epoch 148/500\n",
            "76/76 [==============================] - 0s 1ms/step - loss: 27928986914914304.0000 - val_loss: 55327283375767552.0000\n",
            "Epoch 149/500\n",
            "76/76 [==============================] - 0s 1ms/step - loss: 16269679714631680.0000 - val_loss: 13673280716144640.0000\n",
            "Epoch 150/500\n",
            "76/76 [==============================] - 0s 1ms/step - loss: 11811210529865728.0000 - val_loss: 5903340206555136.0000\n",
            "Epoch 151/500\n",
            "76/76 [==============================] - 0s 1ms/step - loss: 8713331149897728.0000 - val_loss: 31267795706576896.0000\n",
            "Epoch 152/500\n",
            "76/76 [==============================] - 0s 1ms/step - loss: 7200077806305280.0000 - val_loss: 5201612343607296.0000\n",
            "Epoch 153/500\n",
            "76/76 [==============================] - 0s 1ms/step - loss: 5088158098128896.0000 - val_loss: 8431905028440064.0000\n",
            "Epoch 154/500\n",
            "76/76 [==============================] - 0s 1ms/step - loss: 17168127817154560.0000 - val_loss: 20449118832820224.0000\n",
            "Epoch 155/500\n",
            "76/76 [==============================] - 0s 1ms/step - loss: 31093097911812096.0000 - val_loss: 12318309802311680.0000\n",
            "Epoch 156/500\n",
            "76/76 [==============================] - 0s 1ms/step - loss: 118027986216681472.0000 - val_loss: 747133750395011072.0000\n",
            "Epoch 157/500\n",
            "76/76 [==============================] - 0s 1ms/step - loss: 607319783087538176.0000 - val_loss: 79824647255752704.0000\n",
            "Epoch 158/500\n",
            "76/76 [==============================] - 0s 1ms/step - loss: 67374585036668928.0000 - val_loss: 33202010606010368.0000\n",
            "Epoch 159/500\n",
            "76/76 [==============================] - 0s 1ms/step - loss: 22958019683811328.0000 - val_loss: 60492900672208896.0000\n",
            "Epoch 160/500\n",
            "76/76 [==============================] - 0s 1ms/step - loss: 45535964826697728.0000 - val_loss: 5137649543151616.0000\n",
            "Epoch 161/500\n",
            "76/76 [==============================] - 0s 1ms/step - loss: 4808782286684160.0000 - val_loss: 10622269093052416.0000\n",
            "Epoch 162/500\n",
            "76/76 [==============================] - 0s 1ms/step - loss: 6499407579054080.0000 - val_loss: 11963998622711808.0000\n",
            "Epoch 163/500\n",
            "76/76 [==============================] - 0s 1ms/step - loss: 5545088931332096.0000 - val_loss: 15077672744910848.0000\n",
            "Epoch 164/500\n",
            "76/76 [==============================] - 0s 1ms/step - loss: 7567878404440064.0000 - val_loss: 12874311572389888.0000\n",
            "Epoch 165/500\n",
            "76/76 [==============================] - 0s 1ms/step - loss: 5952347930886144.0000 - val_loss: 6733178354008064.0000\n",
            "Epoch 166/500\n",
            "76/76 [==============================] - 0s 1ms/step - loss: 3947903068405760.0000 - val_loss: 5070787639771136.0000\n",
            "Epoch 167/500\n",
            "76/76 [==============================] - 0s 1ms/step - loss: 8846780615622656.0000 - val_loss: 25764271858122752.0000\n",
            "Epoch 168/500\n",
            "76/76 [==============================] - 0s 1ms/step - loss: 114434395670052864.0000 - val_loss: 72377397302788096.0000\n",
            "Epoch 169/500\n",
            "76/76 [==============================] - 0s 1ms/step - loss: 111567891547029504.0000 - val_loss: 526031857653907456.0000\n",
            "Epoch 170/500\n",
            "76/76 [==============================] - 0s 1ms/step - loss: 75895920411017216.0000 - val_loss: 121645147543830528.0000\n",
            "Epoch 171/500\n",
            "76/76 [==============================] - 0s 1ms/step - loss: 32875752005304320.0000 - val_loss: 7754566137282560.0000\n",
            "Epoch 172/500\n",
            "76/76 [==============================] - 0s 1ms/step - loss: 3661729129037824.0000 - val_loss: 11053575077625856.0000\n",
            "Epoch 173/500\n",
            "76/76 [==============================] - 0s 1ms/step - loss: 6472289692418048.0000 - val_loss: 12875850244423680.0000\n",
            "Epoch 174/500\n",
            "76/76 [==============================] - 0s 1ms/step - loss: 5778049031208960.0000 - val_loss: 8866580951728128.0000\n",
            "Epoch 175/500\n",
            "76/76 [==============================] - 0s 1ms/step - loss: 4448131735355392.0000 - val_loss: 6229484990627840.0000\n",
            "Epoch 176/500\n",
            "76/76 [==============================] - 0s 1ms/step - loss: 15804442414678016.0000 - val_loss: 513155614419976192.0000\n",
            "Epoch 177/500\n",
            "76/76 [==============================] - 0s 1ms/step - loss: 83510734218067968.0000 - val_loss: 50064866106408960.0000\n",
            "Epoch 178/500\n",
            "76/76 [==============================] - 0s 1ms/step - loss: 46140129286291456.0000 - val_loss: 114080979991134208.0000\n",
            "Epoch 179/500\n",
            "76/76 [==============================] - 0s 1ms/step - loss: 76908089583861760.0000 - val_loss: 2606731787858083840.0000\n",
            "Epoch 180/500\n",
            "76/76 [==============================] - 0s 1ms/step - loss: 769228917591506944.0000 - val_loss: 112053394650169344.0000\n",
            "Epoch 181/500\n",
            "76/76 [==============================] - 0s 1ms/step - loss: 135112507126710272.0000 - val_loss: 305599808012288000.0000\n",
            "Epoch 182/500\n",
            "76/76 [==============================] - 0s 1ms/step - loss: 213873720479973376.0000 - val_loss: 41122211620192256.0000\n",
            "Epoch 183/500\n",
            "76/76 [==============================] - 0s 1ms/step - loss: 34287396086349824.0000 - val_loss: 121840852023640064.0000\n",
            "Epoch 184/500\n",
            "76/76 [==============================] - 0s 1ms/step - loss: 48000520140357632.0000 - val_loss: 8151299245735936.0000\n",
            "Epoch 185/500\n",
            "76/76 [==============================] - 0s 1ms/step - loss: 31717014926000128.0000 - val_loss: 7630767999942656.0000\n",
            "Epoch 186/500\n",
            "76/76 [==============================] - 0s 1ms/step - loss: 4666705842274304.0000 - val_loss: 5747446315483136.0000\n",
            "Epoch 187/500\n",
            "76/76 [==============================] - 0s 1ms/step - loss: 5018052420698112.0000 - val_loss: 7387549370679296.0000\n",
            "Epoch 188/500\n",
            "76/76 [==============================] - 0s 1ms/step - loss: 5234413545717760.0000 - val_loss: 5620120399380480.0000\n",
            "Epoch 189/500\n",
            "76/76 [==============================] - 0s 1ms/step - loss: 5700340724793344.0000 - val_loss: 6556245028765696.0000\n",
            "Epoch 190/500\n",
            "76/76 [==============================] - 0s 1ms/step - loss: 7031780586553344.0000 - val_loss: 5252685410336768.0000\n",
            "Epoch 191/500\n",
            "76/76 [==============================] - 0s 1ms/step - loss: 7211196402892800.0000 - val_loss: 7868197550161920.0000\n",
            "Epoch 192/500\n",
            "76/76 [==============================] - 0s 1ms/step - loss: 25021979102806016.0000 - val_loss: 22234463723323392.0000\n",
            "Epoch 193/500\n",
            "76/76 [==============================] - 0s 1ms/step - loss: 14134493631741952.0000 - val_loss: 15376500463239168.0000\n",
            "Epoch 194/500\n",
            "76/76 [==============================] - 0s 1ms/step - loss: 10187512102256640.0000 - val_loss: 20157911460216832.0000\n",
            "Epoch 195/500\n",
            "76/76 [==============================] - 0s 1ms/step - loss: 9671328973979648.0000 - val_loss: 13424554865065984.0000\n",
            "Epoch 196/500\n",
            "76/76 [==============================] - 0s 1ms/step - loss: 17459569265475584.0000 - val_loss: 11367771262681088.0000\n",
            "Epoch 197/500\n",
            "76/76 [==============================] - 0s 2ms/step - loss: 25340831032410112.0000 - val_loss: 178509269002354688.0000\n",
            "Epoch 198/500\n",
            "76/76 [==============================] - 0s 1ms/step - loss: 19253223843954688.0000 - val_loss: 10341629487480832.0000\n",
            "Epoch 199/500\n",
            "76/76 [==============================] - 0s 1ms/step - loss: 16134868207403008.0000 - val_loss: 4630205599580160.0000\n",
            "Epoch 200/500\n",
            "76/76 [==============================] - 0s 1ms/step - loss: 7337801301360640.0000 - val_loss: 21485019847458816.0000\n",
            "Epoch 201/500\n",
            "76/76 [==============================] - 0s 1ms/step - loss: 7851112707129344.0000 - val_loss: 11800623435481088.0000\n",
            "Epoch 202/500\n",
            "76/76 [==============================] - 0s 1ms/step - loss: 6221299319832576.0000 - val_loss: 11180227220733952.0000\n",
            "Epoch 203/500\n",
            "76/76 [==============================] - 0s 1ms/step - loss: 23056086672080896.0000 - val_loss: 72927522483863552.0000\n",
            "Epoch 204/500\n",
            "76/76 [==============================] - 0s 1ms/step - loss: 24913146779009024.0000 - val_loss: 138663577497108480.0000\n",
            "Epoch 205/500\n",
            "76/76 [==============================] - 0s 1ms/step - loss: 23005369550766080.0000 - val_loss: 8138950677889024.0000\n",
            "Epoch 206/500\n",
            "76/76 [==============================] - 0s 1ms/step - loss: 24109824685899776.0000 - val_loss: 13684296233517056.0000\n",
            "Epoch 207/500\n",
            "76/76 [==============================] - 0s 1ms/step - loss: 62443009098121216.0000 - val_loss: 3934579006111744.0000\n",
            "Epoch 208/500\n",
            "76/76 [==============================] - 0s 1ms/step - loss: 162870107666644992.0000 - val_loss: 565563904877395968.0000\n",
            "Epoch 209/500\n",
            "76/76 [==============================] - 0s 1ms/step - loss: 279859192834031616.0000 - val_loss: 624891353288933376.0000\n",
            "Epoch 210/500\n",
            "76/76 [==============================] - 0s 1ms/step - loss: 126879724835176448.0000 - val_loss: 53352547607379968.0000\n",
            "Epoch 211/500\n",
            "76/76 [==============================] - 0s 1ms/step - loss: 78423199427067904.0000 - val_loss: 226554181924683776.0000\n",
            "Epoch 212/500\n",
            "76/76 [==============================] - 0s 1ms/step - loss: 63744933944623104.0000 - val_loss: 79882552004837376.0000\n",
            "Epoch 213/500\n",
            "76/76 [==============================] - 0s 1ms/step - loss: 8995309711523840.0000 - val_loss: 6535134727634944.0000\n",
            "Epoch 214/500\n",
            "76/76 [==============================] - 0s 1ms/step - loss: 6110789274435584.0000 - val_loss: 6674272877543424.0000\n",
            "Epoch 215/500\n",
            "76/76 [==============================] - 0s 1ms/step - loss: 6325878552264704.0000 - val_loss: 8546810435993600.0000\n",
            "Epoch 216/500\n",
            "76/76 [==============================] - 0s 1ms/step - loss: 7948950451519488.0000 - val_loss: 20775611509243904.0000\n",
            "Epoch 217/500\n",
            "76/76 [==============================] - 0s 1ms/step - loss: 22372476054929408.0000 - val_loss: 17735388843999232.0000\n",
            "Epoch 218/500\n",
            "76/76 [==============================] - 0s 1ms/step - loss: 38048969246375936.0000 - val_loss: 27633171042402304.0000\n",
            "Epoch 219/500\n",
            "76/76 [==============================] - 0s 1ms/step - loss: 43018340897128448.0000 - val_loss: 78249648388571136.0000\n",
            "Epoch 220/500\n",
            "76/76 [==============================] - 0s 1ms/step - loss: 28334569266610176.0000 - val_loss: 7719918099234816.0000\n",
            "Epoch 221/500\n",
            "76/76 [==============================] - 0s 1ms/step - loss: 36288260288282624.0000 - val_loss: 186622565303713792.0000\n",
            "Epoch 222/500\n",
            "76/76 [==============================] - 0s 1ms/step - loss: 37559566312931328.0000 - val_loss: 29947408943153152.0000\n",
            "Epoch 223/500\n",
            "76/76 [==============================] - 0s 1ms/step - loss: 9043962027311104.0000 - val_loss: 9431407805857792.0000\n",
            "Epoch 224/500\n",
            "76/76 [==============================] - 0s 1ms/step - loss: 6045116003254272.0000 - val_loss: 22259999451381760.0000\n",
            "Epoch 225/500\n",
            "76/76 [==============================] - 0s 1ms/step - loss: 6270240472170496.0000 - val_loss: 9150416012967936.0000\n",
            "Epoch 226/500\n",
            "76/76 [==============================] - 0s 1ms/step - loss: 13743536717430784.0000 - val_loss: 11828771577397248.0000\n",
            "Epoch 227/500\n",
            "76/76 [==============================] - 0s 1ms/step - loss: 15203724666339328.0000 - val_loss: 113464042298802176.0000\n",
            "Epoch 228/500\n",
            "76/76 [==============================] - 0s 1ms/step - loss: 83921874257444864.0000 - val_loss: 22270717542268928.0000\n",
            "Epoch 229/500\n",
            "76/76 [==============================] - 0s 1ms/step - loss: 142127150793752576.0000 - val_loss: 115574159731326976.0000\n",
            "Epoch 230/500\n",
            "76/76 [==============================] - 0s 1ms/step - loss: 101968021165178880.0000 - val_loss: 7959883827642368.0000\n",
            "Epoch 231/500\n",
            "76/76 [==============================] - 0s 1ms/step - loss: 15723679849644032.0000 - val_loss: 28048539477082112.0000\n",
            "Epoch 232/500\n",
            "76/76 [==============================] - 0s 1ms/step - loss: 12133099001348096.0000 - val_loss: 9255332400332800.0000\n",
            "Epoch 233/500\n",
            "76/76 [==============================] - 0s 1ms/step - loss: 3780454373130240.0000 - val_loss: 13333020522053632.0000\n",
            "Epoch 234/500\n",
            "76/76 [==============================] - 0s 1ms/step - loss: 7337175309877248.0000 - val_loss: 24947124265287680.0000\n",
            "Epoch 235/500\n",
            "76/76 [==============================] - 0s 1ms/step - loss: 18381749209792512.0000 - val_loss: 15129765329502208.0000\n",
            "Epoch 236/500\n",
            "76/76 [==============================] - 0s 1ms/step - loss: 9144155024392192.0000 - val_loss: 9803401365815296.0000\n",
            "Epoch 237/500\n",
            "76/76 [==============================] - 0s 1ms/step - loss: 135964276450918400.0000 - val_loss: 33674566530236416.0000\n",
            "Epoch 238/500\n",
            "76/76 [==============================] - 0s 1ms/step - loss: 324088336551510016.0000 - val_loss: 100359736301453312.0000\n",
            "Epoch 239/500\n",
            "76/76 [==============================] - 0s 1ms/step - loss: 86093555751190528.0000 - val_loss: 197267504307896320.0000\n",
            "Epoch 240/500\n",
            "76/76 [==============================] - 0s 1ms/step - loss: 97569304639176704.0000 - val_loss: 25797044606074880.0000\n",
            "Epoch 241/500\n",
            "76/76 [==============================] - 0s 1ms/step - loss: 13491227789885440.0000 - val_loss: 9727467417763840.0000\n",
            "Epoch 242/500\n",
            "76/76 [==============================] - 0s 1ms/step - loss: 7687629071974400.0000 - val_loss: 39682482747998208.0000\n",
            "Epoch 243/500\n",
            "76/76 [==============================] - 0s 1ms/step - loss: 25398003489570816.0000 - val_loss: 62021943389323264.0000\n",
            "Epoch 244/500\n",
            "76/76 [==============================] - 0s 1ms/step - loss: 14021551024242688.0000 - val_loss: 106166858503159808.0000\n",
            "Epoch 245/500\n",
            "76/76 [==============================] - 0s 1ms/step - loss: 19743152910893056.0000 - val_loss: 3918515023118336.0000\n",
            "Epoch 246/500\n",
            "76/76 [==============================] - 0s 1ms/step - loss: 10149757192241152.0000 - val_loss: 65491349251555328.0000\n",
            "Epoch 247/500\n",
            "76/76 [==============================] - 0s 1ms/step - loss: 53249966608482304.0000 - val_loss: 43264081745936384.0000\n",
            "Epoch 248/500\n",
            "76/76 [==============================] - 0s 1ms/step - loss: 75261296043360256.0000 - val_loss: 81742058095640576.0000\n",
            "Epoch 249/500\n",
            "76/76 [==============================] - 0s 1ms/step - loss: 217188438800072704.0000 - val_loss: 32307521389592576.0000\n",
            "Epoch 250/500\n",
            "76/76 [==============================] - 0s 1ms/step - loss: 74461444283826176.0000 - val_loss: 7788699316125696.0000\n",
            "Epoch 251/500\n",
            "76/76 [==============================] - 0s 1ms/step - loss: 26595307227709440.0000 - val_loss: 206107010859532288.0000\n",
            "Epoch 252/500\n",
            "76/76 [==============================] - 0s 1ms/step - loss: 139939775489507328.0000 - val_loss: 652802662118457344.0000\n",
            "Epoch 253/500\n",
            "76/76 [==============================] - 0s 1ms/step - loss: 855606963386449920.0000 - val_loss: 1482050002460082176.0000\n",
            "Epoch 254/500\n",
            "76/76 [==============================] - 0s 1ms/step - loss: 462598420507394048.0000 - val_loss: 22204727517249536.0000\n",
            "Epoch 255/500\n",
            "76/76 [==============================] - 0s 1ms/step - loss: 6716483816128512.0000 - val_loss: 10118334137761792.0000\n",
            "Epoch 256/500\n",
            "76/76 [==============================] - 0s 1ms/step - loss: 4808031204278272.0000 - val_loss: 11374980365287424.0000\n",
            "Epoch 257/500\n",
            "76/76 [==============================] - 0s 1ms/step - loss: 12597569649639424.0000 - val_loss: 8269016246255616.0000\n",
            "Epoch 258/500\n",
            "76/76 [==============================] - 0s 1ms/step - loss: 8267363757588480.0000 - val_loss: 11117508887052288.0000\n",
            "Epoch 259/500\n",
            "76/76 [==============================] - 0s 1ms/step - loss: 4358678572433408.0000 - val_loss: 11558508612812800.0000\n",
            "Epoch 260/500\n",
            "76/76 [==============================] - 0s 1ms/step - loss: 4852236618301440.0000 - val_loss: 10345923381035008.0000\n",
            "Epoch 261/500\n",
            "76/76 [==============================] - 0s 1ms/step - loss: 12331921627414528.0000 - val_loss: 11688524789055488.0000\n",
            "Epoch 262/500\n",
            "76/76 [==============================] - 0s 1ms/step - loss: 13940746583277568.0000 - val_loss: 7176300867354624.0000\n",
            "Epoch 263/500\n",
            "76/76 [==============================] - 0s 1ms/step - loss: 8730411161092096.0000 - val_loss: 6539617599750144.0000\n",
            "Epoch 264/500\n",
            "76/76 [==============================] - 0s 1ms/step - loss: 5375050102341632.0000 - val_loss: 7371399219904512.0000\n",
            "Epoch 265/500\n",
            "76/76 [==============================] - 0s 1ms/step - loss: 5659707649818624.0000 - val_loss: 13744540666036224.0000\n",
            "Epoch 266/500\n",
            "76/76 [==============================] - 0s 1ms/step - loss: 12713685164228608.0000 - val_loss: 11059480657657856.0000\n",
            "Epoch 267/500\n",
            "76/76 [==============================] - 0s 1ms/step - loss: 7603922843729920.0000 - val_loss: 11932427391860736.0000\n",
            "Epoch 268/500\n",
            "76/76 [==============================] - 0s 1ms/step - loss: 8477024733626368.0000 - val_loss: 7363237171429376.0000\n",
            "Epoch 269/500\n",
            "76/76 [==============================] - 0s 1ms/step - loss: 17076361545908224.0000 - val_loss: 116158627470901248.0000\n",
            "Epoch 270/500\n",
            "76/76 [==============================] - 0s 1ms/step - loss: 12218810442448896.0000 - val_loss: 8454701641105408.0000\n",
            "Epoch 271/500\n",
            "76/76 [==============================] - 0s 1ms/step - loss: 19722320172023808.0000 - val_loss: 111361209130811392.0000\n",
            "Epoch 272/500\n",
            "76/76 [==============================] - 0s 1ms/step - loss: 35827395265036288.0000 - val_loss: 24928226409185280.0000\n",
            "Epoch 273/500\n",
            "76/76 [==============================] - 0s 1ms/step - loss: 8395341434978304.0000 - val_loss: 13977103481438208.0000\n",
            "Epoch 274/500\n",
            "76/76 [==============================] - 0s 1ms/step - loss: 69709659971256320.0000 - val_loss: 33850840577998848.0000\n",
            "Epoch 275/500\n",
            "76/76 [==============================] - 0s 1ms/step - loss: 163162801097932800.0000 - val_loss: 120779471115517952.0000\n",
            "Epoch 276/500\n",
            "76/76 [==============================] - 0s 1ms/step - loss: 178691358435835904.0000 - val_loss: 220125440516292608.0000\n",
            "Epoch 277/500\n",
            "76/76 [==============================] - 0s 1ms/step - loss: 216271325843423232.0000 - val_loss: 32464678537920512.0000\n",
            "Epoch 278/500\n",
            "76/76 [==============================] - 0s 1ms/step - loss: 98008009778659328.0000 - val_loss: 6949869654638592.0000\n",
            "Epoch 279/500\n",
            "76/76 [==============================] - 0s 1ms/step - loss: 24497101886980096.0000 - val_loss: 542086307967401984.0000\n",
            "Epoch 280/500\n",
            "76/76 [==============================] - 0s 1ms/step - loss: 106830430950391808.0000 - val_loss: 17732153659883520.0000\n",
            "Epoch 281/500\n",
            "76/76 [==============================] - 0s 1ms/step - loss: 11349217003962368.0000 - val_loss: 10209427172884480.0000\n",
            "Epoch 282/500\n",
            "76/76 [==============================] - 0s 1ms/step - loss: 9834712751144960.0000 - val_loss: 13938679630266368.0000\n",
            "Epoch 283/500\n",
            "76/76 [==============================] - 0s 1ms/step - loss: 6211291509161984.0000 - val_loss: 7207318584295424.0000\n",
            "Epoch 284/500\n",
            "76/76 [==============================] - 0s 1ms/step - loss: 4743600789258240.0000 - val_loss: 9091770382024704.0000\n",
            "Epoch 285/500\n",
            "76/76 [==============================] - 0s 1ms/step - loss: 4595976320843776.0000 - val_loss: 16789335323967488.0000\n",
            "Epoch 286/500\n",
            "76/76 [==============================] - 0s 1ms/step - loss: 15217315016605696.0000 - val_loss: 11572879573385216.0000\n",
            "Epoch 287/500\n",
            "76/76 [==============================] - 0s 1ms/step - loss: 4681770976935936.0000 - val_loss: 15577046444933120.0000\n",
            "Epoch 288/500\n",
            "76/76 [==============================] - 0s 1ms/step - loss: 4864947574013952.0000 - val_loss: 8108373195096064.0000\n",
            "Epoch 289/500\n",
            "76/76 [==============================] - 0s 1ms/step - loss: 10644311938957312.0000 - val_loss: 11289666208661504.0000\n",
            "Epoch 290/500\n",
            "76/76 [==============================] - 0s 1ms/step - loss: 14387462910509056.0000 - val_loss: 8584920754552832.0000\n",
            "Epoch 291/500\n",
            "76/76 [==============================] - 0s 1ms/step - loss: 39692760604737536.0000 - val_loss: 733510595168436224.0000\n",
            "Epoch 292/500\n",
            "76/76 [==============================] - 0s 2ms/step - loss: 58588172870746112.0000 - val_loss: 7075816349368320.0000\n",
            "Epoch 293/500\n",
            "76/76 [==============================] - 0s 1ms/step - loss: 46792036602347520.0000 - val_loss: 44278291028246528.0000\n",
            "Epoch 294/500\n",
            "76/76 [==============================] - 0s 1ms/step - loss: 17121805521125376.0000 - val_loss: 16788954145619968.0000\n",
            "Epoch 295/500\n",
            "76/76 [==============================] - 0s 1ms/step - loss: 23385880030871552.0000 - val_loss: 14299581437181952.0000\n",
            "Epoch 296/500\n",
            "76/76 [==============================] - 0s 1ms/step - loss: 30894200123817984.0000 - val_loss: 35525952985366528.0000\n",
            "Epoch 297/500\n",
            "76/76 [==============================] - 0s 1ms/step - loss: 193735872959479808.0000 - val_loss: 25481031649853440.0000\n",
            "Epoch 298/500\n",
            "76/76 [==============================] - 0s 1ms/step - loss: 386046813209100288.0000 - val_loss: 425699669272690688.0000\n",
            "Epoch 299/500\n",
            "76/76 [==============================] - 0s 1ms/step - loss: 169029279747670016.0000 - val_loss: 7683647637291008.0000\n",
            "Epoch 300/500\n",
            "76/76 [==============================] - 0s 1ms/step - loss: 13419028315897856.0000 - val_loss: 6548002986524672.0000\n",
            "Epoch 301/500\n",
            "76/76 [==============================] - 0s 1ms/step - loss: 7428262439419904.0000 - val_loss: 9033855969263616.0000\n",
            "Epoch 302/500\n",
            "76/76 [==============================] - 0s 1ms/step - loss: 26070969030279168.0000 - val_loss: 54787496180973568.0000\n",
            "Epoch 303/500\n",
            "76/76 [==============================] - 0s 1ms/step - loss: 11865697558724608.0000 - val_loss: 9755092647411712.0000\n",
            "Epoch 304/500\n",
            "76/76 [==============================] - 0s 1ms/step - loss: 4767136673169408.0000 - val_loss: 20291441993449472.0000\n",
            "Epoch 305/500\n",
            "76/76 [==============================] - 0s 1ms/step - loss: 13305700235083776.0000 - val_loss: 9431297210449920.0000\n",
            "Epoch 306/500\n",
            "76/76 [==============================] - 0s 1ms/step - loss: 15481173111209984.0000 - val_loss: 82095963400830976.0000\n",
            "Epoch 307/500\n",
            "76/76 [==============================] - 0s 1ms/step - loss: 37865200480681984.0000 - val_loss: 18744646029017088.0000\n",
            "Epoch 308/500\n",
            "76/76 [==============================] - 0s 1ms/step - loss: 66935609314246656.0000 - val_loss: 27059326904434688.0000\n",
            "Epoch 309/500\n",
            "76/76 [==============================] - 0s 1ms/step - loss: 17775309491273728.0000 - val_loss: 31574958882684928.0000\n",
            "Epoch 310/500\n",
            "76/76 [==============================] - 0s 1ms/step - loss: 10072228737581056.0000 - val_loss: 125296118853533696.0000\n",
            "Epoch 311/500\n",
            "76/76 [==============================] - 0s 1ms/step - loss: 24970755175350272.0000 - val_loss: 14726700902383616.0000\n",
            "Epoch 312/500\n",
            "76/76 [==============================] - 0s 2ms/step - loss: 6838778178043904.0000 - val_loss: 6482190128906240.0000\n",
            "Epoch 313/500\n",
            "76/76 [==============================] - 0s 1ms/step - loss: 4220095815483392.0000 - val_loss: 16619520907018240.0000\n",
            "Epoch 314/500\n",
            "76/76 [==============================] - 0s 1ms/step - loss: 6625207708024832.0000 - val_loss: 41965687362551808.0000\n",
            "Epoch 315/500\n",
            "76/76 [==============================] - 0s 1ms/step - loss: 37126968616943616.0000 - val_loss: 21385481832890368.0000\n",
            "Epoch 316/500\n",
            "76/76 [==============================] - 0s 1ms/step - loss: 24506862200160256.0000 - val_loss: 124812625795088384.0000\n",
            "Epoch 317/500\n",
            "76/76 [==============================] - 0s 1ms/step - loss: 30792465233477632.0000 - val_loss: 34266625624506368.0000\n",
            "Epoch 318/500\n",
            "76/76 [==============================] - 0s 1ms/step - loss: 34303233778253824.0000 - val_loss: 11422409689137152.0000\n",
            "Epoch 319/500\n",
            "76/76 [==============================] - 0s 1ms/step - loss: 13290375791771648.0000 - val_loss: 7855765230452736.0000\n",
            "Epoch 320/500\n",
            "76/76 [==============================] - 0s 1ms/step - loss: 15387861725478912.0000 - val_loss: 86129006411251712.0000\n",
            "Epoch 321/500\n",
            "76/76 [==============================] - 0s 1ms/step - loss: 102050768005103616.0000 - val_loss: 171429187213590528.0000\n",
            "Epoch 322/500\n",
            "76/76 [==============================] - 0s 1ms/step - loss: 130922749349593088.0000 - val_loss: 27957917814620160.0000\n",
            "Epoch 323/500\n",
            "76/76 [==============================] - 0s 1ms/step - loss: 12645609932587008.0000 - val_loss: 7146239854379008.0000\n",
            "Epoch 324/500\n",
            "76/76 [==============================] - 0s 1ms/step - loss: 14939440296230912.0000 - val_loss: 32933313157005312.0000\n",
            "Epoch 325/500\n",
            "76/76 [==============================] - 0s 1ms/step - loss: 51994848315572224.0000 - val_loss: 9836192367378432.0000\n",
            "Epoch 326/500\n",
            "76/76 [==============================] - 0s 1ms/step - loss: 32394058538156032.0000 - val_loss: 6127598702690304.0000\n",
            "Epoch 327/500\n",
            "76/76 [==============================] - 0s 1ms/step - loss: 11845608922939392.0000 - val_loss: 5113231043461120.0000\n",
            "Epoch 328/500\n",
            "76/76 [==============================] - 0s 1ms/step - loss: 4403931421605888.0000 - val_loss: 5626853834358784.0000\n",
            "Epoch 329/500\n",
            "76/76 [==============================] - 0s 1ms/step - loss: 10559499219763200.0000 - val_loss: 12379401417129984.0000\n",
            "Epoch 330/500\n",
            "76/76 [==============================] - 0s 1ms/step - loss: 278217312736116736.0000 - val_loss: 20976815694675968.0000\n",
            "Epoch 331/500\n",
            "76/76 [==============================] - 0s 1ms/step - loss: 385008496275357696.0000 - val_loss: 9200652097945600.0000\n",
            "Epoch 332/500\n",
            "76/76 [==============================] - 0s 1ms/step - loss: 83566293915009024.0000 - val_loss: 63633883270217728.0000\n",
            "Epoch 333/500\n",
            "76/76 [==============================] - 0s 1ms/step - loss: 12188262487556096.0000 - val_loss: 5387314918326272.0000\n",
            "Epoch 334/500\n",
            "76/76 [==============================] - 0s 1ms/step - loss: 14217923371466752.0000 - val_loss: 9731652863393792.0000\n",
            "Epoch 335/500\n",
            "76/76 [==============================] - 0s 1ms/step - loss: 4393964681560064.0000 - val_loss: 5965931301830656.0000\n",
            "Epoch 336/500\n",
            "76/76 [==============================] - 0s 1ms/step - loss: 4538178945941504.0000 - val_loss: 11555079081426944.0000\n",
            "Epoch 337/500\n",
            "76/76 [==============================] - 0s 1ms/step - loss: 5947120955686912.0000 - val_loss: 10094890058776576.0000\n",
            "Epoch 338/500\n",
            "76/76 [==============================] - 0s 1ms/step - loss: 4173764661084160.0000 - val_loss: 24284812390957056.0000\n",
            "Epoch 339/500\n",
            "76/76 [==============================] - 0s 1ms/step - loss: 4015847840415744.0000 - val_loss: 8677418243981312.0000\n",
            "Epoch 340/500\n",
            "76/76 [==============================] - 0s 1ms/step - loss: 6160065434222592.0000 - val_loss: 10614969796132864.0000\n",
            "Epoch 341/500\n",
            "76/76 [==============================] - 0s 1ms/step - loss: 9255387161165824.0000 - val_loss: 10376355371810816.0000\n",
            "Epoch 342/500\n",
            "76/76 [==============================] - 0s 1ms/step - loss: 17303090721980416.0000 - val_loss: 11370060480249856.0000\n",
            "Epoch 343/500\n",
            "76/76 [==============================] - 0s 1ms/step - loss: 309739641089556480.0000 - val_loss: 11425396838891520.0000\n",
            "Epoch 344/500\n",
            "76/76 [==============================] - 0s 1ms/step - loss: 82120144066707456.0000 - val_loss: 27489987570171904.0000\n",
            "Epoch 345/500\n",
            "76/76 [==============================] - 0s 1ms/step - loss: 23884783431974912.0000 - val_loss: 13868040303149056.0000\n",
            "Epoch 346/500\n",
            "76/76 [==============================] - 0s 1ms/step - loss: 110291307007574016.0000 - val_loss: 33122085559599104.0000\n",
            "Epoch 347/500\n",
            "76/76 [==============================] - 0s 1ms/step - loss: 79888496239575040.0000 - val_loss: 11173934019903488.0000\n",
            "Epoch 348/500\n",
            "76/76 [==============================] - 0s 1ms/step - loss: 10395371339513856.0000 - val_loss: 14393496265818112.0000\n",
            "Epoch 349/500\n",
            "76/76 [==============================] - 0s 1ms/step - loss: 172542185038675968.0000 - val_loss: 252139972121853952.0000\n",
            "Epoch 350/500\n",
            "76/76 [==============================] - 0s 1ms/step - loss: 44513715365609472.0000 - val_loss: 13253340288778240.0000\n",
            "Epoch 351/500\n",
            "76/76 [==============================] - 0s 1ms/step - loss: 12201035720294400.0000 - val_loss: 8093790707384320.0000\n",
            "Epoch 352/500\n",
            "76/76 [==============================] - 0s 1ms/step - loss: 13646074245808128.0000 - val_loss: 4089125351194624.0000\n",
            "Epoch 353/500\n",
            "76/76 [==============================] - 0s 1ms/step - loss: 20280283668414464.0000 - val_loss: 12312807949205504.0000\n",
            "Epoch 354/500\n",
            "76/76 [==============================] - 0s 1ms/step - loss: 221328512395509760.0000 - val_loss: 793023998484021248.0000\n",
            "Epoch 355/500\n",
            "76/76 [==============================] - 0s 1ms/step - loss: 194301743490662400.0000 - val_loss: 8081378251898880.0000\n",
            "Epoch 356/500\n",
            "76/76 [==============================] - 0s 1ms/step - loss: 152806243377872896.0000 - val_loss: 4164139907809280.0000\n",
            "Epoch 357/500\n",
            "76/76 [==============================] - 0s 1ms/step - loss: 17459307272470528.0000 - val_loss: 8248248468766720.0000\n",
            "Epoch 358/500\n",
            "76/76 [==============================] - 0s 1ms/step - loss: 12821640240955392.0000 - val_loss: 14885784343543808.0000\n",
            "Epoch 359/500\n",
            "76/76 [==============================] - 0s 1ms/step - loss: 41470834115608576.0000 - val_loss: 21265714522357760.0000\n",
            "Epoch 360/500\n",
            "76/76 [==============================] - 0s 1ms/step - loss: 32757621077311488.0000 - val_loss: 6884211952713728.0000\n",
            "Epoch 361/500\n",
            "76/76 [==============================] - 0s 1ms/step - loss: 19903136147701760.0000 - val_loss: 66954386911264768.0000\n",
            "Epoch 362/500\n",
            "76/76 [==============================] - 0s 1ms/step - loss: 55772572700114944.0000 - val_loss: 32531495344144384.0000\n",
            "Epoch 363/500\n",
            "76/76 [==============================] - 0s 1ms/step - loss: 241159905409499136.0000 - val_loss: 58740236187860992.0000\n",
            "Epoch 364/500\n",
            "76/76 [==============================] - 0s 1ms/step - loss: 34124539516420096.0000 - val_loss: 18851781840732160.0000\n",
            "Epoch 365/500\n",
            "76/76 [==============================] - 0s 1ms/step - loss: 86901086912249856.0000 - val_loss: 76026315618123776.0000\n",
            "Epoch 366/500\n",
            "76/76 [==============================] - 0s 1ms/step - loss: 148851832628707328.0000 - val_loss: 31886859407720448.0000\n",
            "Epoch 367/500\n",
            "76/76 [==============================] - 0s 1ms/step - loss: 219708536630804480.0000 - val_loss: 20105139197050880.0000\n",
            "Epoch 368/500\n",
            "76/76 [==============================] - 0s 1ms/step - loss: 60953192317321216.0000 - val_loss: 37472335527149568.0000\n",
            "Epoch 369/500\n",
            "76/76 [==============================] - 0s 1ms/step - loss: 210890539275386880.0000 - val_loss: 121360554420862976.0000\n",
            "Epoch 370/500\n",
            "76/76 [==============================] - 0s 1ms/step - loss: 46378001755013120.0000 - val_loss: 25123960953765888.0000\n",
            "Epoch 371/500\n",
            "76/76 [==============================] - 0s 1ms/step - loss: 12535651253616640.0000 - val_loss: 11880431444033536.0000\n",
            "Epoch 372/500\n",
            "76/76 [==============================] - 0s 1ms/step - loss: 6584156947480576.0000 - val_loss: 14166135729553408.0000\n",
            "Epoch 373/500\n",
            "76/76 [==============================] - 0s 1ms/step - loss: 4122454565847040.0000 - val_loss: 14029906883117056.0000\n",
            "Epoch 374/500\n",
            "76/76 [==============================] - 0s 1ms/step - loss: 11005456411525120.0000 - val_loss: 10299619338616832.0000\n",
            "Epoch 375/500\n",
            "76/76 [==============================] - 0s 1ms/step - loss: 3595459394273280.0000 - val_loss: 8834981266718720.0000\n",
            "Epoch 376/500\n",
            "76/76 [==============================] - 0s 1ms/step - loss: 4076411442692096.0000 - val_loss: 5023979475566592.0000\n",
            "Epoch 377/500\n",
            "76/76 [==============================] - 0s 1ms/step - loss: 9049798887866368.0000 - val_loss: 26691316926644224.0000\n",
            "Epoch 378/500\n",
            "76/76 [==============================] - 0s 1ms/step - loss: 11776915216007168.0000 - val_loss: 33972050997542912.0000\n",
            "Epoch 379/500\n",
            "76/76 [==============================] - 0s 1ms/step - loss: 7742969725583360.0000 - val_loss: 14207035629371392.0000\n",
            "Epoch 380/500\n",
            "76/76 [==============================] - 0s 1ms/step - loss: 9374314805592064.0000 - val_loss: 19080117334573056.0000\n",
            "Epoch 381/500\n",
            "76/76 [==============================] - 0s 1ms/step - loss: 34477789839097856.0000 - val_loss: 128524027294646272.0000\n",
            "Epoch 382/500\n",
            "76/76 [==============================] - 0s 1ms/step - loss: 91815397082267648.0000 - val_loss: 15214736962486272.0000\n",
            "Epoch 383/500\n",
            "76/76 [==============================] - 0s 1ms/step - loss: 6447263454855168.0000 - val_loss: 5593866338041856.0000\n",
            "Epoch 384/500\n",
            "76/76 [==============================] - 0s 1ms/step - loss: 13768812599967744.0000 - val_loss: 8620999016710144.0000\n",
            "Epoch 385/500\n",
            "76/76 [==============================] - 0s 1ms/step - loss: 6735506763153408.0000 - val_loss: 5553793219428352.0000\n",
            "Epoch 386/500\n",
            "76/76 [==============================] - 0s 1ms/step - loss: 5144906964140032.0000 - val_loss: 27994899630522368.0000\n",
            "Epoch 387/500\n",
            "76/76 [==============================] - 0s 1ms/step - loss: 23486959938699264.0000 - val_loss: 86699652946067456.0000\n",
            "Epoch 388/500\n",
            "76/76 [==============================] - 0s 1ms/step - loss: 24172035139698688.0000 - val_loss: 11124575181996032.0000\n",
            "Epoch 389/500\n",
            "76/76 [==============================] - 0s 1ms/step - loss: 12648816125673472.0000 - val_loss: 15946894668726272.0000\n",
            "Epoch 390/500\n",
            "76/76 [==============================] - 0s 1ms/step - loss: 237853897283076096.0000 - val_loss: 35633599898189824.0000\n",
            "Epoch 391/500\n",
            "76/76 [==============================] - 0s 1ms/step - loss: 77435597467156480.0000 - val_loss: 117365135323955200.0000\n",
            "Epoch 392/500\n",
            "76/76 [==============================] - 0s 1ms/step - loss: 143884101655461888.0000 - val_loss: 37563453258334208.0000\n",
            "Epoch 393/500\n",
            "76/76 [==============================] - 0s 1ms/step - loss: 241918104576196608.0000 - val_loss: 145166389911486464.0000\n",
            "Epoch 394/500\n",
            "76/76 [==============================] - 0s 1ms/step - loss: 155898877529030656.0000 - val_loss: 6960018662359040.0000\n",
            "Epoch 395/500\n",
            "76/76 [==============================] - 0s 1ms/step - loss: 56808256818905088.0000 - val_loss: 34190389955002368.0000\n",
            "Epoch 396/500\n",
            "76/76 [==============================] - 0s 1ms/step - loss: 14604015161573376.0000 - val_loss: 6059431666122752.0000\n",
            "Epoch 397/500\n",
            "76/76 [==============================] - 0s 1ms/step - loss: 5661480397570048.0000 - val_loss: 16287927956930560.0000\n",
            "Epoch 398/500\n",
            "76/76 [==============================] - 0s 1ms/step - loss: 16850173535715328.0000 - val_loss: 6954572643827712.0000\n",
            "Epoch 399/500\n",
            "76/76 [==============================] - 0s 1ms/step - loss: 9666467071000576.0000 - val_loss: 46600498240815104.0000\n",
            "Epoch 400/500\n",
            "76/76 [==============================] - 0s 1ms/step - loss: 15290498038104064.0000 - val_loss: 10030648085446656.0000\n",
            "Epoch 401/500\n",
            "76/76 [==============================] - 0s 1ms/step - loss: 14102726979878912.0000 - val_loss: 39560870749011968.0000\n",
            "Epoch 402/500\n",
            "76/76 [==============================] - 0s 1ms/step - loss: 70427666833997824.0000 - val_loss: 17849746643222528.0000\n",
            "Epoch 403/500\n",
            "76/76 [==============================] - 0s 1ms/step - loss: 101759363064004608.0000 - val_loss: 811788263923646464.0000\n",
            "Epoch 404/500\n",
            "76/76 [==============================] - 0s 1ms/step - loss: 62563109268619264.0000 - val_loss: 18324542392893440.0000\n",
            "Epoch 405/500\n",
            "76/76 [==============================] - 0s 1ms/step - loss: 6045213713760256.0000 - val_loss: 18596188336947200.0000\n",
            "Epoch 406/500\n",
            "76/76 [==============================] - 0s 1ms/step - loss: 26842018739126272.0000 - val_loss: 39306449771298816.0000\n",
            "Epoch 407/500\n",
            "76/76 [==============================] - 0s 1ms/step - loss: 9309308328083456.0000 - val_loss: 8277136418799616.0000\n",
            "Epoch 408/500\n",
            "76/76 [==============================] - 0s 1ms/step - loss: 5242382320664576.0000 - val_loss: 6513287839612928.0000\n",
            "Epoch 409/500\n",
            "76/76 [==============================] - 0s 1ms/step - loss: 8394056166014976.0000 - val_loss: 10711160957435904.0000\n",
            "Epoch 410/500\n",
            "76/76 [==============================] - 0s 1ms/step - loss: 22973857375715328.0000 - val_loss: 63689485916831744.0000\n",
            "Epoch 411/500\n",
            "76/76 [==============================] - 0s 1ms/step - loss: 71798848028147712.0000 - val_loss: 22067116765085696.0000\n",
            "Epoch 412/500\n",
            "76/76 [==============================] - 0s 1ms/step - loss: 100990065701814272.0000 - val_loss: 13926800824467456.0000\n",
            "Epoch 413/500\n",
            "76/76 [==============================] - 0s 1ms/step - loss: 17231284237500416.0000 - val_loss: 6590444779601920.0000\n",
            "Epoch 414/500\n",
            "76/76 [==============================] - 0s 1ms/step - loss: 9398018730098688.0000 - val_loss: 20301309680812032.0000\n",
            "Epoch 415/500\n",
            "76/76 [==============================] - 0s 1ms/step - loss: 9311114361831424.0000 - val_loss: 8586356884242432.0000\n",
            "Epoch 416/500\n",
            "76/76 [==============================] - 0s 1ms/step - loss: 14004175734046720.0000 - val_loss: 10551802638368768.0000\n",
            "Epoch 417/500\n",
            "76/76 [==============================] - 0s 1ms/step - loss: 57890094656258048.0000 - val_loss: 7342191831678976.0000\n",
            "Epoch 418/500\n",
            "76/76 [==============================] - 0s 1ms/step - loss: 21134589170810880.0000 - val_loss: 6786765050347520.0000\n",
            "Epoch 419/500\n",
            "76/76 [==============================] - 0s 1ms/step - loss: 103618259269451776.0000 - val_loss: 103445970951340032.0000\n",
            "Epoch 420/500\n",
            "76/76 [==============================] - 0s 1ms/step - loss: 34573666394046464.0000 - val_loss: 9956805786468352.0000\n",
            "Epoch 421/500\n",
            "76/76 [==============================] - 0s 1ms/step - loss: 24645959011008512.0000 - val_loss: 193883740093546496.0000\n",
            "Epoch 422/500\n",
            "76/76 [==============================] - 0s 1ms/step - loss: 695516695992729600.0000 - val_loss: 448283844265639936.0000\n",
            "Epoch 423/500\n",
            "76/76 [==============================] - 0s 1ms/step - loss: 137592764840804352.0000 - val_loss: 63860378370572288.0000\n",
            "Epoch 424/500\n",
            "76/76 [==============================] - 0s 1ms/step - loss: 91962164704706560.0000 - val_loss: 3893043988004864.0000\n",
            "Epoch 425/500\n",
            "76/76 [==============================] - 0s 1ms/step - loss: 30898651857420288.0000 - val_loss: 62213812463337472.0000\n",
            "Epoch 426/500\n",
            "76/76 [==============================] - 0s 1ms/step - loss: 15299501363298304.0000 - val_loss: 6621101719289856.0000\n",
            "Epoch 427/500\n",
            "76/76 [==============================] - 0s 1ms/step - loss: 5859292095709184.0000 - val_loss: 7790499444293632.0000\n",
            "Epoch 428/500\n",
            "76/76 [==============================] - 0s 1ms/step - loss: 3902175356911616.0000 - val_loss: 5981992868904960.0000\n",
            "Epoch 429/500\n",
            "76/76 [==============================] - 0s 1ms/step - loss: 3468340978778112.0000 - val_loss: 5554938365083648.0000\n",
            "Epoch 430/500\n",
            "76/76 [==============================] - 0s 1ms/step - loss: 6135740350070784.0000 - val_loss: 17383081266642944.0000\n",
            "Epoch 431/500\n",
            "76/76 [==============================] - 0s 1ms/step - loss: 9317852091777024.0000 - val_loss: 7556842485972992.0000\n",
            "Epoch 432/500\n",
            "76/76 [==============================] - 0s 1ms/step - loss: 5994921257336832.0000 - val_loss: 5589495135076352.0000\n",
            "Epoch 433/500\n",
            "76/76 [==============================] - 0s 1ms/step - loss: 11461025740095488.0000 - val_loss: 15045612961529856.0000\n",
            "Epoch 434/500\n",
            "76/76 [==============================] - 0s 1ms/step - loss: 10321465689767936.0000 - val_loss: 31533600495108096.0000\n",
            "Epoch 435/500\n",
            "76/76 [==============================] - 0s 1ms/step - loss: 90101026526330880.0000 - val_loss: 18752787139526656.0000\n",
            "Epoch 436/500\n",
            "76/76 [==============================] - 0s 1ms/step - loss: 21225786358890496.0000 - val_loss: 69640412213542912.0000\n",
            "Epoch 437/500\n",
            "76/76 [==============================] - 0s 1ms/step - loss: 104580409253167104.0000 - val_loss: 279355668048117760.0000\n",
            "Epoch 438/500\n",
            "76/76 [==============================] - 0s 1ms/step - loss: 773934208883097600.0000 - val_loss: 90653273421250560.0000\n",
            "Epoch 439/500\n",
            "76/76 [==============================] - 0s 1ms/step - loss: 38308303666675712.0000 - val_loss: 7622978003009536.0000\n",
            "Epoch 440/500\n",
            "76/76 [==============================] - 0s 1ms/step - loss: 16112717987315712.0000 - val_loss: 40061032575533056.0000\n",
            "Epoch 441/500\n",
            "76/76 [==============================] - 0s 1ms/step - loss: 20152254988288000.0000 - val_loss: 15577760483246080.0000\n",
            "Epoch 442/500\n",
            "76/76 [==============================] - 0s 1ms/step - loss: 12445073614569472.0000 - val_loss: 9080068743626752.0000\n",
            "Epoch 443/500\n",
            "76/76 [==============================] - 0s 1ms/step - loss: 41324624838918144.0000 - val_loss: 8028937774956544.0000\n",
            "Epoch 444/500\n",
            "76/76 [==============================] - 0s 1ms/step - loss: 5067027932774400.0000 - val_loss: 9151413519122432.0000\n",
            "Epoch 445/500\n",
            "76/76 [==============================] - 0s 1ms/step - loss: 4223046458015744.0000 - val_loss: 6007575841603584.0000\n",
            "Epoch 446/500\n",
            "76/76 [==============================] - 0s 1ms/step - loss: 4054614752100352.0000 - val_loss: 13953148301344768.0000\n",
            "Epoch 447/500\n",
            "76/76 [==============================] - 0s 1ms/step - loss: 7082642663014400.0000 - val_loss: 6603592211365888.0000\n",
            "Epoch 448/500\n",
            "76/76 [==============================] - 0s 1ms/step - loss: 3375536936058880.0000 - val_loss: 9152188760719360.0000\n",
            "Epoch 449/500\n",
            "76/76 [==============================] - 0s 1ms/step - loss: 5004673060700160.0000 - val_loss: 16593522396233728.0000\n",
            "Epoch 450/500\n",
            "76/76 [==============================] - 0s 1ms/step - loss: 8724948499562496.0000 - val_loss: 5322675660521472.0000\n",
            "Epoch 451/500\n",
            "76/76 [==============================] - 0s 1ms/step - loss: 9467676657188864.0000 - val_loss: 6160214684336128.0000\n",
            "Epoch 452/500\n",
            "76/76 [==============================] - 0s 1ms/step - loss: 33042547060244480.0000 - val_loss: 8700029099311104.0000\n",
            "Epoch 453/500\n",
            "76/76 [==============================] - 0s 1ms/step - loss: 652388352393216000.0000 - val_loss: 9350075358793170944.0000\n",
            "Epoch 454/500\n",
            "76/76 [==============================] - 0s 1ms/step - loss: 1922218729358229504.0000 - val_loss: 164199125166850048.0000\n",
            "Epoch 455/500\n",
            "76/76 [==============================] - 0s 1ms/step - loss: 121519433851076608.0000 - val_loss: 55885998491435008.0000\n",
            "Epoch 456/500\n",
            "76/76 [==============================] - 0s 1ms/step - loss: 12208644254859264.0000 - val_loss: 50471311746531328.0000\n",
            "Epoch 457/500\n",
            "76/76 [==============================] - 0s 1ms/step - loss: 8803265080721408.0000 - val_loss: 6387569315020800.0000\n",
            "Epoch 458/500\n",
            "76/76 [==============================] - 0s 1ms/step - loss: 7309868444680192.0000 - val_loss: 11672231830618112.0000\n",
            "Epoch 459/500\n",
            "76/76 [==============================] - 0s 1ms/step - loss: 3830332902080512.0000 - val_loss: 8715833505218560.0000\n",
            "Epoch 460/500\n",
            "76/76 [==============================] - 0s 1ms/step - loss: 3554788201463808.0000 - val_loss: 5648540197978112.0000\n",
            "Epoch 461/500\n",
            "76/76 [==============================] - 0s 1ms/step - loss: 4050145301757952.0000 - val_loss: 6003397912166400.0000\n",
            "Epoch 462/500\n",
            "76/76 [==============================] - 0s 1ms/step - loss: 3745156452843520.0000 - val_loss: 14260520857108480.0000\n",
            "Epoch 463/500\n",
            "76/76 [==============================] - 0s 1ms/step - loss: 4090875013496832.0000 - val_loss: 5822734944698368.0000\n",
            "Epoch 464/500\n",
            "76/76 [==============================] - 0s 1ms/step - loss: 3913581179437056.0000 - val_loss: 8533723133771776.0000\n",
            "Epoch 465/500\n",
            "76/76 [==============================] - 0s 1ms/step - loss: 5369062917931008.0000 - val_loss: 5972863915917312.0000\n",
            "Epoch 466/500\n",
            "76/76 [==============================] - 0s 1ms/step - loss: 3927239712309248.0000 - val_loss: 6997845513076736.0000\n",
            "Epoch 467/500\n",
            "76/76 [==============================] - 0s 1ms/step - loss: 7855992863719424.0000 - val_loss: 27545459220283392.0000\n",
            "Epoch 468/500\n",
            "76/76 [==============================] - 0s 1ms/step - loss: 5960430522466304.0000 - val_loss: 4138472377942016.0000\n",
            "Epoch 469/500\n",
            "76/76 [==============================] - 0s 1ms/step - loss: 43078040942542848.0000 - val_loss: 23581008985063424.0000\n",
            "Epoch 470/500\n",
            "76/76 [==============================] - 0s 1ms/step - loss: 32693797863292928.0000 - val_loss: 10988227150217216.0000\n",
            "Epoch 471/500\n",
            "76/76 [==============================] - 0s 1ms/step - loss: 66843396366401536.0000 - val_loss: 102704925884022784.0000\n",
            "Epoch 472/500\n",
            "76/76 [==============================] - 0s 1ms/step - loss: 77078402217017344.0000 - val_loss: 9495493012881408.0000\n",
            "Epoch 473/500\n",
            "76/76 [==============================] - 0s 1ms/step - loss: 31614582103474176.0000 - val_loss: 7521625901629440.0000\n",
            "Epoch 474/500\n",
            "76/76 [==============================] - 0s 1ms/step - loss: 5169630943379456.0000 - val_loss: 11194561674084352.0000\n",
            "Epoch 475/500\n",
            "76/76 [==============================] - 0s 1ms/step - loss: 9301183323701248.0000 - val_loss: 20296864389660672.0000\n",
            "Epoch 476/500\n",
            "76/76 [==============================] - 0s 1ms/step - loss: 3920661701459968.0000 - val_loss: 4896602556727296.0000\n",
            "Epoch 477/500\n",
            "76/76 [==============================] - 0s 1ms/step - loss: 4390639303131136.0000 - val_loss: 19751568899309568.0000\n",
            "Epoch 478/500\n",
            "76/76 [==============================] - 0s 1ms/step - loss: 9446329595985920.0000 - val_loss: 5901259294900224.0000\n",
            "Epoch 479/500\n",
            "76/76 [==============================] - 0s 1ms/step - loss: 20617518058045440.0000 - val_loss: 87169350569558016.0000\n",
            "Epoch 480/500\n",
            "76/76 [==============================] - 0s 1ms/step - loss: 37320585742647296.0000 - val_loss: 43524034641526784.0000\n",
            "Epoch 481/500\n",
            "76/76 [==============================] - 0s 1ms/step - loss: 14939612094922752.0000 - val_loss: 18818942520786944.0000\n",
            "Epoch 482/500\n",
            "76/76 [==============================] - 0s 1ms/step - loss: 7675454987173888.0000 - val_loss: 10935117732118528.0000\n",
            "Epoch 483/500\n",
            "76/76 [==============================] - 0s 1ms/step - loss: 4852676852449280.0000 - val_loss: 9921885554868224.0000\n",
            "Epoch 484/500\n",
            "76/76 [==============================] - 0s 1ms/step - loss: 6856074011344896.0000 - val_loss: 4630658718629888.0000\n",
            "Epoch 485/500\n",
            "76/76 [==============================] - 0s 1ms/step - loss: 5908668113485824.0000 - val_loss: 21514139725725696.0000\n",
            "Epoch 486/500\n",
            "76/76 [==============================] - 0s 1ms/step - loss: 10433943367057408.0000 - val_loss: 9319116959645696.0000\n",
            "Epoch 487/500\n",
            "76/76 [==============================] - 0s 1ms/step - loss: 25226685834067968.0000 - val_loss: 26481954450833408.0000\n",
            "Epoch 488/500\n",
            "76/76 [==============================] - 0s 1ms/step - loss: 30834543028076544.0000 - val_loss: 22856037832851456.0000\n",
            "Epoch 489/500\n",
            "76/76 [==============================] - 0s 1ms/step - loss: 26018106572800000.0000 - val_loss: 13941688254857216.0000\n",
            "Epoch 490/500\n",
            "76/76 [==============================] - 0s 1ms/step - loss: 225982882554839040.0000 - val_loss: 22955947362091008.0000\n",
            "Epoch 491/500\n",
            "76/76 [==============================] - 0s 1ms/step - loss: 157150894855553024.0000 - val_loss: 63255805889085440.0000\n",
            "Epoch 492/500\n",
            "76/76 [==============================] - 0s 1ms/step - loss: 173974539452022784.0000 - val_loss: 40220865488486400.0000\n",
            "Epoch 493/500\n",
            "76/76 [==============================] - 0s 1ms/step - loss: 145095488591364096.0000 - val_loss: 36259952158834688.0000\n",
            "Epoch 494/500\n",
            "76/76 [==============================] - 0s 1ms/step - loss: 9818003180879872.0000 - val_loss: 42751485989093376.0000\n",
            "Epoch 495/500\n",
            "76/76 [==============================] - 0s 1ms/step - loss: 13042387601326080.0000 - val_loss: 6770890314350592.0000\n",
            "Epoch 496/500\n",
            "76/76 [==============================] - 0s 1ms/step - loss: 10833848845729792.0000 - val_loss: 19931888806264832.0000\n",
            "Epoch 497/500\n",
            "76/76 [==============================] - 0s 1ms/step - loss: 4969057044398080.0000 - val_loss: 6150127953641472.0000\n",
            "Epoch 498/500\n",
            "76/76 [==============================] - 0s 1ms/step - loss: 10036082292817920.0000 - val_loss: 52468583208321024.0000\n",
            "Epoch 499/500\n",
            "76/76 [==============================] - 0s 1ms/step - loss: 10157190706888704.0000 - val_loss: 12405740304072704.0000\n",
            "Epoch 500/500\n",
            "76/76 [==============================] - 0s 1ms/step - loss: 6615037762338816.0000 - val_loss: 12074906489454592.0000\n",
            "Training Set R2 is:\t0.543\n",
            "TEsting Set R2 is:\t0.646\n",
            "Epoch 1/500\n",
            "76/76 [==============================] - 0s 2ms/step - loss: 6708143530805559296.0000 - val_loss: 5346279632549183488.0000\n",
            "Epoch 2/500\n",
            "76/76 [==============================] - 0s 1ms/step - loss: 3491833700415438848.0000 - val_loss: 147278586108182528.0000\n",
            "Epoch 3/500\n",
            "76/76 [==============================] - 0s 1ms/step - loss: 635123202338586624.0000 - val_loss: 3638160556130566144.0000\n",
            "Epoch 4/500\n",
            "76/76 [==============================] - 0s 1ms/step - loss: 685046527797755904.0000 - val_loss: 455841921554710528.0000\n",
            "Epoch 5/500\n",
            "76/76 [==============================] - 0s 1ms/step - loss: 163366434087370752.0000 - val_loss: 36257100300550144.0000\n",
            "Epoch 6/500\n",
            "76/76 [==============================] - 0s 1ms/step - loss: 206336276213792768.0000 - val_loss: 40126840064442368.0000\n",
            "Epoch 7/500\n",
            "76/76 [==============================] - 0s 1ms/step - loss: 685433418451779584.0000 - val_loss: 1014545904666935296.0000\n",
            "Epoch 8/500\n",
            "76/76 [==============================] - 0s 1ms/step - loss: 523452987490697216.0000 - val_loss: 435305518249017344.0000\n",
            "Epoch 9/500\n",
            "76/76 [==============================] - 0s 1ms/step - loss: 31069641136903553024.0000 - val_loss: 108007648432157097984.0000\n",
            "Epoch 10/500\n",
            "76/76 [==============================] - 0s 1ms/step - loss: 29094421274162102272.0000 - val_loss: 2122391280825663488.0000\n",
            "Epoch 11/500\n",
            "76/76 [==============================] - 0s 1ms/step - loss: 5869289276335718400.0000 - val_loss: 14570381745124802560.0000\n",
            "Epoch 12/500\n",
            "76/76 [==============================] - 0s 1ms/step - loss: 5229457621609611264.0000 - val_loss: 1683629791372115968.0000\n",
            "Epoch 13/500\n",
            "76/76 [==============================] - 0s 1ms/step - loss: 2867968054036267008.0000 - val_loss: 2180499095964090368.0000\n",
            "Epoch 14/500\n",
            "76/76 [==============================] - 0s 1ms/step - loss: 321455074922463232.0000 - val_loss: 25319454980177920.0000\n",
            "Epoch 15/500\n",
            "76/76 [==============================] - 0s 1ms/step - loss: 9575994658652160.0000 - val_loss: 63000409953796096.0000\n",
            "Epoch 16/500\n",
            "76/76 [==============================] - 0s 1ms/step - loss: 10839772679372800.0000 - val_loss: 19880701386031104.0000\n",
            "Epoch 17/500\n",
            "76/76 [==============================] - 0s 1ms/step - loss: 4301128695021568.0000 - val_loss: 8434053048958976.0000\n",
            "Epoch 18/500\n",
            "76/76 [==============================] - 0s 1ms/step - loss: 11786266433552384.0000 - val_loss: 83505047681368064.0000\n",
            "Epoch 19/500\n",
            "76/76 [==============================] - 0s 1ms/step - loss: 99517166797193216.0000 - val_loss: 8690008403738624.0000\n",
            "Epoch 20/500\n",
            "76/76 [==============================] - 0s 1ms/step - loss: 24607800374067200.0000 - val_loss: 6324963187359744.0000\n",
            "Epoch 21/500\n",
            "76/76 [==============================] - 0s 1ms/step - loss: 13342686345953280.0000 - val_loss: 11941122553151488.0000\n",
            "Epoch 22/500\n",
            "76/76 [==============================] - 0s 1ms/step - loss: 6711982690402304.0000 - val_loss: 7537663846383616.0000\n",
            "Epoch 23/500\n",
            "76/76 [==============================] - 0s 1ms/step - loss: 5060320267599872.0000 - val_loss: 17918523028275200.0000\n",
            "Epoch 24/500\n",
            "76/76 [==============================] - 0s 1ms/step - loss: 14395615832178688.0000 - val_loss: 36742118072385536.0000\n",
            "Epoch 25/500\n",
            "76/76 [==============================] - 0s 1ms/step - loss: 56358728361836544.0000 - val_loss: 12221710619115520.0000\n",
            "Epoch 26/500\n",
            "76/76 [==============================] - 0s 1ms/step - loss: 57931090119098368.0000 - val_loss: 40887324153741312.0000\n",
            "Epoch 27/500\n",
            "76/76 [==============================] - 0s 1ms/step - loss: 100473003178983424.0000 - val_loss: 18061110573793280.0000\n",
            "Epoch 28/500\n",
            "76/76 [==============================] - 0s 1ms/step - loss: 29763627292557312.0000 - val_loss: 180506033658003456.0000\n",
            "Epoch 29/500\n",
            "76/76 [==============================] - 0s 1ms/step - loss: 33887775149260800.0000 - val_loss: 67764168635187200.0000\n",
            "Epoch 30/500\n",
            "76/76 [==============================] - 0s 1ms/step - loss: 17784765935517696.0000 - val_loss: 6178622377295872.0000\n",
            "Epoch 31/500\n",
            "76/76 [==============================] - 0s 1ms/step - loss: 50829666637840384.0000 - val_loss: 6217929917988864.0000\n",
            "Epoch 32/500\n",
            "76/76 [==============================] - 0s 1ms/step - loss: 174712724071120896.0000 - val_loss: 384564396656951296.0000\n",
            "Epoch 33/500\n",
            "76/76 [==============================] - 0s 1ms/step - loss: 123007339371429888.0000 - val_loss: 478675994924810240.0000\n",
            "Epoch 34/500\n",
            "76/76 [==============================] - 0s 1ms/step - loss: 385013581516636160.0000 - val_loss: 228254456397955072.0000\n",
            "Epoch 35/500\n",
            "76/76 [==============================] - 0s 1ms/step - loss: 376648325253824512.0000 - val_loss: 688782049833648128.0000\n",
            "Epoch 36/500\n",
            "76/76 [==============================] - 0s 1ms/step - loss: 859907977996402688.0000 - val_loss: 52241452452806656.0000\n",
            "Epoch 37/500\n",
            "76/76 [==============================] - 0s 1ms/step - loss: 2133881452213829632.0000 - val_loss: 531374968768823296.0000\n",
            "Epoch 38/500\n",
            "76/76 [==============================] - 0s 1ms/step - loss: 9970051482789085184.0000 - val_loss: 3278726906475708416.0000\n",
            "Epoch 39/500\n",
            "76/76 [==============================] - 0s 1ms/step - loss: 3972840350753488896.0000 - val_loss: 18383718967693803520.0000\n",
            "Epoch 40/500\n",
            "76/76 [==============================] - 0s 1ms/step - loss: 5722763958771777536.0000 - val_loss: 241322598770671616.0000\n",
            "Epoch 41/500\n",
            "76/76 [==============================] - 0s 1ms/step - loss: 7376334339191078912.0000 - val_loss: 107146540543377408.0000\n",
            "Epoch 42/500\n",
            "76/76 [==============================] - 0s 1ms/step - loss: 6875753633099546624.0000 - val_loss: 7378946229062860800.0000\n",
            "Epoch 43/500\n",
            "76/76 [==============================] - 0s 1ms/step - loss: 6331892850803867648.0000 - val_loss: 8467302211863445504.0000\n",
            "Epoch 44/500\n",
            "76/76 [==============================] - 0s 1ms/step - loss: 6689148917679915008.0000 - val_loss: 1832716146395054080.0000\n",
            "Epoch 45/500\n",
            "76/76 [==============================] - 0s 1ms/step - loss: 644758841208078336.0000 - val_loss: 394182443340398592.0000\n",
            "Epoch 46/500\n",
            "76/76 [==============================] - 0s 1ms/step - loss: 15118350852617666560.0000 - val_loss: 263693956141239238656.0000\n",
            "Epoch 47/500\n",
            "76/76 [==============================] - 0s 1ms/step - loss: 23280085039226814464.0000 - val_loss: 5331896920946245632.0000\n",
            "Epoch 48/500\n",
            "76/76 [==============================] - 0s 1ms/step - loss: 9302865628031352832.0000 - val_loss: 91823170973073408.0000\n",
            "Epoch 49/500\n",
            "76/76 [==============================] - 0s 1ms/step - loss: 2756948440834375680.0000 - val_loss: 2456077804131844096.0000\n",
            "Epoch 50/500\n",
            "76/76 [==============================] - 0s 1ms/step - loss: 1707437241770442752.0000 - val_loss: 1909739134944018432.0000\n",
            "Epoch 51/500\n",
            "76/76 [==============================] - 0s 1ms/step - loss: 5214181556809105408.0000 - val_loss: 2406013466306412544.0000\n",
            "Epoch 52/500\n",
            "76/76 [==============================] - 0s 1ms/step - loss: 943860913457332224.0000 - val_loss: 409425832029716480.0000\n",
            "Epoch 53/500\n",
            "76/76 [==============================] - 0s 1ms/step - loss: 383930047167201280.0000 - val_loss: 12942307347136512.0000\n",
            "Epoch 54/500\n",
            "76/76 [==============================] - 0s 1ms/step - loss: 560430937922338816.0000 - val_loss: 19234691060072448.0000\n",
            "Epoch 55/500\n",
            "76/76 [==============================] - 0s 1ms/step - loss: 643041885081829376.0000 - val_loss: 175778064939089920.0000\n",
            "Epoch 56/500\n",
            "76/76 [==============================] - 0s 1ms/step - loss: 227387697637883904.0000 - val_loss: 74331040486785024.0000\n",
            "Epoch 57/500\n",
            "76/76 [==============================] - 0s 1ms/step - loss: 111247375317598208.0000 - val_loss: 326326289390632960.0000\n",
            "Epoch 58/500\n",
            "76/76 [==============================] - 0s 1ms/step - loss: 795330361562234880.0000 - val_loss: 510484831956631552.0000\n",
            "Epoch 59/500\n",
            "76/76 [==============================] - 0s 1ms/step - loss: 459198180798496768.0000 - val_loss: 18238122737455333376.0000\n",
            "Epoch 60/500\n",
            "76/76 [==============================] - 0s 1ms/step - loss: 1425524384554024960.0000 - val_loss: 6067580700846981120.0000\n",
            "Epoch 61/500\n",
            "76/76 [==============================] - 0s 1ms/step - loss: 2585502967104798720.0000 - val_loss: 7530889390172667904.0000\n",
            "Epoch 62/500\n",
            "76/76 [==============================] - 0s 1ms/step - loss: 14213336234725474304.0000 - val_loss: 133647934136451596288.0000\n",
            "Epoch 63/500\n",
            "76/76 [==============================] - 0s 1ms/step - loss: 25872124328080834560.0000 - val_loss: 5644212649060204544.0000\n",
            "Epoch 64/500\n",
            "76/76 [==============================] - 0s 1ms/step - loss: 28866046112003260416.0000 - val_loss: 6059922602359521280.0000\n",
            "Epoch 65/500\n",
            "76/76 [==============================] - 0s 1ms/step - loss: 11744579687135838208.0000 - val_loss: 1648574611899547648.0000\n",
            "Epoch 66/500\n",
            "76/76 [==============================] - 0s 1ms/step - loss: 5640510593409482752.0000 - val_loss: 336478526926487552.0000\n",
            "Epoch 67/500\n",
            "76/76 [==============================] - 0s 1ms/step - loss: 348864662852337664.0000 - val_loss: 1630118347154653184.0000\n",
            "Epoch 68/500\n",
            "76/76 [==============================] - 0s 1ms/step - loss: 533713286403719168.0000 - val_loss: 52513268048068608.0000\n",
            "Epoch 69/500\n",
            "76/76 [==============================] - 0s 1ms/step - loss: 245962245782110208.0000 - val_loss: 147629811353780224.0000\n",
            "Epoch 70/500\n",
            "76/76 [==============================] - 0s 1ms/step - loss: 77820125889167360.0000 - val_loss: 7171125431762944.0000\n",
            "Epoch 71/500\n",
            "76/76 [==============================] - 0s 2ms/step - loss: 12843178428203008.0000 - val_loss: 85153035222777856.0000\n",
            "Epoch 72/500\n",
            "76/76 [==============================] - 0s 1ms/step - loss: 11364983828905984.0000 - val_loss: 10673082851131392.0000\n",
            "Epoch 73/500\n",
            "76/76 [==============================] - 0s 1ms/step - loss: 7253794962276352.0000 - val_loss: 5536530672123904.0000\n",
            "Epoch 74/500\n",
            "76/76 [==============================] - 0s 1ms/step - loss: 4212511171674112.0000 - val_loss: 6031802678378496.0000\n",
            "Epoch 75/500\n",
            "76/76 [==============================] - 0s 1ms/step - loss: 49885808919838720.0000 - val_loss: 75375842821144576.0000\n",
            "Epoch 76/500\n",
            "76/76 [==============================] - 0s 1ms/step - loss: 1428417199646703616.0000 - val_loss: 342757184997687296.0000\n",
            "Epoch 77/500\n",
            "76/76 [==============================] - 0s 1ms/step - loss: 18938119273316352.0000 - val_loss: 16251989818081280.0000\n",
            "Epoch 78/500\n",
            "76/76 [==============================] - 0s 1ms/step - loss: 5628259899277312.0000 - val_loss: 9759882609688576.0000\n",
            "Epoch 79/500\n",
            "76/76 [==============================] - 0s 1ms/step - loss: 9844429040910336.0000 - val_loss: 7581802688413696.0000\n",
            "Epoch 80/500\n",
            "76/76 [==============================] - 0s 1ms/step - loss: 6992191188631552.0000 - val_loss: 25231466132668416.0000\n",
            "Epoch 81/500\n",
            "76/76 [==============================] - 0s 1ms/step - loss: 41535610812366848.0000 - val_loss: 17404076140527616.0000\n",
            "Epoch 82/500\n",
            "76/76 [==============================] - 0s 1ms/step - loss: 147287072963559424.0000 - val_loss: 70893649310777344.0000\n",
            "Epoch 83/500\n",
            "76/76 [==============================] - 0s 1ms/step - loss: 23814369590640640.0000 - val_loss: 9772152257511424.0000\n",
            "Epoch 84/500\n",
            "76/76 [==============================] - 0s 1ms/step - loss: 11765883592507392.0000 - val_loss: 10397250387705856.0000\n",
            "Epoch 85/500\n",
            "76/76 [==============================] - 0s 1ms/step - loss: 583585175334551552.0000 - val_loss: 2601369194771513344.0000\n",
            "Epoch 86/500\n",
            "76/76 [==============================] - 0s 1ms/step - loss: 5630500089794396160.0000 - val_loss: 13679801515882053632.0000\n",
            "Epoch 87/500\n",
            "76/76 [==============================] - 0s 1ms/step - loss: 7724246756254285824.0000 - val_loss: 1203312947141541888.0000\n",
            "Epoch 88/500\n",
            "76/76 [==============================] - 0s 1ms/step - loss: 61254232588052070400.0000 - val_loss: 279185265736045035520.0000\n",
            "Epoch 89/500\n",
            "76/76 [==============================] - 0s 1ms/step - loss: 46452088085443248128.0000 - val_loss: 413813879856955392.0000\n",
            "Epoch 90/500\n",
            "76/76 [==============================] - 0s 1ms/step - loss: 11418168769709604864.0000 - val_loss: 30588563808583680.0000\n",
            "Epoch 91/500\n",
            "76/76 [==============================] - 0s 1ms/step - loss: 2185850281617522688.0000 - val_loss: 5385084696428281856.0000\n",
            "Epoch 92/500\n",
            "76/76 [==============================] - 0s 1ms/step - loss: 2987000083347668992.0000 - val_loss: 138741934880456704.0000\n",
            "Epoch 93/500\n",
            "76/76 [==============================] - 0s 1ms/step - loss: 255189570700705792.0000 - val_loss: 889475701093171200.0000\n",
            "Epoch 94/500\n",
            "76/76 [==============================] - 0s 1ms/step - loss: 1626407495410909184.0000 - val_loss: 14623837509386240.0000\n",
            "Epoch 95/500\n",
            "76/76 [==============================] - 0s 1ms/step - loss: 991689119509774336.0000 - val_loss: 9841630723688103936.0000\n",
            "Epoch 96/500\n",
            "76/76 [==============================] - 0s 1ms/step - loss: 1174470970438582272.0000 - val_loss: 6422937296961536.0000\n",
            "Epoch 97/500\n",
            "76/76 [==============================] - 0s 1ms/step - loss: 124014741130575872.0000 - val_loss: 14759185887526912.0000\n",
            "Epoch 98/500\n",
            "76/76 [==============================] - 0s 1ms/step - loss: 22908322617229312.0000 - val_loss: 38341499468906496.0000\n",
            "Epoch 99/500\n",
            "76/76 [==============================] - 0s 1ms/step - loss: 145736589769703424.0000 - val_loss: 562576359986036736.0000\n",
            "Epoch 100/500\n",
            "76/76 [==============================] - 0s 1ms/step - loss: 76912968666710016.0000 - val_loss: 55795739753709568.0000\n",
            "Epoch 101/500\n",
            "76/76 [==============================] - 0s 1ms/step - loss: 442207977370288128.0000 - val_loss: 119635059899629568.0000\n",
            "Epoch 102/500\n",
            "76/76 [==============================] - 0s 1ms/step - loss: 190427614270193664.0000 - val_loss: 973758421322956800.0000\n",
            "Epoch 103/500\n",
            "76/76 [==============================] - 0s 1ms/step - loss: 667922183950958592.0000 - val_loss: 558548264777940992.0000\n",
            "Epoch 104/500\n",
            "76/76 [==============================] - 0s 1ms/step - loss: 824397944307318784.0000 - val_loss: 322132442804649984.0000\n",
            "Epoch 105/500\n",
            "76/76 [==============================] - 0s 1ms/step - loss: 585914765595901952.0000 - val_loss: 18378240221511680.0000\n",
            "Epoch 106/500\n",
            "76/76 [==============================] - 0s 1ms/step - loss: 12468002263119429632.0000 - val_loss: 86280823678280138752.0000\n",
            "Epoch 107/500\n",
            "76/76 [==============================] - 0s 1ms/step - loss: 82590158968022106112.0000 - val_loss: 86803839369380626432.0000\n",
            "Epoch 108/500\n",
            "76/76 [==============================] - 0s 1ms/step - loss: 87924004223572770816.0000 - val_loss: 23669331946668818432.0000\n",
            "Epoch 109/500\n",
            "76/76 [==============================] - 0s 1ms/step - loss: 9620416680760967168.0000 - val_loss: 777350322791120896.0000\n",
            "Epoch 110/500\n",
            "76/76 [==============================] - 0s 1ms/step - loss: 1182977479585824768.0000 - val_loss: 168515086262992896.0000\n",
            "Epoch 111/500\n",
            "76/76 [==============================] - 0s 1ms/step - loss: 203558514705039360.0000 - val_loss: 10246158806941696.0000\n",
            "Epoch 112/500\n",
            "76/76 [==============================] - 0s 1ms/step - loss: 15488475629355008.0000 - val_loss: 19359839964626944.0000\n",
            "Epoch 113/500\n",
            "76/76 [==============================] - 0s 1ms/step - loss: 10818190468710400.0000 - val_loss: 9437421833814016.0000\n",
            "Epoch 114/500\n",
            "76/76 [==============================] - 0s 1ms/step - loss: 4294390428205056.0000 - val_loss: 9350985616982016.0000\n",
            "Epoch 115/500\n",
            "76/76 [==============================] - 0s 1ms/step - loss: 4328811369857024.0000 - val_loss: 9751721098084352.0000\n",
            "Epoch 116/500\n",
            "76/76 [==============================] - 0s 1ms/step - loss: 6882519735599104.0000 - val_loss: 6092722494504960.0000\n",
            "Epoch 117/500\n",
            "76/76 [==============================] - 0s 1ms/step - loss: 4893031828291584.0000 - val_loss: 11006387345686528.0000\n",
            "Epoch 118/500\n",
            "76/76 [==============================] - 0s 1ms/step - loss: 4987657474015232.0000 - val_loss: 14892810910040064.0000\n",
            "Epoch 119/500\n",
            "76/76 [==============================] - 0s 1ms/step - loss: 4636869241339904.0000 - val_loss: 7589675363467264.0000\n",
            "Epoch 120/500\n",
            "76/76 [==============================] - 0s 1ms/step - loss: 6543337041428480.0000 - val_loss: 5247231338741760.0000\n",
            "Epoch 121/500\n",
            "76/76 [==============================] - 0s 1ms/step - loss: 14883955761217536.0000 - val_loss: 9470991298199552.0000\n",
            "Epoch 122/500\n",
            "76/76 [==============================] - 0s 1ms/step - loss: 19050986718887936.0000 - val_loss: 40048259342794752.0000\n",
            "Epoch 123/500\n",
            "76/76 [==============================] - 0s 1ms/step - loss: 15341441718943744.0000 - val_loss: 44673793091698688.0000\n",
            "Epoch 124/500\n",
            "76/76 [==============================] - 0s 1ms/step - loss: 19737820708995072.0000 - val_loss: 38593661293821952.0000\n",
            "Epoch 125/500\n",
            "76/76 [==============================] - 0s 1ms/step - loss: 10745709674364928.0000 - val_loss: 9298038333898752.0000\n",
            "Epoch 126/500\n",
            "76/76 [==============================] - 0s 1ms/step - loss: 5928307388317696.0000 - val_loss: 11373130308124672.0000\n",
            "Epoch 127/500\n",
            "76/76 [==============================] - 0s 1ms/step - loss: 11472210908676096.0000 - val_loss: 8166044942204928.0000\n",
            "Epoch 128/500\n",
            "76/76 [==============================] - 0s 1ms/step - loss: 44012612941250560.0000 - val_loss: 304456865675214848.0000\n",
            "Epoch 129/500\n",
            "76/76 [==============================] - 0s 1ms/step - loss: 81381478411272192.0000 - val_loss: 35813533258088448.0000\n",
            "Epoch 130/500\n",
            "76/76 [==============================] - 0s 1ms/step - loss: 51054576895262720.0000 - val_loss: 168706487185571840.0000\n",
            "Epoch 131/500\n",
            "76/76 [==============================] - 0s 1ms/step - loss: 561191628170067968.0000 - val_loss: 922579041268006912.0000\n",
            "Epoch 132/500\n",
            "76/76 [==============================] - 0s 1ms/step - loss: 462712975875112960.0000 - val_loss: 462016469618655232.0000\n",
            "Epoch 133/500\n",
            "76/76 [==============================] - 0s 1ms/step - loss: 1017138278207324160.0000 - val_loss: 2761359406607106048.0000\n",
            "Epoch 134/500\n",
            "76/76 [==============================] - 0s 1ms/step - loss: 13594746594892185600.0000 - val_loss: 2252106852307304448.0000\n",
            "Epoch 135/500\n",
            "76/76 [==============================] - 0s 1ms/step - loss: 60003173073596448768.0000 - val_loss: 28932254304181420032.0000\n",
            "Epoch 136/500\n",
            "76/76 [==============================] - 0s 1ms/step - loss: 18185701321577857024.0000 - val_loss: 7352682194810175488.0000\n",
            "Epoch 137/500\n",
            "76/76 [==============================] - 0s 1ms/step - loss: 4373378967734845440.0000 - val_loss: 887673738974199808.0000\n",
            "Epoch 138/500\n",
            "76/76 [==============================] - 0s 1ms/step - loss: 794523938502737920.0000 - val_loss: 1564149023877627904.0000\n",
            "Epoch 139/500\n",
            "76/76 [==============================] - 0s 1ms/step - loss: 966866751159533568.0000 - val_loss: 46510969647529984.0000\n",
            "Epoch 140/500\n",
            "76/76 [==============================] - 0s 1ms/step - loss: 179188595389628416.0000 - val_loss: 4025264287776768.0000\n",
            "Epoch 141/500\n",
            "76/76 [==============================] - 0s 1ms/step - loss: 55613104859381760.0000 - val_loss: 142919391871238144.0000\n",
            "Epoch 142/500\n",
            "76/76 [==============================] - 0s 1ms/step - loss: 61765366338027520.0000 - val_loss: 115488380644491264.0000\n",
            "Epoch 143/500\n",
            "76/76 [==============================] - 0s 1ms/step - loss: 47124845028179968.0000 - val_loss: 63312417853014016.0000\n",
            "Epoch 144/500\n",
            "76/76 [==============================] - 0s 1ms/step - loss: 7128772222386176.0000 - val_loss: 10357752794710016.0000\n",
            "Epoch 145/500\n",
            "76/76 [==============================] - 0s 1ms/step - loss: 4939536123559936.0000 - val_loss: 7965897855598592.0000\n",
            "Epoch 146/500\n",
            "76/76 [==============================] - 0s 1ms/step - loss: 7341279151128576.0000 - val_loss: 44320927168593920.0000\n",
            "Epoch 147/500\n",
            "76/76 [==============================] - 0s 1ms/step - loss: 34934656247791616.0000 - val_loss: 1467304726897885184.0000\n",
            "Epoch 148/500\n",
            "76/76 [==============================] - 0s 1ms/step - loss: 316733222236979200.0000 - val_loss: 72261802552983552.0000\n",
            "Epoch 149/500\n",
            "76/76 [==============================] - 0s 1ms/step - loss: 279538650834796544.0000 - val_loss: 8449764039327744.0000\n",
            "Epoch 150/500\n",
            "76/76 [==============================] - 0s 1ms/step - loss: 1498367442211045376.0000 - val_loss: 2354220971080024064.0000\n",
            "Epoch 151/500\n",
            "76/76 [==============================] - 0s 1ms/step - loss: 801684851576012800.0000 - val_loss: 62422711082680320.0000\n",
            "Epoch 152/500\n",
            "76/76 [==============================] - 0s 1ms/step - loss: 2557450577189535744.0000 - val_loss: 1111230222704836608.0000\n",
            "Epoch 153/500\n",
            "76/76 [==============================] - 0s 1ms/step - loss: 344305606607241216.0000 - val_loss: 191845228355780608.0000\n",
            "Epoch 154/500\n",
            "76/76 [==============================] - 0s 1ms/step - loss: 293970342244777984.0000 - val_loss: 4606143582175232.0000\n",
            "Epoch 155/500\n",
            "76/76 [==============================] - 0s 1ms/step - loss: 41572384322355200.0000 - val_loss: 33141322718117888.0000\n",
            "Epoch 156/500\n",
            "76/76 [==============================] - 0s 1ms/step - loss: 101034467073720320.0000 - val_loss: 8291812858920960.0000\n",
            "Epoch 157/500\n",
            "76/76 [==============================] - 0s 1ms/step - loss: 87530437060067328.0000 - val_loss: 8105546032873472.0000\n",
            "Epoch 158/500\n",
            "76/76 [==============================] - 0s 1ms/step - loss: 143112837198249984.0000 - val_loss: 48409469746413568.0000\n",
            "Epoch 159/500\n",
            "76/76 [==============================] - 0s 1ms/step - loss: 868393733861670912.0000 - val_loss: 1661738239985188864.0000\n",
            "Epoch 160/500\n",
            "76/76 [==============================] - 0s 1ms/step - loss: 12468939047026294784.0000 - val_loss: 18067399367987298304.0000\n",
            "Epoch 161/500\n",
            "76/76 [==============================] - 0s 1ms/step - loss: 11463749024239058944.0000 - val_loss: 1950450889424633856.0000\n",
            "Epoch 162/500\n",
            "76/76 [==============================] - 0s 1ms/step - loss: 7691421386362847232.0000 - val_loss: 5417549976261623808.0000\n",
            "Epoch 163/500\n",
            "76/76 [==============================] - 0s 1ms/step - loss: 5812489605156438016.0000 - val_loss: 3395161614444396544.0000\n",
            "Epoch 164/500\n",
            "76/76 [==============================] - 0s 1ms/step - loss: 2120285303741612032.0000 - val_loss: 16661894753712865280.0000\n",
            "Epoch 165/500\n",
            "76/76 [==============================] - 0s 1ms/step - loss: 124700196470540730368.0000 - val_loss: 27340124083766427648.0000\n",
            "Epoch 166/500\n",
            "76/76 [==============================] - 0s 1ms/step - loss: 4100380950796435456.0000 - val_loss: 358189517888290816.0000\n",
            "Epoch 167/500\n",
            "76/76 [==============================] - 0s 1ms/step - loss: 197147382662561792.0000 - val_loss: 42683621210849280.0000\n",
            "Epoch 168/500\n",
            "76/76 [==============================] - 0s 1ms/step - loss: 699855849912270848.0000 - val_loss: 19025766670925824.0000\n",
            "Epoch 169/500\n",
            "76/76 [==============================] - 0s 1ms/step - loss: 470429726435966976.0000 - val_loss: 104403104413253632.0000\n",
            "Epoch 170/500\n",
            "76/76 [==============================] - 0s 1ms/step - loss: 620624148661534720.0000 - val_loss: 361903943044825088.0000\n",
            "Epoch 171/500\n",
            "76/76 [==============================] - 0s 1ms/step - loss: 1276084261664849920.0000 - val_loss: 62967085302546432.0000\n",
            "Epoch 172/500\n",
            "76/76 [==============================] - 0s 1ms/step - loss: 623032628882178048.0000 - val_loss: 3247934533584027648.0000\n",
            "Epoch 173/500\n",
            "76/76 [==============================] - 0s 1ms/step - loss: 1292800136941928448.0000 - val_loss: 80221983270240256.0000\n",
            "Epoch 174/500\n",
            "76/76 [==============================] - 0s 2ms/step - loss: 184381417008922624.0000 - val_loss: 139873779022036992.0000\n",
            "Epoch 175/500\n",
            "76/76 [==============================] - 0s 1ms/step - loss: 834315333031428096.0000 - val_loss: 1266447592003207168.0000\n",
            "Epoch 176/500\n",
            "76/76 [==============================] - 0s 1ms/step - loss: 775096598832087040.0000 - val_loss: 131685604260839424.0000\n",
            "Epoch 177/500\n",
            "76/76 [==============================] - 0s 1ms/step - loss: 440100935134347264.0000 - val_loss: 17404316658696192.0000\n",
            "Epoch 178/500\n",
            "76/76 [==============================] - 0s 1ms/step - loss: 48713918503190528.0000 - val_loss: 26731474870861824.0000\n",
            "Epoch 179/500\n",
            "76/76 [==============================] - 0s 1ms/step - loss: 159307672812781568.0000 - val_loss: 25247707551498240.0000\n",
            "Epoch 180/500\n",
            "76/76 [==============================] - 0s 1ms/step - loss: 55741112064671744.0000 - val_loss: 164087799614537728.0000\n",
            "Epoch 181/500\n",
            "76/76 [==============================] - 0s 1ms/step - loss: 796626823210336256.0000 - val_loss: 514317660771581952.0000\n",
            "Epoch 182/500\n",
            "76/76 [==============================] - 0s 1ms/step - loss: 921969774387265536.0000 - val_loss: 6706984645549883392.0000\n",
            "Epoch 183/500\n",
            "76/76 [==============================] - 0s 1ms/step - loss: 2634557403500118016.0000 - val_loss: 4335623387704459264.0000\n",
            "Epoch 184/500\n",
            "76/76 [==============================] - 0s 1ms/step - loss: 327802108873015296.0000 - val_loss: 1515618367333990400.0000\n",
            "Epoch 185/500\n",
            "76/76 [==============================] - 0s 1ms/step - loss: 1257703313466458112.0000 - val_loss: 5483870318625816576.0000\n",
            "Epoch 186/500\n",
            "76/76 [==============================] - 0s 1ms/step - loss: 3606511113925033984.0000 - val_loss: 5229088185702678528.0000\n",
            "Epoch 187/500\n",
            "76/76 [==============================] - 0s 1ms/step - loss: 217833474168455168.0000 - val_loss: 8333782742466560.0000\n",
            "Epoch 188/500\n",
            "76/76 [==============================] - 0s 1ms/step - loss: 56129046395748352.0000 - val_loss: 26872890964049920.0000\n",
            "Epoch 189/500\n",
            "76/76 [==============================] - 0s 1ms/step - loss: 64597119880658944.0000 - val_loss: 12161418941956096.0000\n",
            "Epoch 190/500\n",
            "76/76 [==============================] - 0s 1ms/step - loss: 785434482034343936.0000 - val_loss: 553448867287269376.0000\n",
            "Epoch 191/500\n",
            "76/76 [==============================] - 0s 1ms/step - loss: 86777649552162816.0000 - val_loss: 44719727766929408.0000\n",
            "Epoch 192/500\n",
            "76/76 [==============================] - 0s 1ms/step - loss: 2425443486036656128.0000 - val_loss: 241976928448282624.0000\n",
            "Epoch 193/500\n",
            "76/76 [==============================] - 0s 1ms/step - loss: 44721241279044780032.0000 - val_loss: 240907360507860615168.0000\n",
            "Epoch 194/500\n",
            "76/76 [==============================] - 0s 1ms/step - loss: 54081700425650667520.0000 - val_loss: 85159172284367241216.0000\n",
            "Epoch 195/500\n",
            "76/76 [==============================] - 0s 1ms/step - loss: 6434036381512630272.0000 - val_loss: 5564721256906883072.0000\n",
            "Epoch 196/500\n",
            "76/76 [==============================] - 0s 1ms/step - loss: 1888737775658729472.0000 - val_loss: 67348080793485312.0000\n",
            "Epoch 197/500\n",
            "76/76 [==============================] - 0s 1ms/step - loss: 246854808705695744.0000 - val_loss: 2075517038549270528.0000\n",
            "Epoch 198/500\n",
            "76/76 [==============================] - 0s 1ms/step - loss: 3957086273272807424.0000 - val_loss: 15243634705044602880.0000\n",
            "Epoch 199/500\n",
            "76/76 [==============================] - 0s 1ms/step - loss: 7273830168668405760.0000 - val_loss: 3315473684587610112.0000\n",
            "Epoch 200/500\n",
            "76/76 [==============================] - 0s 1ms/step - loss: 1971200323108208640.0000 - val_loss: 29618131856611344384.0000\n",
            "Epoch 201/500\n",
            "76/76 [==============================] - 0s 1ms/step - loss: 9249456850712133632.0000 - val_loss: 4786108694767075328.0000\n",
            "Epoch 202/500\n",
            "76/76 [==============================] - 0s 1ms/step - loss: 8438281701959925760.0000 - val_loss: 18520222236770566144.0000\n",
            "Epoch 203/500\n",
            "76/76 [==============================] - 0s 1ms/step - loss: 21413835574890987520.0000 - val_loss: 1235635290463272960.0000\n",
            "Epoch 204/500\n",
            "76/76 [==============================] - 0s 1ms/step - loss: 4830644413250142208.0000 - val_loss: 35082016352379076608.0000\n",
            "Epoch 205/500\n",
            "76/76 [==============================] - 0s 1ms/step - loss: 13313606969228001280.0000 - val_loss: 3065288609780203520.0000\n",
            "Epoch 206/500\n",
            "76/76 [==============================] - 0s 1ms/step - loss: 3500141060519100416.0000 - val_loss: 812239407288418304.0000\n",
            "Epoch 207/500\n",
            "76/76 [==============================] - 0s 1ms/step - loss: 156244038280806400.0000 - val_loss: 1268180422328582144.0000\n",
            "Epoch 208/500\n",
            "76/76 [==============================] - 0s 1ms/step - loss: 239158313210609664.0000 - val_loss: 132220971934285824.0000\n",
            "Epoch 209/500\n",
            "76/76 [==============================] - 0s 1ms/step - loss: 15990278133383168.0000 - val_loss: 71093966585462784.0000\n",
            "Epoch 210/500\n",
            "76/76 [==============================] - 0s 1ms/step - loss: 9479863626891264.0000 - val_loss: 19443654103924736.0000\n",
            "Epoch 211/500\n",
            "76/76 [==============================] - 0s 1ms/step - loss: 5684489611116544.0000 - val_loss: 8244263812857856.0000\n",
            "Epoch 212/500\n",
            "76/76 [==============================] - 0s 1ms/step - loss: 22442825471754240.0000 - val_loss: 13024900641980416.0000\n",
            "Epoch 213/500\n",
            "76/76 [==============================] - 0s 1ms/step - loss: 53198508605308928.0000 - val_loss: 20693940558626816.0000\n",
            "Epoch 214/500\n",
            "76/76 [==============================] - 0s 1ms/step - loss: 7781799988035584.0000 - val_loss: 46897138747047936.0000\n",
            "Epoch 215/500\n",
            "76/76 [==============================] - 0s 1ms/step - loss: 34108160658636800.0000 - val_loss: 7187064055398400.0000\n",
            "Epoch 216/500\n",
            "76/76 [==============================] - 0s 1ms/step - loss: 53161455922446336.0000 - val_loss: 470514663709212672.0000\n",
            "Epoch 217/500\n",
            "76/76 [==============================] - 0s 1ms/step - loss: 2072074330203750400.0000 - val_loss: 1170574163790790656.0000\n",
            "Epoch 218/500\n",
            "76/76 [==============================] - 0s 1ms/step - loss: 46525443103201951744.0000 - val_loss: 51390223504203841536.0000\n",
            "Epoch 219/500\n",
            "76/76 [==============================] - 0s 1ms/step - loss: 7732777317218385920.0000 - val_loss: 2137913773669744640.0000\n",
            "Epoch 220/500\n",
            "76/76 [==============================] - 0s 1ms/step - loss: 1310289793527054336.0000 - val_loss: 7200245902735310848.0000\n",
            "Epoch 221/500\n",
            "76/76 [==============================] - 0s 1ms/step - loss: 4737226606819409920.0000 - val_loss: 1967810253881868288.0000\n",
            "Epoch 222/500\n",
            "76/76 [==============================] - 0s 1ms/step - loss: 4460585632980271104.0000 - val_loss: 1765132877487407104.0000\n",
            "Epoch 223/500\n",
            "76/76 [==============================] - 0s 1ms/step - loss: 2624205226646700032.0000 - val_loss: 229905940042743808.0000\n",
            "Epoch 224/500\n",
            "76/76 [==============================] - 0s 1ms/step - loss: 5409767083204411392.0000 - val_loss: 2469771396822073344.0000\n",
            "Epoch 225/500\n",
            "76/76 [==============================] - 0s 1ms/step - loss: 14412751360120324096.0000 - val_loss: 20293527784187232256.0000\n",
            "Epoch 226/500\n",
            "76/76 [==============================] - 0s 1ms/step - loss: 7543258346229334016.0000 - val_loss: 10394832407017553920.0000\n",
            "Epoch 227/500\n",
            "76/76 [==============================] - 0s 1ms/step - loss: 10128157956328390656.0000 - val_loss: 1531037231207153664.0000\n",
            "Epoch 228/500\n",
            "76/76 [==============================] - 0s 1ms/step - loss: 2012832506260226048.0000 - val_loss: 204422988542509056.0000\n",
            "Epoch 229/500\n",
            "76/76 [==============================] - 0s 1ms/step - loss: 46955945439264768.0000 - val_loss: 5366061272662016.0000\n",
            "Epoch 230/500\n",
            "76/76 [==============================] - 0s 1ms/step - loss: 10650037130362880.0000 - val_loss: 11636142294171648.0000\n",
            "Epoch 231/500\n",
            "76/76 [==============================] - 0s 1ms/step - loss: 7074961114005504.0000 - val_loss: 12248708783538176.0000\n",
            "Epoch 232/500\n",
            "76/76 [==============================] - 0s 1ms/step - loss: 99709014396370944.0000 - val_loss: 802745674138386432.0000\n",
            "Epoch 233/500\n",
            "76/76 [==============================] - 0s 1ms/step - loss: 320541002802659328.0000 - val_loss: 36236557471973376.0000\n",
            "Epoch 234/500\n",
            "76/76 [==============================] - 0s 1ms/step - loss: 225234115136323584.0000 - val_loss: 18886841658769408.0000\n",
            "Epoch 235/500\n",
            "76/76 [==============================] - 0s 1ms/step - loss: 30773986136686592.0000 - val_loss: 33407449629196288.0000\n",
            "Epoch 236/500\n",
            "76/76 [==============================] - 0s 1ms/step - loss: 12189209527844864.0000 - val_loss: 11251128540856320.0000\n",
            "Epoch 237/500\n",
            "76/76 [==============================] - 0s 1ms/step - loss: 27366507260411904.0000 - val_loss: 17838537852321792.0000\n",
            "Epoch 238/500\n",
            "76/76 [==============================] - 0s 1ms/step - loss: 6529670992363520.0000 - val_loss: 6114423890509824.0000\n",
            "Epoch 239/500\n",
            "76/76 [==============================] - 0s 1ms/step - loss: 6585418594123776.0000 - val_loss: 5783171316580352.0000\n",
            "Epoch 240/500\n",
            "76/76 [==============================] - 0s 1ms/step - loss: 4742490003341312.0000 - val_loss: 8134669669236736.0000\n",
            "Epoch 241/500\n",
            "76/76 [==============================] - 0s 1ms/step - loss: 31896031310381056.0000 - val_loss: 83610806956064768.0000\n",
            "Epoch 242/500\n",
            "76/76 [==============================] - 0s 1ms/step - loss: 12807679449759744.0000 - val_loss: 41487219415842816.0000\n",
            "Epoch 243/500\n",
            "76/76 [==============================] - 0s 1ms/step - loss: 12891079124713472.0000 - val_loss: 14584246500851712.0000\n",
            "Epoch 244/500\n",
            "76/76 [==============================] - 0s 1ms/step - loss: 21734834472747008.0000 - val_loss: 8871573314338816.0000\n",
            "Epoch 245/500\n",
            "76/76 [==============================] - 0s 1ms/step - loss: 56924912425631744.0000 - val_loss: 4783484929310720.0000\n",
            "Epoch 246/500\n",
            "76/76 [==============================] - 0s 1ms/step - loss: 24929018830651392.0000 - val_loss: 126203851601608704.0000\n",
            "Epoch 247/500\n",
            "76/76 [==============================] - 0s 1ms/step - loss: 208793409823965184.0000 - val_loss: 13153635844227072.0000\n",
            "Epoch 248/500\n",
            "76/76 [==============================] - 0s 1ms/step - loss: 1149879362091220992.0000 - val_loss: 5061216399641280512.0000\n",
            "Epoch 249/500\n",
            "76/76 [==============================] - 0s 1ms/step - loss: 29663891331536125952.0000 - val_loss: 9320395141912985600.0000\n",
            "Epoch 250/500\n",
            "76/76 [==============================] - 0s 1ms/step - loss: 13201619510915760128.0000 - val_loss: 934663361252032512.0000\n",
            "Epoch 251/500\n",
            "76/76 [==============================] - 0s 1ms/step - loss: 19483049176051220480.0000 - val_loss: 3702280500849672192.0000\n",
            "Epoch 252/500\n",
            "76/76 [==============================] - 0s 1ms/step - loss: 25861896670919262208.0000 - val_loss: 5183004904603516928.0000\n",
            "Epoch 253/500\n",
            "76/76 [==============================] - 0s 1ms/step - loss: 3629067869846765568.0000 - val_loss: 37049486857167962112.0000\n",
            "Epoch 254/500\n",
            "76/76 [==============================] - 0s 1ms/step - loss: 21002332353079541760.0000 - val_loss: 25734243370934468608.0000\n",
            "Epoch 255/500\n",
            "76/76 [==============================] - 0s 1ms/step - loss: 14731436009338175488.0000 - val_loss: 464295825942511616.0000\n",
            "Epoch 256/500\n",
            "76/76 [==============================] - 0s 1ms/step - loss: 606404370937937920.0000 - val_loss: 13022027480658083840.0000\n",
            "Epoch 257/500\n",
            "76/76 [==============================] - 0s 1ms/step - loss: 3928552572142485504.0000 - val_loss: 305474360607506432.0000\n",
            "Epoch 258/500\n",
            "76/76 [==============================] - 0s 1ms/step - loss: 1790637561522159616.0000 - val_loss: 22201030924797214720.0000\n",
            "Epoch 259/500\n",
            "76/76 [==============================] - 0s 1ms/step - loss: 6754033297858232320.0000 - val_loss: 3233088927585796096.0000\n",
            "Epoch 260/500\n",
            "76/76 [==============================] - 0s 1ms/step - loss: 2863772592542580736.0000 - val_loss: 2801118021945393152.0000\n",
            "Epoch 261/500\n",
            "76/76 [==============================] - 0s 1ms/step - loss: 2769007059734102016.0000 - val_loss: 385359687161217024.0000\n",
            "Epoch 262/500\n",
            "76/76 [==============================] - 0s 1ms/step - loss: 2390575223540809728.0000 - val_loss: 751801108535443456.0000\n",
            "Epoch 263/500\n",
            "76/76 [==============================] - 0s 1ms/step - loss: 1578988857439813632.0000 - val_loss: 656380198077333504.0000\n",
            "Epoch 264/500\n",
            "76/76 [==============================] - 0s 1ms/step - loss: 20342258139530264576.0000 - val_loss: 5281673978568507392.0000\n",
            "Epoch 265/500\n",
            "76/76 [==============================] - 0s 1ms/step - loss: 2763084265473179648.0000 - val_loss: 134845540549525504.0000\n",
            "Epoch 266/500\n",
            "76/76 [==============================] - 0s 1ms/step - loss: 3554006410041753600.0000 - val_loss: 7273088548075470848.0000\n",
            "Epoch 267/500\n",
            "76/76 [==============================] - 0s 1ms/step - loss: 4691173562290012160.0000 - val_loss: 1857413239139205120.0000\n",
            "Epoch 268/500\n",
            "76/76 [==============================] - 0s 1ms/step - loss: 3755460854628220928.0000 - val_loss: 52485672883191808.0000\n",
            "Epoch 269/500\n",
            "76/76 [==============================] - 0s 1ms/step - loss: 2509273825951088640.0000 - val_loss: 2215941166090682368.0000\n",
            "Epoch 270/500\n",
            "76/76 [==============================] - 0s 1ms/step - loss: 3867965358283423744.0000 - val_loss: 287700789504245760.0000\n",
            "Epoch 271/500\n",
            "76/76 [==============================] - 0s 1ms/step - loss: 4908293023915311104.0000 - val_loss: 363768096290242560.0000\n",
            "Epoch 272/500\n",
            "76/76 [==============================] - 0s 1ms/step - loss: 3753616698750533632.0000 - val_loss: 526196165922783232.0000\n",
            "Epoch 273/500\n",
            "76/76 [==============================] - 0s 1ms/step - loss: 792844640649740288.0000 - val_loss: 53932372487307264.0000\n",
            "Epoch 274/500\n",
            "76/76 [==============================] - 0s 1ms/step - loss: 57315105909506048.0000 - val_loss: 7891743634620416.0000\n",
            "Epoch 275/500\n",
            "76/76 [==============================] - 0s 1ms/step - loss: 81215314716524544.0000 - val_loss: 90282901211447296.0000\n",
            "Epoch 276/500\n",
            "76/76 [==============================] - 0s 1ms/step - loss: 68622277331124224.0000 - val_loss: 80647975306526720.0000\n",
            "Epoch 277/500\n",
            "76/76 [==============================] - 0s 1ms/step - loss: 196732179584122880.0000 - val_loss: 1564014333703225344.0000\n",
            "Epoch 278/500\n",
            "76/76 [==============================] - 0s 1ms/step - loss: 784737735259717632.0000 - val_loss: 24151324807397376.0000\n",
            "Epoch 279/500\n",
            "76/76 [==============================] - 0s 1ms/step - loss: 489521715060146176.0000 - val_loss: 28726199417044992.0000\n",
            "Epoch 280/500\n",
            "76/76 [==============================] - 0s 1ms/step - loss: 24558614408593408.0000 - val_loss: 289452655124676608.0000\n",
            "Epoch 281/500\n",
            "76/76 [==============================] - 0s 1ms/step - loss: 1353701123931766784.0000 - val_loss: 2211531437268533248.0000\n",
            "Epoch 282/500\n",
            "76/76 [==============================] - 0s 1ms/step - loss: 542211205616369664.0000 - val_loss: 2563069906241191936.0000\n",
            "Epoch 283/500\n",
            "76/76 [==============================] - 0s 1ms/step - loss: 1890001801713811456.0000 - val_loss: 81857101371644313600.0000\n",
            "Epoch 284/500\n",
            "76/76 [==============================] - 0s 1ms/step - loss: 12858383866561298432.0000 - val_loss: 359186053380177920.0000\n",
            "Epoch 285/500\n",
            "76/76 [==============================] - 0s 1ms/step - loss: 1708217070392442880.0000 - val_loss: 418990002643402752.0000\n",
            "Epoch 286/500\n",
            "76/76 [==============================] - 0s 1ms/step - loss: 4737679605610053632.0000 - val_loss: 4337503552587956224.0000\n",
            "Epoch 287/500\n",
            "76/76 [==============================] - 0s 1ms/step - loss: 24163454671214608384.0000 - val_loss: 19616765183151570944.0000\n",
            "Epoch 288/500\n",
            "76/76 [==============================] - 0s 1ms/step - loss: 938951181722451968.0000 - val_loss: 22450921485107200.0000\n",
            "Epoch 289/500\n",
            "76/76 [==============================] - 0s 1ms/step - loss: 327831039772721152.0000 - val_loss: 254744440290148352.0000\n",
            "Epoch 290/500\n",
            "76/76 [==============================] - 0s 1ms/step - loss: 232029371873886208.0000 - val_loss: 3821803365466112.0000\n",
            "Epoch 291/500\n",
            "76/76 [==============================] - 0s 1ms/step - loss: 57764965079056384.0000 - val_loss: 17986835556859904.0000\n",
            "Epoch 292/500\n",
            "76/76 [==============================] - 0s 1ms/step - loss: 38798681557696512.0000 - val_loss: 66313680869916672.0000\n",
            "Epoch 293/500\n",
            "76/76 [==============================] - 0s 1ms/step - loss: 677620013946896384.0000 - val_loss: 528815752375959552.0000\n",
            "Epoch 294/500\n",
            "76/76 [==============================] - 0s 1ms/step - loss: 912585854961057792.0000 - val_loss: 704829009724178432.0000\n",
            "Epoch 295/500\n",
            "76/76 [==============================] - 0s 1ms/step - loss: 2949056211951026176.0000 - val_loss: 12802375843754016768.0000\n",
            "Epoch 296/500\n",
            "76/76 [==============================] - 0s 1ms/step - loss: 14408340119469686784.0000 - val_loss: 49295680413368320.0000\n",
            "Epoch 297/500\n",
            "76/76 [==============================] - 0s 1ms/step - loss: 257848430334836736.0000 - val_loss: 937011643211055104.0000\n",
            "Epoch 298/500\n",
            "76/76 [==============================] - 0s 1ms/step - loss: 96832219531706368.0000 - val_loss: 20303102829658112.0000\n",
            "Epoch 299/500\n",
            "76/76 [==============================] - 0s 1ms/step - loss: 15110304832684032.0000 - val_loss: 7030184469331968.0000\n",
            "Epoch 300/500\n",
            "76/76 [==============================] - 0s 1ms/step - loss: 13916240573628416.0000 - val_loss: 137353552342286336.0000\n",
            "Epoch 301/500\n",
            "76/76 [==============================] - 0s 1ms/step - loss: 39670920696037376.0000 - val_loss: 23047683568566272.0000\n",
            "Epoch 302/500\n",
            "76/76 [==============================] - 0s 1ms/step - loss: 1306702774280388608.0000 - val_loss: 4474786925164625920.0000\n",
            "Epoch 303/500\n",
            "76/76 [==============================] - 0s 1ms/step - loss: 3940988598408445952.0000 - val_loss: 70197808774250496.0000\n",
            "Epoch 304/500\n",
            "76/76 [==============================] - 0s 1ms/step - loss: 6950237299544162304.0000 - val_loss: 22187649868287180800.0000\n",
            "Epoch 305/500\n",
            "76/76 [==============================] - 0s 1ms/step - loss: 4950990358956736512.0000 - val_loss: 1964612736629342208.0000\n",
            "Epoch 306/500\n",
            "76/76 [==============================] - 0s 1ms/step - loss: 2038752943129231360.0000 - val_loss: 1138537624772804608.0000\n",
            "Epoch 307/500\n",
            "76/76 [==============================] - 0s 1ms/step - loss: 143611603160399872.0000 - val_loss: 333937864792342528.0000\n",
            "Epoch 308/500\n",
            "76/76 [==============================] - 0s 1ms/step - loss: 396002444322013184.0000 - val_loss: 190127945812017152.0000\n",
            "Epoch 309/500\n",
            "76/76 [==============================] - 0s 1ms/step - loss: 1020951796849311744.0000 - val_loss: 49421535840043008.0000\n",
            "Epoch 310/500\n",
            "76/76 [==============================] - 0s 1ms/step - loss: 118313086145789952.0000 - val_loss: 188991188227850240.0000\n",
            "Epoch 311/500\n",
            "76/76 [==============================] - 0s 1ms/step - loss: 168067310152581120.0000 - val_loss: 186497392776839168.0000\n",
            "Epoch 312/500\n",
            "76/76 [==============================] - 0s 1ms/step - loss: 12550864757923512320.0000 - val_loss: 20389974745152487424.0000\n",
            "Epoch 313/500\n",
            "76/76 [==============================] - 0s 1ms/step - loss: 4189486472623030272.0000 - val_loss: 35506086992096002048.0000\n",
            "Epoch 314/500\n",
            "76/76 [==============================] - 0s 1ms/step - loss: 8421099083996856320.0000 - val_loss: 5452574919164428288.0000\n",
            "Epoch 315/500\n",
            "76/76 [==============================] - 0s 1ms/step - loss: 2958440818572001280.0000 - val_loss: 3788650987502174208.0000\n",
            "Epoch 316/500\n",
            "76/76 [==============================] - 0s 1ms/step - loss: 3852446026535272448.0000 - val_loss: 32436485822833754112.0000\n",
            "Epoch 317/500\n",
            "76/76 [==============================] - 0s 1ms/step - loss: 94762086939037270016.0000 - val_loss: 60687610265793986560.0000\n",
            "Epoch 318/500\n",
            "76/76 [==============================] - 0s 1ms/step - loss: 27966076053459304448.0000 - val_loss: 147041984949780480.0000\n",
            "Epoch 319/500\n",
            "76/76 [==============================] - 0s 1ms/step - loss: 10492406367401279488.0000 - val_loss: 505668936667234304.0000\n",
            "Epoch 320/500\n",
            "76/76 [==============================] - 0s 1ms/step - loss: 1851296930831794176.0000 - val_loss: 615842028994953216.0000\n",
            "Epoch 321/500\n",
            "76/76 [==============================] - 0s 1ms/step - loss: 1308866475724898304.0000 - val_loss: 1627578750172397568.0000\n",
            "Epoch 322/500\n",
            "76/76 [==============================] - 0s 1ms/step - loss: 329418837642444800.0000 - val_loss: 3725643748550377472.0000\n",
            "Epoch 323/500\n",
            "76/76 [==============================] - 0s 1ms/step - loss: 746066468201824256.0000 - val_loss: 623187728741171200.0000\n",
            "Epoch 324/500\n",
            "76/76 [==============================] - 0s 1ms/step - loss: 195507821846986752.0000 - val_loss: 27640536911314944.0000\n",
            "Epoch 325/500\n",
            "76/76 [==============================] - 0s 1ms/step - loss: 110094090699276288.0000 - val_loss: 3277262984052736.0000\n",
            "Epoch 326/500\n",
            "76/76 [==============================] - 0s 1ms/step - loss: 43532366878081024.0000 - val_loss: 206275390757404672.0000\n",
            "Epoch 327/500\n",
            "76/76 [==============================] - 0s 1ms/step - loss: 322145121548107776.0000 - val_loss: 187095372483526656.0000\n",
            "Epoch 328/500\n",
            "76/76 [==============================] - 0s 1ms/step - loss: 284150329019203584.0000 - val_loss: 1968404127599820800.0000\n",
            "Epoch 329/500\n",
            "76/76 [==============================] - 0s 1ms/step - loss: 1703987936355155968.0000 - val_loss: 1962274625152876544.0000\n",
            "Epoch 330/500\n",
            "76/76 [==============================] - 0s 1ms/step - loss: 900879492099080192.0000 - val_loss: 369131170413150208.0000\n",
            "Epoch 331/500\n",
            "76/76 [==============================] - 0s 1ms/step - loss: 109694272193691648.0000 - val_loss: 6447970513846272.0000\n",
            "Epoch 332/500\n",
            "76/76 [==============================] - 0s 1ms/step - loss: 35910371885711360.0000 - val_loss: 12060613912035328.0000\n",
            "Epoch 333/500\n",
            "76/76 [==============================] - 0s 1ms/step - loss: 14903307810111488.0000 - val_loss: 6732716645023744.0000\n",
            "Epoch 334/500\n",
            "76/76 [==============================] - 0s 1ms/step - loss: 9671505067638784.0000 - val_loss: 39305311604965376.0000\n",
            "Epoch 335/500\n",
            "76/76 [==============================] - 0s 1ms/step - loss: 590197157227659264.0000 - val_loss: 1105952704330465280.0000\n",
            "Epoch 336/500\n",
            "76/76 [==============================] - 0s 1ms/step - loss: 441316067281731584.0000 - val_loss: 261699126213738496.0000\n",
            "Epoch 337/500\n",
            "76/76 [==============================] - 0s 1ms/step - loss: 298856881156259840.0000 - val_loss: 4832502587901083648.0000\n",
            "Epoch 338/500\n",
            "76/76 [==============================] - 0s 1ms/step - loss: 520064842409705472.0000 - val_loss: 538407548219293696.0000\n",
            "Epoch 339/500\n",
            "76/76 [==============================] - 0s 1ms/step - loss: 1575187295986778112.0000 - val_loss: 911786166410280960.0000\n",
            "Epoch 340/500\n",
            "76/76 [==============================] - 0s 1ms/step - loss: 633468987094597632.0000 - val_loss: 115803837402447872.0000\n",
            "Epoch 341/500\n",
            "76/76 [==============================] - 0s 1ms/step - loss: 551278465693777920.0000 - val_loss: 39243781903482880.0000\n",
            "Epoch 342/500\n",
            "76/76 [==============================] - 0s 1ms/step - loss: 595904241051107328.0000 - val_loss: 1006090110493523968.0000\n",
            "Epoch 343/500\n",
            "76/76 [==============================] - 0s 1ms/step - loss: 368285061855838208.0000 - val_loss: 124068110394195968.0000\n",
            "Epoch 344/500\n",
            "76/76 [==============================] - 0s 1ms/step - loss: 13462702944977682432.0000 - val_loss: 864953568136790016.0000\n",
            "Epoch 345/500\n",
            "76/76 [==============================] - 0s 1ms/step - loss: 22932415064477532160.0000 - val_loss: 207718791826636800.0000\n",
            "Epoch 346/500\n",
            "76/76 [==============================] - 0s 1ms/step - loss: 9116791426972123136.0000 - val_loss: 3198747880915468288.0000\n",
            "Epoch 347/500\n",
            "76/76 [==============================] - 0s 1ms/step - loss: 991367443639173120.0000 - val_loss: 10925390704934912.0000\n",
            "Epoch 348/500\n",
            "76/76 [==============================] - 0s 1ms/step - loss: 33043854877786112.0000 - val_loss: 71090113999798272.0000\n",
            "Epoch 349/500\n",
            "76/76 [==============================] - 0s 1ms/step - loss: 32127512867766272.0000 - val_loss: 10417689063325696.0000\n",
            "Epoch 350/500\n",
            "76/76 [==============================] - 0s 1ms/step - loss: 5409098992451584.0000 - val_loss: 30309642189930496.0000\n",
            "Epoch 351/500\n",
            "76/76 [==============================] - 0s 1ms/step - loss: 18467270598590464.0000 - val_loss: 53091074293366784.0000\n",
            "Epoch 352/500\n",
            "76/76 [==============================] - 0s 1ms/step - loss: 207169053192617984.0000 - val_loss: 477269307236024320.0000\n",
            "Epoch 353/500\n",
            "76/76 [==============================] - 0s 1ms/step - loss: 318458940096512000.0000 - val_loss: 11272528215408640.0000\n",
            "Epoch 354/500\n",
            "76/76 [==============================] - 0s 1ms/step - loss: 872769583981789184.0000 - val_loss: 669789635731259392.0000\n",
            "Epoch 355/500\n",
            "76/76 [==============================] - 0s 1ms/step - loss: 30134732996875386880.0000 - val_loss: 19677953005237305344.0000\n",
            "Epoch 356/500\n",
            "76/76 [==============================] - 0s 1ms/step - loss: 32622393447881375744.0000 - val_loss: 23146032581568364544.0000\n",
            "Epoch 357/500\n",
            "76/76 [==============================] - 0s 1ms/step - loss: 17188701560905924608.0000 - val_loss: 10666353504961953792.0000\n",
            "Epoch 358/500\n",
            "76/76 [==============================] - 0s 1ms/step - loss: 1044702828557238272.0000 - val_loss: 185233744678879232.0000\n",
            "Epoch 359/500\n",
            "76/76 [==============================] - 0s 1ms/step - loss: 23097687725309952.0000 - val_loss: 9782328108777472.0000\n",
            "Epoch 360/500\n",
            "76/76 [==============================] - 0s 1ms/step - loss: 78269748835516416.0000 - val_loss: 341512022438969344.0000\n",
            "Epoch 361/500\n",
            "76/76 [==============================] - 0s 1ms/step - loss: 147064335959588864.0000 - val_loss: 9731217997955072.0000\n",
            "Epoch 362/500\n",
            "76/76 [==============================] - 0s 1ms/step - loss: 144347477087092736.0000 - val_loss: 12490396256960512.0000\n",
            "Epoch 363/500\n",
            "76/76 [==============================] - 0s 1ms/step - loss: 117156013366312960.0000 - val_loss: 111765691970879488.0000\n",
            "Epoch 364/500\n",
            "76/76 [==============================] - 0s 1ms/step - loss: 450807326530600960.0000 - val_loss: 60107328573145088.0000\n",
            "Epoch 365/500\n",
            "76/76 [==============================] - 0s 1ms/step - loss: 9133006363033600.0000 - val_loss: 8580527539879936.0000\n",
            "Epoch 366/500\n",
            "76/76 [==============================] - 0s 1ms/step - loss: 8524326282199040.0000 - val_loss: 6886524255731712.0000\n",
            "Epoch 367/500\n",
            "76/76 [==============================] - 0s 1ms/step - loss: 23544974209449984.0000 - val_loss: 8562099445825536.0000\n",
            "Epoch 368/500\n",
            "76/76 [==============================] - 0s 1ms/step - loss: 259038806290726912.0000 - val_loss: 82137676123209728.0000\n",
            "Epoch 369/500\n",
            "76/76 [==============================] - 0s 1ms/step - loss: 25467070858657792.0000 - val_loss: 36717284571480064.0000\n",
            "Epoch 370/500\n",
            "76/76 [==============================] - 0s 1ms/step - loss: 235143601120608256.0000 - val_loss: 61564774185435136.0000\n",
            "Epoch 371/500\n",
            "76/76 [==============================] - 0s 1ms/step - loss: 284869306544553984.0000 - val_loss: 825508313612419072.0000\n",
            "Epoch 372/500\n",
            "76/76 [==============================] - 0s 1ms/step - loss: 8115495874370469888.0000 - val_loss: 6986041796191059968.0000\n",
            "Epoch 373/500\n",
            "76/76 [==============================] - 0s 1ms/step - loss: 4792749744998842368.0000 - val_loss: 664305203012435968.0000\n",
            "Epoch 374/500\n",
            "76/76 [==============================] - 0s 1ms/step - loss: 593130722970042368.0000 - val_loss: 20911025385635840.0000\n",
            "Epoch 375/500\n",
            "76/76 [==============================] - 0s 1ms/step - loss: 67292619880792064.0000 - val_loss: 43929466669367296.0000\n",
            "Epoch 376/500\n",
            "76/76 [==============================] - 0s 1ms/step - loss: 373726819779608576.0000 - val_loss: 688313314282831872.0000\n",
            "Epoch 377/500\n",
            "76/76 [==============================] - 0s 1ms/step - loss: 49212358047825920.0000 - val_loss: 193822287701475328.0000\n",
            "Epoch 378/500\n",
            "76/76 [==============================] - 0s 1ms/step - loss: 436067720325234688.0000 - val_loss: 566415751511015424.0000\n",
            "Epoch 379/500\n",
            "76/76 [==============================] - 0s 1ms/step - loss: 2345548298238033920.0000 - val_loss: 114553735631339520.0000\n",
            "Epoch 380/500\n",
            "76/76 [==============================] - 0s 1ms/step - loss: 1397304319115526144.0000 - val_loss: 749307897199984640.0000\n",
            "Epoch 381/500\n",
            "76/76 [==============================] - 0s 1ms/step - loss: 2268929929968091136.0000 - val_loss: 26446401450291494912.0000\n",
            "Epoch 382/500\n",
            "76/76 [==============================] - 0s 1ms/step - loss: 25146015645190586368.0000 - val_loss: 18268489049591250944.0000\n",
            "Epoch 383/500\n",
            "76/76 [==============================] - 0s 1ms/step - loss: 23040569625255346176.0000 - val_loss: 61037871892529152.0000\n",
            "Epoch 384/500\n",
            "76/76 [==============================] - 0s 1ms/step - loss: 11606352383826722816.0000 - val_loss: 14967852999542571008.0000\n",
            "Epoch 385/500\n",
            "76/76 [==============================] - 0s 1ms/step - loss: 37951772487200014336.0000 - val_loss: 3206528025193611264.0000\n",
            "Epoch 386/500\n",
            "76/76 [==============================] - 0s 1ms/step - loss: 341396436279099392.0000 - val_loss: 1540306526546165760.0000\n",
            "Epoch 387/500\n",
            "76/76 [==============================] - 0s 1ms/step - loss: 1757857958802227200.0000 - val_loss: 84111144876244992.0000\n",
            "Epoch 388/500\n",
            "76/76 [==============================] - 0s 1ms/step - loss: 194578992219553792.0000 - val_loss: 3405827152111730688.0000\n",
            "Epoch 389/500\n",
            "76/76 [==============================] - 0s 1ms/step - loss: 1902048600863539200.0000 - val_loss: 2282782951844347904.0000\n",
            "Epoch 390/500\n",
            "76/76 [==============================] - 0s 1ms/step - loss: 3159855405861961728.0000 - val_loss: 9807095063459659776.0000\n",
            "Epoch 391/500\n",
            "76/76 [==============================] - 0s 1ms/step - loss: 562614877252747264.0000 - val_loss: 582490130472763392.0000\n",
            "Epoch 392/500\n",
            "76/76 [==============================] - 0s 1ms/step - loss: 313832676203167744.0000 - val_loss: 1020268244214218752.0000\n",
            "Epoch 393/500\n",
            "76/76 [==============================] - 0s 1ms/step - loss: 125363575609884672.0000 - val_loss: 175929110348955648.0000\n",
            "Epoch 394/500\n",
            "76/76 [==============================] - 0s 1ms/step - loss: 51490524665741312.0000 - val_loss: 102856933366562816.0000\n",
            "Epoch 395/500\n",
            "76/76 [==============================] - 0s 1ms/step - loss: 24115427470737408.0000 - val_loss: 44330217182855168.0000\n",
            "Epoch 396/500\n",
            "76/76 [==============================] - 0s 1ms/step - loss: 58455385366855680.0000 - val_loss: 301805736982216704.0000\n",
            "Epoch 397/500\n",
            "76/76 [==============================] - 0s 2ms/step - loss: 1905087101246898176.0000 - val_loss: 128036393887727616.0000\n",
            "Epoch 398/500\n",
            "76/76 [==============================] - 0s 1ms/step - loss: 401884178695585792.0000 - val_loss: 4624374932367736832.0000\n",
            "Epoch 399/500\n",
            "76/76 [==============================] - 0s 1ms/step - loss: 606737110644293632.0000 - val_loss: 1734603425313718272.0000\n",
            "Epoch 400/500\n",
            "76/76 [==============================] - 0s 1ms/step - loss: 1055924238071889920.0000 - val_loss: 1410726332433694720.0000\n",
            "Epoch 401/500\n",
            "76/76 [==============================] - 0s 1ms/step - loss: 877616780992839680.0000 - val_loss: 1458172870512345088.0000\n",
            "Epoch 402/500\n",
            "76/76 [==============================] - 0s 1ms/step - loss: 7023984293198168064.0000 - val_loss: 2637231690656776192.0000\n",
            "Epoch 403/500\n",
            "76/76 [==============================] - 0s 1ms/step - loss: 34933463535373516800.0000 - val_loss: 118120388143087616.0000\n",
            "Epoch 404/500\n",
            "76/76 [==============================] - 0s 1ms/step - loss: 23155033183753338880.0000 - val_loss: 32879817707246059520.0000\n",
            "Epoch 405/500\n",
            "76/76 [==============================] - 0s 1ms/step - loss: 18754380830091509760.0000 - val_loss: 1479124889213337600.0000\n",
            "Epoch 406/500\n",
            "76/76 [==============================] - 0s 1ms/step - loss: 17966316865999339520.0000 - val_loss: 25539658400120438784.0000\n",
            "Epoch 407/500\n",
            "76/76 [==============================] - 0s 1ms/step - loss: 35181227485576560640.0000 - val_loss: 14188891892216758272.0000\n",
            "Epoch 408/500\n",
            "76/76 [==============================] - 0s 1ms/step - loss: 4614853711427010560.0000 - val_loss: 411733122820866048.0000\n",
            "Epoch 409/500\n",
            "76/76 [==============================] - 0s 1ms/step - loss: 1360571834654785536.0000 - val_loss: 536160043372904448.0000\n",
            "Epoch 410/500\n",
            "76/76 [==============================] - 0s 1ms/step - loss: 201003455840518144.0000 - val_loss: 13479685065277440.0000\n",
            "Epoch 411/500\n",
            "76/76 [==============================] - 0s 1ms/step - loss: 27609026883747840.0000 - val_loss: 150761151750209536.0000\n",
            "Epoch 412/500\n",
            "76/76 [==============================] - 0s 1ms/step - loss: 34861064130658304.0000 - val_loss: 7345390508572672.0000\n",
            "Epoch 413/500\n",
            "76/76 [==============================] - 0s 1ms/step - loss: 13101411189391360.0000 - val_loss: 25003283110166528.0000\n",
            "Epoch 414/500\n",
            "76/76 [==============================] - 0s 1ms/step - loss: 11452183476174848.0000 - val_loss: 11791075723182080.0000\n",
            "Epoch 415/500\n",
            "76/76 [==============================] - 0s 1ms/step - loss: 6082395245641728.0000 - val_loss: 5342555990392832.0000\n",
            "Epoch 416/500\n",
            "76/76 [==============================] - 0s 1ms/step - loss: 13902508489441280.0000 - val_loss: 19457129563815936.0000\n",
            "Epoch 417/500\n",
            "76/76 [==============================] - 0s 1ms/step - loss: 12895039084560384.0000 - val_loss: 13104149231042560.0000\n",
            "Epoch 418/500\n",
            "76/76 [==============================] - 0s 1ms/step - loss: 10492650201284608.0000 - val_loss: 9405707795300352.0000\n",
            "Epoch 419/500\n",
            "76/76 [==============================] - 0s 1ms/step - loss: 4581825477345280.0000 - val_loss: 8920617009020928.0000\n",
            "Epoch 420/500\n",
            "76/76 [==============================] - 0s 1ms/step - loss: 17261062319505408.0000 - val_loss: 9854582343598080.0000\n",
            "Epoch 421/500\n",
            "76/76 [==============================] - 0s 1ms/step - loss: 8930215187185664.0000 - val_loss: 8357738459430912.0000\n",
            "Epoch 422/500\n",
            "76/76 [==============================] - 0s 1ms/step - loss: 9340599312318464.0000 - val_loss: 16637220467245056.0000\n",
            "Epoch 423/500\n",
            "76/76 [==============================] - 0s 1ms/step - loss: 4518954135453696.0000 - val_loss: 7462528225378304.0000\n",
            "Epoch 424/500\n",
            "76/76 [==============================] - 0s 1ms/step - loss: 7300656813572096.0000 - val_loss: 7187200420610048.0000\n",
            "Epoch 425/500\n",
            "76/76 [==============================] - 0s 1ms/step - loss: 4791872463568896.0000 - val_loss: 6439594790748160.0000\n",
            "Epoch 426/500\n",
            "76/76 [==============================] - 0s 1ms/step - loss: 34664251549286400.0000 - val_loss: 37522157147783168.0000\n",
            "Epoch 427/500\n",
            "76/76 [==============================] - 0s 1ms/step - loss: 519599714631417856.0000 - val_loss: 1582426755421962240.0000\n",
            "Epoch 428/500\n",
            "76/76 [==============================] - 0s 2ms/step - loss: 532863226476494848.0000 - val_loss: 754766972431892480.0000\n",
            "Epoch 429/500\n",
            "76/76 [==============================] - 0s 1ms/step - loss: 276210772734902272.0000 - val_loss: 239704066114977792.0000\n",
            "Epoch 430/500\n",
            "76/76 [==============================] - 0s 1ms/step - loss: 241434731776835584.0000 - val_loss: 754896371206586368.0000\n",
            "Epoch 431/500\n",
            "76/76 [==============================] - 0s 1ms/step - loss: 2791302681644236800.0000 - val_loss: 16855813420480462848.0000\n",
            "Epoch 432/500\n",
            "76/76 [==============================] - 0s 1ms/step - loss: 7253513942566174720.0000 - val_loss: 27943091862392274944.0000\n",
            "Epoch 433/500\n",
            "76/76 [==============================] - 0s 1ms/step - loss: 31056317254998163456.0000 - val_loss: 32613788669882400768.0000\n",
            "Epoch 434/500\n",
            "76/76 [==============================] - 0s 1ms/step - loss: 15134354244359946240.0000 - val_loss: 6643890820057399296.0000\n",
            "Epoch 435/500\n",
            "76/76 [==============================] - 0s 1ms/step - loss: 11602483202408579072.0000 - val_loss: 4724214986216308736.0000\n",
            "Epoch 436/500\n",
            "76/76 [==============================] - 0s 1ms/step - loss: 28758881111690444800.0000 - val_loss: 3130551221958475776.0000\n",
            "Epoch 437/500\n",
            "76/76 [==============================] - 0s 1ms/step - loss: 12127265808694902784.0000 - val_loss: 25823767806691246080.0000\n",
            "Epoch 438/500\n",
            "76/76 [==============================] - 0s 1ms/step - loss: 6081866655426674688.0000 - val_loss: 5610488428413059072.0000\n",
            "Epoch 439/500\n",
            "76/76 [==============================] - 0s 1ms/step - loss: 1752767907160391680.0000 - val_loss: 9062994101141504.0000\n",
            "Epoch 440/500\n",
            "76/76 [==============================] - 0s 1ms/step - loss: 50877942070247424.0000 - val_loss: 9860588855361536.0000\n",
            "Epoch 441/500\n",
            "76/76 [==============================] - 0s 1ms/step - loss: 27567954111496192.0000 - val_loss: 115218983115816960.0000\n",
            "Epoch 442/500\n",
            "76/76 [==============================] - 0s 1ms/step - loss: 42426726331973632.0000 - val_loss: 63022550510206976.0000\n",
            "Epoch 443/500\n",
            "76/76 [==============================] - 0s 1ms/step - loss: 38341267540672512.0000 - val_loss: 118766943929892864.0000\n",
            "Epoch 444/500\n",
            "76/76 [==============================] - 0s 1ms/step - loss: 27940235434262528.0000 - val_loss: 34574347146362880.0000\n",
            "Epoch 445/500\n",
            "76/76 [==============================] - 0s 1ms/step - loss: 12225972300414976.0000 - val_loss: 6840110154776576.0000\n",
            "Epoch 446/500\n",
            "76/76 [==============================] - 0s 1ms/step - loss: 21154363200241664.0000 - val_loss: 29846479359180800.0000\n",
            "Epoch 447/500\n",
            "76/76 [==============================] - 0s 1ms/step - loss: 9357903735554048.0000 - val_loss: 8736098234662912.0000\n",
            "Epoch 448/500\n",
            "76/76 [==============================] - 0s 1ms/step - loss: 11276239067152384.0000 - val_loss: 5204581239750656.0000\n",
            "Epoch 449/500\n",
            "76/76 [==============================] - 0s 1ms/step - loss: 11232236053463040.0000 - val_loss: 34219091073957888.0000\n",
            "Epoch 450/500\n",
            "76/76 [==============================] - 0s 1ms/step - loss: 46639917450657792.0000 - val_loss: 287296753340776448.0000\n",
            "Epoch 451/500\n",
            "76/76 [==============================] - 0s 1ms/step - loss: 1998314279849164800.0000 - val_loss: 17978321333951397888.0000\n",
            "Epoch 452/500\n",
            "76/76 [==============================] - 0s 1ms/step - loss: 12723215404600655872.0000 - val_loss: 2586137110436118528.0000\n",
            "Epoch 453/500\n",
            "76/76 [==============================] - 0s 1ms/step - loss: 3857147813133549568.0000 - val_loss: 22220782105001984.0000\n",
            "Epoch 454/500\n",
            "76/76 [==============================] - 0s 1ms/step - loss: 658644436116307968.0000 - val_loss: 88382120484929536.0000\n",
            "Epoch 455/500\n",
            "76/76 [==============================] - 0s 1ms/step - loss: 424927674671038464.0000 - val_loss: 885783266169192448.0000\n",
            "Epoch 456/500\n",
            "76/76 [==============================] - 0s 1ms/step - loss: 241495136196886528.0000 - val_loss: 751774307939516416.0000\n",
            "Epoch 457/500\n",
            "76/76 [==============================] - 0s 2ms/step - loss: 1081381849265078272.0000 - val_loss: 44035708973265977344.0000\n",
            "Epoch 458/500\n",
            "76/76 [==============================] - 0s 1ms/step - loss: 3976382152584462336.0000 - val_loss: 1186506224716218368.0000\n",
            "Epoch 459/500\n",
            "76/76 [==============================] - 0s 1ms/step - loss: 329082627602513920.0000 - val_loss: 142349647279554560.0000\n",
            "Epoch 460/500\n",
            "76/76 [==============================] - 0s 1ms/step - loss: 810963286605430784.0000 - val_loss: 1231896126295113728.0000\n",
            "Epoch 461/500\n",
            "76/76 [==============================] - 0s 1ms/step - loss: 403298631685242880.0000 - val_loss: 143465093235998720.0000\n",
            "Epoch 462/500\n",
            "76/76 [==============================] - 0s 1ms/step - loss: 37985665723400192.0000 - val_loss: 236016029237510144.0000\n",
            "Epoch 463/500\n",
            "76/76 [==============================] - 0s 1ms/step - loss: 26990751309103104.0000 - val_loss: 44776472874844160.0000\n",
            "Epoch 464/500\n",
            "76/76 [==============================] - 0s 1ms/step - loss: 12681724165095424.0000 - val_loss: 6653175461314560.0000\n",
            "Epoch 465/500\n",
            "76/76 [==============================] - 0s 1ms/step - loss: 1694025536373784576.0000 - val_loss: 2216944333012074496.0000\n",
            "Epoch 466/500\n",
            "76/76 [==============================] - 0s 1ms/step - loss: 5823759049585328128.0000 - val_loss: 1866801281734017024.0000\n",
            "Epoch 467/500\n",
            "76/76 [==============================] - 0s 1ms/step - loss: 1979583686953140224.0000 - val_loss: 1432316617634611200.0000\n",
            "Epoch 468/500\n",
            "76/76 [==============================] - 0s 1ms/step - loss: 950533849526304768.0000 - val_loss: 204872757517746176.0000\n",
            "Epoch 469/500\n",
            "76/76 [==============================] - 0s 1ms/step - loss: 733588591774531584.0000 - val_loss: 307196298895818752.0000\n",
            "Epoch 470/500\n",
            "76/76 [==============================] - 0s 1ms/step - loss: 2389952625081581568.0000 - val_loss: 6528299162629308416.0000\n",
            "Epoch 471/500\n",
            "76/76 [==============================] - 0s 2ms/step - loss: 18926469793001242624.0000 - val_loss: 39833485483068882944.0000\n",
            "Epoch 472/500\n",
            "76/76 [==============================] - 0s 1ms/step - loss: 2562712015206350848.0000 - val_loss: 736703920532881408.0000\n",
            "Epoch 473/500\n",
            "76/76 [==============================] - 0s 1ms/step - loss: 2167376424686583808.0000 - val_loss: 268335503521087488.0000\n",
            "Epoch 474/500\n",
            "76/76 [==============================] - 0s 1ms/step - loss: 2092585169864097792.0000 - val_loss: 6586484218459586560.0000\n",
            "Epoch 475/500\n",
            "76/76 [==============================] - 0s 1ms/step - loss: 567469942643884032.0000 - val_loss: 1084348400356294656.0000\n",
            "Epoch 476/500\n",
            "76/76 [==============================] - 0s 1ms/step - loss: 5148064624096051200.0000 - val_loss: 435786107909570560.0000\n",
            "Epoch 477/500\n",
            "76/76 [==============================] - 0s 1ms/step - loss: 7473581744621355008.0000 - val_loss: 1826391343195226112.0000\n",
            "Epoch 478/500\n",
            "76/76 [==============================] - 0s 1ms/step - loss: 191257230153089024.0000 - val_loss: 3671496689975296.0000\n",
            "Epoch 479/500\n",
            "76/76 [==============================] - 0s 1ms/step - loss: 33814801507418112.0000 - val_loss: 11526467083042816.0000\n",
            "Epoch 480/500\n",
            "76/76 [==============================] - 0s 1ms/step - loss: 893678721729298432.0000 - val_loss: 214008170136207360.0000\n",
            "Epoch 481/500\n",
            "76/76 [==============================] - 0s 1ms/step - loss: 11177230587691794432.0000 - val_loss: 3680645410549923840.0000\n",
            "Epoch 482/500\n",
            "76/76 [==============================] - 0s 1ms/step - loss: 388595962198622208.0000 - val_loss: 45396043382128640.0000\n",
            "Epoch 483/500\n",
            "76/76 [==============================] - 0s 1ms/step - loss: 92908655237660672.0000 - val_loss: 170551244358680576.0000\n",
            "Epoch 484/500\n",
            "76/76 [==============================] - 0s 1ms/step - loss: 25818259597033472.0000 - val_loss: 9853858641608704.0000\n",
            "Epoch 485/500\n",
            "76/76 [==============================] - 0s 1ms/step - loss: 150140443076591616.0000 - val_loss: 31661635617685504.0000\n",
            "Epoch 486/500\n",
            "76/76 [==============================] - 0s 1ms/step - loss: 87481465842958336.0000 - val_loss: 309463835469676544.0000\n",
            "Epoch 487/500\n",
            "76/76 [==============================] - 0s 1ms/step - loss: 10032077132735184896.0000 - val_loss: 35388531606900703232.0000\n",
            "Epoch 488/500\n",
            "76/76 [==============================] - 0s 1ms/step - loss: 36788843227757150208.0000 - val_loss: 24439687176484028416.0000\n",
            "Epoch 489/500\n",
            "76/76 [==============================] - 0s 1ms/step - loss: 2688456837883232256.0000 - val_loss: 11255159573822046208.0000\n",
            "Epoch 490/500\n",
            "76/76 [==============================] - 0s 1ms/step - loss: 13538131641666371584.0000 - val_loss: 92029299166711644160.0000\n",
            "Epoch 491/500\n",
            "76/76 [==============================] - 0s 1ms/step - loss: 15006521723979825152.0000 - val_loss: 1668263291740225536.0000\n",
            "Epoch 492/500\n",
            "76/76 [==============================] - 0s 1ms/step - loss: 694436563257393152.0000 - val_loss: 1955493936944381952.0000\n",
            "Epoch 493/500\n",
            "76/76 [==============================] - 0s 1ms/step - loss: 562515302730956800.0000 - val_loss: 76944081409802240.0000\n",
            "Epoch 494/500\n",
            "76/76 [==============================] - 0s 1ms/step - loss: 255823164276211712.0000 - val_loss: 188988439448780800.0000\n",
            "Epoch 495/500\n",
            "76/76 [==============================] - 0s 1ms/step - loss: 1228798939478622208.0000 - val_loss: 8588897752535007232.0000\n",
            "Epoch 496/500\n",
            "76/76 [==============================] - 0s 1ms/step - loss: 4998146763404607488.0000 - val_loss: 7578579607515824128.0000\n",
            "Epoch 497/500\n",
            "76/76 [==============================] - 0s 1ms/step - loss: 17147984446306123776.0000 - val_loss: 239622925592821760.0000\n",
            "Epoch 498/500\n",
            "76/76 [==============================] - 0s 1ms/step - loss: 4857503833049268224.0000 - val_loss: 50421610934737829888.0000\n",
            "Epoch 499/500\n",
            "76/76 [==============================] - 0s 2ms/step - loss: 3598633937745739776.0000 - val_loss: 2018362225114218496.0000\n",
            "Epoch 500/500\n",
            "76/76 [==============================] - 0s 1ms/step - loss: 1684099832592990208.0000 - val_loss: 18616580841668608.0000\n",
            "Training Set R2 is:\t-0.321\n",
            "TEsting Set R2 is:\t-0.925\n",
            "Epoch 1/500\n",
            "76/76 [==============================] - 0s 2ms/step - loss: 407842287895602790400.0000 - val_loss: 2821060414094180352.0000\n",
            "Epoch 2/500\n",
            "76/76 [==============================] - 0s 1ms/step - loss: 256887820835631398912.0000 - val_loss: 530304380069293850624.0000\n",
            "Epoch 3/500\n",
            "76/76 [==============================] - 0s 1ms/step - loss: 1502093605753717784576.0000 - val_loss: 1640431660670075797504.0000\n",
            "Epoch 4/500\n",
            "76/76 [==============================] - 0s 2ms/step - loss: 1285920260689980555264.0000 - val_loss: 7763609272528666624.0000\n",
            "Epoch 5/500\n",
            "76/76 [==============================] - 0s 1ms/step - loss: 94378225439548112896.0000 - val_loss: 6642338859394793472.0000\n",
            "Epoch 6/500\n",
            "76/76 [==============================] - 0s 1ms/step - loss: 147824553279879118848.0000 - val_loss: 10439175710965760000.0000\n",
            "Epoch 7/500\n",
            "76/76 [==============================] - 0s 1ms/step - loss: 78784687651638214656.0000 - val_loss: 645433380596602634240.0000\n",
            "Epoch 8/500\n",
            "76/76 [==============================] - 0s 1ms/step - loss: 76051864694940499968.0000 - val_loss: 133863368046751514624.0000\n",
            "Epoch 9/500\n",
            "76/76 [==============================] - 0s 1ms/step - loss: 158745008320066617344.0000 - val_loss: 1536513761186152448.0000\n",
            "Epoch 10/500\n",
            "76/76 [==============================] - 0s 1ms/step - loss: 42718014656120619008.0000 - val_loss: 136574227159172775936.0000\n",
            "Epoch 11/500\n",
            "76/76 [==============================] - 0s 1ms/step - loss: 114677672994339291136.0000 - val_loss: 272548367260184477696.0000\n",
            "Epoch 12/500\n",
            "76/76 [==============================] - 0s 1ms/step - loss: 323601401334474997760.0000 - val_loss: 72477264432110501888.0000\n",
            "Epoch 13/500\n",
            "76/76 [==============================] - 0s 1ms/step - loss: 249819509181403627520.0000 - val_loss: 1809572788925276094464.0000\n",
            "Epoch 14/500\n",
            "76/76 [==============================] - 0s 1ms/step - loss: 3079329208340158873600.0000 - val_loss: 1075577529031316209664.0000\n",
            "Epoch 15/500\n",
            "76/76 [==============================] - 0s 1ms/step - loss: 1881726647405239074816.0000 - val_loss: 587810140023745937408.0000\n",
            "Epoch 16/500\n",
            "76/76 [==============================] - 0s 1ms/step - loss: 78546524636968910848.0000 - val_loss: 473943765598339072.0000\n",
            "Epoch 17/500\n",
            "76/76 [==============================] - 0s 1ms/step - loss: 67033868236014747648.0000 - val_loss: 245983233947255963648.0000\n",
            "Epoch 18/500\n",
            "76/76 [==============================] - 0s 1ms/step - loss: 44951012820970897408.0000 - val_loss: 110203821753569902592.0000\n",
            "Epoch 19/500\n",
            "76/76 [==============================] - 0s 1ms/step - loss: 162157522976776388608.0000 - val_loss: 98458873730038759424.0000\n",
            "Epoch 20/500\n",
            "76/76 [==============================] - 0s 1ms/step - loss: 122722175052171706368.0000 - val_loss: 64331259858848317440.0000\n",
            "Epoch 21/500\n",
            "76/76 [==============================] - 0s 1ms/step - loss: 744014361689975685120.0000 - val_loss: 1515112949326492467200.0000\n",
            "Epoch 22/500\n",
            "76/76 [==============================] - 0s 1ms/step - loss: 737406314399227969536.0000 - val_loss: 4486026581624496324608.0000\n",
            "Epoch 23/500\n",
            "76/76 [==============================] - 0s 2ms/step - loss: 604691073986386198528.0000 - val_loss: 589597854671044608.0000\n",
            "Epoch 24/500\n",
            "76/76 [==============================] - 0s 1ms/step - loss: 2840905774341816320.0000 - val_loss: 6392371487889686528.0000\n",
            "Epoch 25/500\n",
            "76/76 [==============================] - 0s 1ms/step - loss: 2457146529434042368.0000 - val_loss: 412250855358595072.0000\n",
            "Epoch 26/500\n",
            "76/76 [==============================] - 0s 1ms/step - loss: 3577468064033144832.0000 - val_loss: 615556018532777984.0000\n",
            "Epoch 27/500\n",
            "76/76 [==============================] - 0s 1ms/step - loss: 494930453275344896.0000 - val_loss: 2296971049889169408.0000\n",
            "Epoch 28/500\n",
            "76/76 [==============================] - 0s 1ms/step - loss: 15320144221663395840.0000 - val_loss: 7502746290548113408.0000\n",
            "Epoch 29/500\n",
            "76/76 [==============================] - 0s 1ms/step - loss: 32220724258068758528.0000 - val_loss: 2565553153252524032.0000\n",
            "Epoch 30/500\n",
            "76/76 [==============================] - 0s 1ms/step - loss: 2071054808046895104.0000 - val_loss: 80086090504994816.0000\n",
            "Epoch 31/500\n",
            "76/76 [==============================] - 0s 2ms/step - loss: 8409902207335399424.0000 - val_loss: 23468015765669543936.0000\n",
            "Epoch 32/500\n",
            "76/76 [==============================] - 0s 1ms/step - loss: 13492888937206644736.0000 - val_loss: 17076980184407605248.0000\n",
            "Epoch 33/500\n",
            "76/76 [==============================] - 0s 1ms/step - loss: 22695644031528992768.0000 - val_loss: 1596185081859276800.0000\n",
            "Epoch 34/500\n",
            "76/76 [==============================] - 0s 1ms/step - loss: 1163562303262556160.0000 - val_loss: 360854253037682688.0000\n",
            "Epoch 35/500\n",
            "76/76 [==============================] - 0s 1ms/step - loss: 2480305817727795200.0000 - val_loss: 2062792527919972352.0000\n",
            "Epoch 36/500\n",
            "76/76 [==============================] - 0s 1ms/step - loss: 11583267037689937920.0000 - val_loss: 54549507748134912.0000\n",
            "Epoch 37/500\n",
            "76/76 [==============================] - 0s 1ms/step - loss: 722139308475023360.0000 - val_loss: 209051554538323968.0000\n",
            "Epoch 38/500\n",
            "76/76 [==============================] - 0s 1ms/step - loss: 1299846769525391360.0000 - val_loss: 106168702040562204672.0000\n",
            "Epoch 39/500\n",
            "76/76 [==============================] - 0s 1ms/step - loss: 78129528255065096192.0000 - val_loss: 61579151468199411712.0000\n",
            "Epoch 40/500\n",
            "76/76 [==============================] - 0s 1ms/step - loss: 77581276573083893760.0000 - val_loss: 903746203686203817984.0000\n",
            "Epoch 41/500\n",
            "76/76 [==============================] - 0s 1ms/step - loss: 29718274408098950021120.0000 - val_loss: 94377415776777604694016.0000\n",
            "Epoch 42/500\n",
            "76/76 [==============================] - 0s 1ms/step - loss: 6985566033111674781696.0000 - val_loss: 7326506539302130810880.0000\n",
            "Epoch 43/500\n",
            "76/76 [==============================] - 0s 1ms/step - loss: 1054839930490902806528.0000 - val_loss: 397569190117477711872.0000\n",
            "Epoch 44/500\n",
            "76/76 [==============================] - 0s 1ms/step - loss: 172478436316570189824.0000 - val_loss: 15100602535922106368.0000\n",
            "Epoch 45/500\n",
            "76/76 [==============================] - 0s 1ms/step - loss: 7715318172080930816.0000 - val_loss: 14339317177524420608.0000\n",
            "Epoch 46/500\n",
            "76/76 [==============================] - 0s 1ms/step - loss: 1541701531923906560.0000 - val_loss: 233357977057230848.0000\n",
            "Epoch 47/500\n",
            "76/76 [==============================] - 0s 1ms/step - loss: 151000226809774080.0000 - val_loss: 6492684881494016.0000\n",
            "Epoch 48/500\n",
            "76/76 [==============================] - 0s 1ms/step - loss: 13831250687033344.0000 - val_loss: 22072146171789312.0000\n",
            "Epoch 49/500\n",
            "76/76 [==============================] - 0s 1ms/step - loss: 15903706625081344.0000 - val_loss: 5648193379368960.0000\n",
            "Epoch 50/500\n",
            "76/76 [==============================] - 0s 1ms/step - loss: 4823090433359872.0000 - val_loss: 5139839976472576.0000\n",
            "Epoch 51/500\n",
            "76/76 [==============================] - 0s 1ms/step - loss: 53716249732972544.0000 - val_loss: 10837889336213504.0000\n",
            "Epoch 52/500\n",
            "76/76 [==============================] - 0s 1ms/step - loss: 10951985142431744.0000 - val_loss: 7991830331260928.0000\n",
            "Epoch 53/500\n",
            "76/76 [==============================] - 0s 1ms/step - loss: 3542541639090176.0000 - val_loss: 8904540409561088.0000\n",
            "Epoch 54/500\n",
            "76/76 [==============================] - 0s 1ms/step - loss: 4121022194253824.0000 - val_loss: 4717950170824704.0000\n",
            "Epoch 55/500\n",
            "76/76 [==============================] - 0s 1ms/step - loss: 5861974302785536.0000 - val_loss: 6632366881636352.0000\n",
            "Epoch 56/500\n",
            "76/76 [==============================] - 0s 1ms/step - loss: 4013288308342784.0000 - val_loss: 8484502808559616.0000\n",
            "Epoch 57/500\n",
            "76/76 [==============================] - 0s 1ms/step - loss: 4799028415954944.0000 - val_loss: 7854965292793856.0000\n",
            "Epoch 58/500\n",
            "76/76 [==============================] - 0s 1ms/step - loss: 14258265999278080.0000 - val_loss: 22057609854976000.0000\n",
            "Epoch 59/500\n",
            "76/76 [==============================] - 0s 1ms/step - loss: 9999693182402560.0000 - val_loss: 27838474774118400.0000\n",
            "Epoch 60/500\n",
            "76/76 [==============================] - 0s 1ms/step - loss: 4430862477164544.0000 - val_loss: 18842515448791040.0000\n",
            "Epoch 61/500\n",
            "76/76 [==============================] - 0s 2ms/step - loss: 6215993961480192.0000 - val_loss: 7142360962039808.0000\n",
            "Epoch 62/500\n",
            "76/76 [==============================] - 0s 1ms/step - loss: 6559384649859072.0000 - val_loss: 9250532774379520.0000\n",
            "Epoch 63/500\n",
            "76/76 [==============================] - 0s 1ms/step - loss: 5278126112243712.0000 - val_loss: 6660232092581888.0000\n",
            "Epoch 64/500\n",
            "76/76 [==============================] - 0s 1ms/step - loss: 3609247849906176.0000 - val_loss: 9437809454612480.0000\n",
            "Epoch 65/500\n",
            "76/76 [==============================] - 0s 1ms/step - loss: 6006984209858560.0000 - val_loss: 9454208713490432.0000\n",
            "Epoch 66/500\n",
            "76/76 [==============================] - 0s 1ms/step - loss: 4809526926639104.0000 - val_loss: 4173773251018752.0000\n",
            "Epoch 67/500\n",
            "76/76 [==============================] - 0s 1ms/step - loss: 151267305056108544.0000 - val_loss: 177428981648195584.0000\n",
            "Epoch 68/500\n",
            "76/76 [==============================] - 0s 1ms/step - loss: 320379134075207680.0000 - val_loss: 523817716113473536.0000\n",
            "Epoch 69/500\n",
            "76/76 [==============================] - 0s 1ms/step - loss: 702712312401756160.0000 - val_loss: 16611084517507072.0000\n",
            "Epoch 70/500\n",
            "76/76 [==============================] - 0s 1ms/step - loss: 53135973881479168.0000 - val_loss: 25507095658889216.0000\n",
            "Epoch 71/500\n",
            "76/76 [==============================] - 0s 1ms/step - loss: 1185616994687254528.0000 - val_loss: 210247857549082624.0000\n",
            "Epoch 72/500\n",
            "76/76 [==============================] - 0s 1ms/step - loss: 4285476861384851456.0000 - val_loss: 297261043107758080.0000\n",
            "Epoch 73/500\n",
            "76/76 [==============================] - 0s 1ms/step - loss: 352344823312678912.0000 - val_loss: 34687682743369728.0000\n",
            "Epoch 74/500\n",
            "76/76 [==============================] - 0s 1ms/step - loss: 56615653305483264.0000 - val_loss: 181243616981680128.0000\n",
            "Epoch 75/500\n",
            "76/76 [==============================] - 0s 1ms/step - loss: 30797312104071168.0000 - val_loss: 28046802162810880.0000\n",
            "Epoch 76/500\n",
            "76/76 [==============================] - 0s 1ms/step - loss: 27211933534912512.0000 - val_loss: 55429954568978432.0000\n",
            "Epoch 77/500\n",
            "76/76 [==============================] - 0s 1ms/step - loss: 1386662833265049600.0000 - val_loss: 3049819855566929920.0000\n",
            "Epoch 78/500\n",
            "76/76 [==============================] - 0s 1ms/step - loss: 3852268180529479680.0000 - val_loss: 12846564116562706432.0000\n",
            "Epoch 79/500\n",
            "76/76 [==============================] - 0s 1ms/step - loss: 999913535205015552.0000 - val_loss: 472067655163969536.0000\n",
            "Epoch 80/500\n",
            "76/76 [==============================] - 0s 1ms/step - loss: 114791857208164352.0000 - val_loss: 17913236997275648.0000\n",
            "Epoch 81/500\n",
            "76/76 [==============================] - 0s 2ms/step - loss: 2180570289341988864.0000 - val_loss: 3615555971453026304.0000\n",
            "Epoch 82/500\n",
            "76/76 [==============================] - 0s 1ms/step - loss: 166234372729470976.0000 - val_loss: 53129393991581696.0000\n",
            "Epoch 83/500\n",
            "76/76 [==============================] - 0s 1ms/step - loss: 20498708525219840.0000 - val_loss: 27956277137113088.0000\n",
            "Epoch 84/500\n",
            "76/76 [==============================] - 0s 1ms/step - loss: 36546065700225024.0000 - val_loss: 5671806572691456.0000\n",
            "Epoch 85/500\n",
            "76/76 [==============================] - 0s 1ms/step - loss: 1866797570882273280.0000 - val_loss: 2389900123401355264.0000\n",
            "Epoch 86/500\n",
            "76/76 [==============================] - 0s 1ms/step - loss: 47381813127658078208.0000 - val_loss: 576159046312761753600.0000\n",
            "Epoch 87/500\n",
            "76/76 [==============================] - 0s 1ms/step - loss: 4697566567096599445504.0000 - val_loss: 8501944353195970002944.0000\n",
            "Epoch 88/500\n",
            "76/76 [==============================] - 0s 1ms/step - loss: 1454495764979480788992.0000 - val_loss: 110741113503645433856.0000\n",
            "Epoch 89/500\n",
            "76/76 [==============================] - 0s 1ms/step - loss: 118444784549053333504.0000 - val_loss: 165362924827185250304.0000\n",
            "Epoch 90/500\n",
            "76/76 [==============================] - 0s 1ms/step - loss: 96555891781242191872.0000 - val_loss: 6096879936948142080.0000\n",
            "Epoch 91/500\n",
            "76/76 [==============================] - 0s 1ms/step - loss: 41584739225278873600.0000 - val_loss: 22934699849640050688.0000\n",
            "Epoch 92/500\n",
            "76/76 [==============================] - 0s 1ms/step - loss: 47617187780839342080.0000 - val_loss: 17718457258284679168.0000\n",
            "Epoch 93/500\n",
            "76/76 [==============================] - 0s 1ms/step - loss: 5461824560733093888.0000 - val_loss: 52537304403043942400.0000\n",
            "Epoch 94/500\n",
            "76/76 [==============================] - 0s 1ms/step - loss: 64651516809693888512.0000 - val_loss: 601584082824709799936.0000\n",
            "Epoch 95/500\n",
            "76/76 [==============================] - 0s 1ms/step - loss: 1871765951666890735616.0000 - val_loss: 2763463618974994923520.0000\n",
            "Epoch 96/500\n",
            "76/76 [==============================] - 0s 1ms/step - loss: 2607817245528233607168.0000 - val_loss: 374939376046126923776.0000\n",
            "Epoch 97/500\n",
            "76/76 [==============================] - 0s 1ms/step - loss: 1305144579386853294080.0000 - val_loss: 17564943444814594048.0000\n",
            "Epoch 98/500\n",
            "76/76 [==============================] - 0s 1ms/step - loss: 256900381656467111936.0000 - val_loss: 25452284609107591168.0000\n",
            "Epoch 99/500\n",
            "76/76 [==============================] - 0s 1ms/step - loss: 295252789792549634048.0000 - val_loss: 2000631810666981752832.0000\n",
            "Epoch 100/500\n",
            "76/76 [==============================] - 0s 1ms/step - loss: 941667568079826059264.0000 - val_loss: 78281489558116761600.0000\n",
            "Epoch 101/500\n",
            "76/76 [==============================] - 0s 1ms/step - loss: 3144304610489069993984.0000 - val_loss: 1553035369251277373440.0000\n",
            "Epoch 102/500\n",
            "76/76 [==============================] - 0s 1ms/step - loss: 184555788695410573312.0000 - val_loss: 4156216900033970176.0000\n",
            "Epoch 103/500\n",
            "76/76 [==============================] - 0s 1ms/step - loss: 5215622466797305856.0000 - val_loss: 70109993907276218368.0000\n",
            "Epoch 104/500\n",
            "76/76 [==============================] - 0s 1ms/step - loss: 42408686850855141376.0000 - val_loss: 77137874319927410688.0000\n",
            "Epoch 105/500\n",
            "76/76 [==============================] - 0s 1ms/step - loss: 13203567845520179200.0000 - val_loss: 3748530357960441856.0000\n",
            "Epoch 106/500\n",
            "76/76 [==============================] - 0s 1ms/step - loss: 12259308359097778176.0000 - val_loss: 2789192718830534656.0000\n",
            "Epoch 107/500\n",
            "76/76 [==============================] - 0s 1ms/step - loss: 28634860598123823104.0000 - val_loss: 12749037435178975232.0000\n",
            "Epoch 108/500\n",
            "76/76 [==============================] - 0s 1ms/step - loss: 14949639589428461568.0000 - val_loss: 21260372338955780096.0000\n",
            "Epoch 109/500\n",
            "76/76 [==============================] - 0s 1ms/step - loss: 53061894594795405312.0000 - val_loss: 9128002047528927232.0000\n",
            "Epoch 110/500\n",
            "76/76 [==============================] - 0s 1ms/step - loss: 57486975897803161600.0000 - val_loss: 20469192358910492672.0000\n",
            "Epoch 111/500\n",
            "76/76 [==============================] - 0s 1ms/step - loss: 5878337157520687104.0000 - val_loss: 5070039430698369024.0000\n",
            "Epoch 112/500\n",
            "76/76 [==============================] - 0s 1ms/step - loss: 6169134893323255808.0000 - val_loss: 31971115327354306560.0000\n",
            "Epoch 113/500\n",
            "76/76 [==============================] - 0s 2ms/step - loss: 6872578793274343424.0000 - val_loss: 570576028632612864.0000\n",
            "Epoch 114/500\n",
            "76/76 [==============================] - 0s 2ms/step - loss: 387265518769274880.0000 - val_loss: 217448112522788864.0000\n",
            "Epoch 115/500\n",
            "76/76 [==============================] - 0s 1ms/step - loss: 2741840051557105664.0000 - val_loss: 5631183986026872832.0000\n",
            "Epoch 116/500\n",
            "76/76 [==============================] - 0s 1ms/step - loss: 4190953770890297344.0000 - val_loss: 38833765530629832704.0000\n",
            "Epoch 117/500\n",
            "76/76 [==============================] - 0s 1ms/step - loss: 11078233859261726720.0000 - val_loss: 11149404147416039424.0000\n",
            "Epoch 118/500\n",
            "76/76 [==============================] - 0s 1ms/step - loss: 107466248906640195584.0000 - val_loss: 66992623355833614336.0000\n",
            "Epoch 119/500\n",
            "76/76 [==============================] - 0s 1ms/step - loss: 78115894310880673792.0000 - val_loss: 13938470422409379840.0000\n",
            "Epoch 120/500\n",
            "76/76 [==============================] - 0s 1ms/step - loss: 320753226413884047360.0000 - val_loss: 867192948416883720192.0000\n",
            "Epoch 121/500\n",
            "76/76 [==============================] - 0s 1ms/step - loss: 206397191356994813952.0000 - val_loss: 171111470684360933376.0000\n",
            "Epoch 122/500\n",
            "76/76 [==============================] - 0s 2ms/step - loss: 70157910624014696448.0000 - val_loss: 9424342971202928640.0000\n",
            "Epoch 123/500\n",
            "76/76 [==============================] - 0s 1ms/step - loss: 24847452058761035776.0000 - val_loss: 5322726993970593792.0000\n",
            "Epoch 124/500\n",
            "76/76 [==============================] - 0s 1ms/step - loss: 1052059523419734016.0000 - val_loss: 31320894937013157888.0000\n",
            "Epoch 125/500\n",
            "76/76 [==============================] - 0s 2ms/step - loss: 431794928804377395200.0000 - val_loss: 164021080836647419904.0000\n",
            "Epoch 126/500\n",
            "76/76 [==============================] - 0s 1ms/step - loss: 151202552067569745920.0000 - val_loss: 294169656489980985344.0000\n",
            "Epoch 127/500\n",
            "76/76 [==============================] - 0s 1ms/step - loss: 4448408858362000703488.0000 - val_loss: 6388332990476958302208.0000\n",
            "Epoch 128/500\n",
            "76/76 [==============================] - 0s 1ms/step - loss: 13380740554372562288640.0000 - val_loss: 588646542917041651712.0000\n",
            "Epoch 129/500\n",
            "76/76 [==============================] - 0s 1ms/step - loss: 1071980560303930736640.0000 - val_loss: 99552474383303835648.0000\n",
            "Epoch 130/500\n",
            "76/76 [==============================] - 0s 1ms/step - loss: 394517931001190023168.0000 - val_loss: 5034171514220781240320.0000\n",
            "Epoch 131/500\n",
            "76/76 [==============================] - 0s 1ms/step - loss: 2039254258858846060544.0000 - val_loss: 53208846522870923264.0000\n",
            "Epoch 132/500\n",
            "76/76 [==============================] - 0s 1ms/step - loss: 401800568257996914688.0000 - val_loss: 798716841982622171136.0000\n",
            "Epoch 133/500\n",
            "76/76 [==============================] - 0s 1ms/step - loss: 404340844738438496256.0000 - val_loss: 12419562178846130176.0000\n",
            "Epoch 134/500\n",
            "76/76 [==============================] - 0s 2ms/step - loss: 2472920123246116864.0000 - val_loss: 102181017183322112.0000\n",
            "Epoch 135/500\n",
            "76/76 [==============================] - 0s 1ms/step - loss: 14912337978851328.0000 - val_loss: 10348120256806912.0000\n",
            "Epoch 136/500\n",
            "76/76 [==============================] - 0s 2ms/step - loss: 6020739916365824.0000 - val_loss: 8108870337560576.0000\n",
            "Epoch 137/500\n",
            "76/76 [==============================] - 0s 2ms/step - loss: 3540406771908608.0000 - val_loss: 5279910671155200.0000\n",
            "Epoch 138/500\n",
            "76/76 [==============================] - 0s 1ms/step - loss: 7425711228846080.0000 - val_loss: 24212326227902464.0000\n",
            "Epoch 139/500\n",
            "76/76 [==============================] - 0s 1ms/step - loss: 8131211146821632.0000 - val_loss: 4833313529266176.0000\n",
            "Epoch 140/500\n",
            "76/76 [==============================] - 0s 1ms/step - loss: 8034833154441216.0000 - val_loss: 10049094969982976.0000\n",
            "Epoch 141/500\n",
            "76/76 [==============================] - 0s 1ms/step - loss: 9902591488032768.0000 - val_loss: 7826821445844992.0000\n",
            "Epoch 142/500\n",
            "76/76 [==============================] - 0s 1ms/step - loss: 7382982209830912.0000 - val_loss: 8497592258265088.0000\n",
            "Epoch 143/500\n",
            "76/76 [==============================] - 0s 1ms/step - loss: 14035987483066368.0000 - val_loss: 16936122273759232.0000\n",
            "Epoch 144/500\n",
            "76/76 [==============================] - 0s 1ms/step - loss: 51651358306074624.0000 - val_loss: 16623483014348800.0000\n",
            "Epoch 145/500\n",
            "76/76 [==============================] - 0s 1ms/step - loss: 91104691663929344.0000 - val_loss: 28671827278561280.0000\n",
            "Epoch 146/500\n",
            "76/76 [==============================] - 0s 1ms/step - loss: 14343900130967552.0000 - val_loss: 68425791167266816.0000\n",
            "Epoch 147/500\n",
            "76/76 [==============================] - 0s 1ms/step - loss: 29913951147917312.0000 - val_loss: 30794569767452672.0000\n",
            "Epoch 148/500\n",
            "76/76 [==============================] - 0s 1ms/step - loss: 49907197856972800.0000 - val_loss: 55430280986492928.0000\n",
            "Epoch 149/500\n",
            "76/76 [==============================] - 0s 1ms/step - loss: 82829689843875840.0000 - val_loss: 44757557838872576.0000\n",
            "Epoch 150/500\n",
            "76/76 [==============================] - 0s 1ms/step - loss: 68263471468249088.0000 - val_loss: 245769848427118592.0000\n",
            "Epoch 151/500\n",
            "76/76 [==============================] - 0s 1ms/step - loss: 2034103795650134016.0000 - val_loss: 326099343318712320.0000\n",
            "Epoch 152/500\n",
            "76/76 [==============================] - 0s 1ms/step - loss: 178979585101135872.0000 - val_loss: 76828830257381376.0000\n",
            "Epoch 153/500\n",
            "76/76 [==============================] - 0s 1ms/step - loss: 165337446119112704.0000 - val_loss: 399171511711170560.0000\n",
            "Epoch 154/500\n",
            "76/76 [==============================] - 0s 1ms/step - loss: 616116425865560064.0000 - val_loss: 818597264556556288.0000\n",
            "Epoch 155/500\n",
            "76/76 [==============================] - 0s 1ms/step - loss: 334837643260985344.0000 - val_loss: 68631451381268480.0000\n",
            "Epoch 156/500\n",
            "76/76 [==============================] - 0s 1ms/step - loss: 36646752618545152.0000 - val_loss: 141218602001891328.0000\n",
            "Epoch 157/500\n",
            "76/76 [==============================] - 0s 1ms/step - loss: 126692670419501056.0000 - val_loss: 2053263472958898176.0000\n",
            "Epoch 158/500\n",
            "76/76 [==============================] - 0s 1ms/step - loss: 162854456805818368.0000 - val_loss: 73395854307753984.0000\n",
            "Epoch 159/500\n",
            "76/76 [==============================] - 0s 1ms/step - loss: 15396151012360192.0000 - val_loss: 11683676844720128.0000\n",
            "Epoch 160/500\n",
            "76/76 [==============================] - 0s 1ms/step - loss: 170138343382712320.0000 - val_loss: 135052437714108416.0000\n",
            "Epoch 161/500\n",
            "76/76 [==============================] - 0s 1ms/step - loss: 4412581779945291776.0000 - val_loss: 802267798897164288.0000\n",
            "Epoch 162/500\n",
            "76/76 [==============================] - 0s 2ms/step - loss: 8954200595258933248.0000 - val_loss: 4298197386284498944.0000\n",
            "Epoch 163/500\n",
            "76/76 [==============================] - 0s 1ms/step - loss: 4053994479365914624.0000 - val_loss: 20954545378713141248.0000\n",
            "Epoch 164/500\n",
            "76/76 [==============================] - 0s 1ms/step - loss: 72446157049137463296.0000 - val_loss: 226185058141614374912.0000\n",
            "Epoch 165/500\n",
            "76/76 [==============================] - 0s 1ms/step - loss: 276293039981598867456.0000 - val_loss: 86235427042192523264.0000\n",
            "Epoch 166/500\n",
            "76/76 [==============================] - 0s 1ms/step - loss: 687244658799621963776.0000 - val_loss: 52273716281493946368.0000\n",
            "Epoch 167/500\n",
            "76/76 [==============================] - 0s 1ms/step - loss: 942644849198965456896.0000 - val_loss: 220928671281217273856.0000\n",
            "Epoch 168/500\n",
            "76/76 [==============================] - 0s 1ms/step - loss: 689007114366295736320.0000 - val_loss: 786549171320629755904.0000\n",
            "Epoch 169/500\n",
            "76/76 [==============================] - 0s 1ms/step - loss: 6713359464434147262464.0000 - val_loss: 2709825184463058894848.0000\n",
            "Epoch 170/500\n",
            "76/76 [==============================] - 0s 1ms/step - loss: 459520952882190876672.0000 - val_loss: 10656441407637553152.0000\n",
            "Epoch 171/500\n",
            "76/76 [==============================] - 0s 2ms/step - loss: 339360938989900005376.0000 - val_loss: 14693043262319493120.0000\n",
            "Epoch 172/500\n",
            "76/76 [==============================] - 0s 1ms/step - loss: 122200179707861794816.0000 - val_loss: 436188753190830735360.0000\n",
            "Epoch 173/500\n",
            "76/76 [==============================] - 0s 1ms/step - loss: 115081712731221393408.0000 - val_loss: 11520259523860234240.0000\n",
            "Epoch 174/500\n",
            "76/76 [==============================] - 0s 1ms/step - loss: 27659857667077177344.0000 - val_loss: 184889107844394123264.0000\n",
            "Epoch 175/500\n",
            "76/76 [==============================] - 0s 2ms/step - loss: 122041075977276096512.0000 - val_loss: 267823246826142695424.0000\n",
            "Epoch 176/500\n",
            "76/76 [==============================] - 0s 1ms/step - loss: 462159851157597454336.0000 - val_loss: 6976510129889869824.0000\n",
            "Epoch 177/500\n",
            "76/76 [==============================] - 0s 1ms/step - loss: 199652224082263408640.0000 - val_loss: 130986377125419810816.0000\n",
            "Epoch 178/500\n",
            "76/76 [==============================] - 0s 1ms/step - loss: 49077088533874737152.0000 - val_loss: 624856306355798016.0000\n",
            "Epoch 179/500\n",
            "76/76 [==============================] - 0s 1ms/step - loss: 40439580272764125184.0000 - val_loss: 29448417838817607680.0000\n",
            "Epoch 180/500\n",
            "76/76 [==============================] - 0s 1ms/step - loss: 18668585937776148480.0000 - val_loss: 102875735084117262336.0000\n",
            "Epoch 181/500\n",
            "76/76 [==============================] - 0s 1ms/step - loss: 100194545193459908608.0000 - val_loss: 59234209825502003200.0000\n",
            "Epoch 182/500\n",
            "76/76 [==============================] - 0s 1ms/step - loss: 53383193882664108032.0000 - val_loss: 2471887681827635200.0000\n",
            "Epoch 183/500\n",
            "76/76 [==============================] - 0s 1ms/step - loss: 4707441386578771968.0000 - val_loss: 4878760141593247744.0000\n",
            "Epoch 184/500\n",
            "76/76 [==============================] - 0s 1ms/step - loss: 22493965011692552192.0000 - val_loss: 43100050966307667968.0000\n",
            "Epoch 185/500\n",
            "76/76 [==============================] - 0s 1ms/step - loss: 356082734037582479360.0000 - val_loss: 544506798153555509248.0000\n",
            "Epoch 186/500\n",
            "76/76 [==============================] - 0s 1ms/step - loss: 65604925332371013632.0000 - val_loss: 684233645107445760.0000\n",
            "Epoch 187/500\n",
            "76/76 [==============================] - 0s 1ms/step - loss: 3366914885848924160.0000 - val_loss: 386605605634179072.0000\n",
            "Epoch 188/500\n",
            "76/76 [==============================] - 0s 1ms/step - loss: 1819420027158265856.0000 - val_loss: 277585024830668800.0000\n",
            "Epoch 189/500\n",
            "76/76 [==============================] - 0s 1ms/step - loss: 2729915847953874944.0000 - val_loss: 3245957611677286400.0000\n",
            "Epoch 190/500\n",
            "76/76 [==============================] - 0s 1ms/step - loss: 516721742945714176.0000 - val_loss: 631389741886996480.0000\n",
            "Epoch 191/500\n",
            "76/76 [==============================] - 0s 1ms/step - loss: 138948503772099248128.0000 - val_loss: 10200030832412852224.0000\n",
            "Epoch 192/500\n",
            "76/76 [==============================] - 0s 1ms/step - loss: 37829524386377367552.0000 - val_loss: 20538127339925536768.0000\n",
            "Epoch 193/500\n",
            "76/76 [==============================] - 0s 1ms/step - loss: 782013624283402600448.0000 - val_loss: 162045795003208302592.0000\n",
            "Epoch 194/500\n",
            "76/76 [==============================] - 0s 1ms/step - loss: 438677062353697112064.0000 - val_loss: 76295929888027705344.0000\n",
            "Epoch 195/500\n",
            "76/76 [==============================] - 0s 1ms/step - loss: 330860078033889394688.0000 - val_loss: 1397214340581467095040.0000\n",
            "Epoch 196/500\n",
            "76/76 [==============================] - 0s 1ms/step - loss: 1032736967207210188800.0000 - val_loss: 22615194964747878400.0000\n",
            "Epoch 197/500\n",
            "76/76 [==============================] - 0s 1ms/step - loss: 12188874743734075392.0000 - val_loss: 6513702046258954240.0000\n",
            "Epoch 198/500\n",
            "76/76 [==============================] - 0s 1ms/step - loss: 75092844264915206144.0000 - val_loss: 8980945116092956672.0000\n",
            "Epoch 199/500\n",
            "76/76 [==============================] - 0s 1ms/step - loss: 14544404683406966784.0000 - val_loss: 2635661038296498176.0000\n",
            "Epoch 200/500\n",
            "76/76 [==============================] - 0s 1ms/step - loss: 12811710697473835008.0000 - val_loss: 838529788588484198400.0000\n",
            "Epoch 201/500\n",
            "76/76 [==============================] - 0s 1ms/step - loss: 53522312889903349760.0000 - val_loss: 11226787775778914304.0000\n",
            "Epoch 202/500\n",
            "76/76 [==============================] - 0s 1ms/step - loss: 155539500916541489152.0000 - val_loss: 96346922999313596416.0000\n",
            "Epoch 203/500\n",
            "76/76 [==============================] - 0s 1ms/step - loss: 401194763739371405312.0000 - val_loss: 186083634868996014080.0000\n",
            "Epoch 204/500\n",
            "76/76 [==============================] - 0s 1ms/step - loss: 529690694251320442880.0000 - val_loss: 524535902265329844224.0000\n",
            "Epoch 205/500\n",
            "76/76 [==============================] - 0s 1ms/step - loss: 416518683683964583936.0000 - val_loss: 364124403753461743616.0000\n",
            "Epoch 206/500\n",
            "76/76 [==============================] - 0s 1ms/step - loss: 729330093629957472256.0000 - val_loss: 1314876154494159159296.0000\n",
            "Epoch 207/500\n",
            "76/76 [==============================] - 0s 1ms/step - loss: 143312658936788680704.0000 - val_loss: 399020686203630387200.0000\n",
            "Epoch 208/500\n",
            "76/76 [==============================] - 0s 1ms/step - loss: 357564172024382750720.0000 - val_loss: 33460194919967621120.0000\n",
            "Epoch 209/500\n",
            "76/76 [==============================] - 0s 1ms/step - loss: 152754059731384926208.0000 - val_loss: 89492734637525434368.0000\n",
            "Epoch 210/500\n",
            "76/76 [==============================] - 0s 1ms/step - loss: 84644477697265762304.0000 - val_loss: 194731257400131584.0000\n",
            "Epoch 211/500\n",
            "76/76 [==============================] - 0s 1ms/step - loss: 37665112213652766720.0000 - val_loss: 67523071745537867776.0000\n",
            "Epoch 212/500\n",
            "76/76 [==============================] - 0s 1ms/step - loss: 37005282091684855808.0000 - val_loss: 75048846207618121728.0000\n",
            "Epoch 213/500\n",
            "76/76 [==============================] - 0s 1ms/step - loss: 2818868027490813607936.0000 - val_loss: 9523191300747618680832.0000\n",
            "Epoch 214/500\n",
            "76/76 [==============================] - 0s 1ms/step - loss: 2013441455382106996736.0000 - val_loss: 2497111303202537472.0000\n",
            "Epoch 215/500\n",
            "76/76 [==============================] - 0s 2ms/step - loss: 1692387015558770458624.0000 - val_loss: 1491694934951607664640.0000\n",
            "Epoch 216/500\n",
            "76/76 [==============================] - 0s 1ms/step - loss: 4167526386477320634368.0000 - val_loss: 14343050582450673549312.0000\n",
            "Epoch 217/500\n",
            "76/76 [==============================] - 0s 1ms/step - loss: 1071979715879000604672.0000 - val_loss: 41784867933720150016.0000\n",
            "Epoch 218/500\n",
            "76/76 [==============================] - 0s 1ms/step - loss: 155033356131857596416.0000 - val_loss: 355020060447383486464.0000\n",
            "Epoch 219/500\n",
            "76/76 [==============================] - 0s 1ms/step - loss: 76761392742483886080.0000 - val_loss: 7132630335673597952.0000\n",
            "Epoch 220/500\n",
            "76/76 [==============================] - 0s 1ms/step - loss: 18748960237766574080.0000 - val_loss: 34957437286905544704.0000\n",
            "Epoch 221/500\n",
            "76/76 [==============================] - 0s 1ms/step - loss: 5598310237623812096.0000 - val_loss: 1106808605413212160.0000\n",
            "Epoch 222/500\n",
            "76/76 [==============================] - 0s 1ms/step - loss: 1024470096619241472.0000 - val_loss: 1699029551230746624.0000\n",
            "Epoch 223/500\n",
            "76/76 [==============================] - 0s 1ms/step - loss: 2108472838007554048.0000 - val_loss: 8485206109454336000.0000\n",
            "Epoch 224/500\n",
            "76/76 [==============================] - 0s 1ms/step - loss: 2438155489721188352.0000 - val_loss: 5108020960368263168.0000\n",
            "Epoch 225/500\n",
            "76/76 [==============================] - 0s 1ms/step - loss: 1789707649562968064.0000 - val_loss: 82555181304119296.0000\n",
            "Epoch 226/500\n",
            "76/76 [==============================] - 0s 1ms/step - loss: 5822814019341254656.0000 - val_loss: 4215223840806010880.0000\n",
            "Epoch 227/500\n",
            "76/76 [==============================] - 0s 1ms/step - loss: 4295628652244107264.0000 - val_loss: 36328774577346838528.0000\n",
            "Epoch 228/500\n",
            "76/76 [==============================] - 0s 1ms/step - loss: 2110485219164291072.0000 - val_loss: 2356792728777392128.0000\n",
            "Epoch 229/500\n",
            "76/76 [==============================] - 0s 1ms/step - loss: 281887310750941184.0000 - val_loss: 4293724171403264.0000\n",
            "Epoch 230/500\n",
            "76/76 [==============================] - 0s 1ms/step - loss: 12102227850166272.0000 - val_loss: 116987161022038016.0000\n",
            "Epoch 231/500\n",
            "76/76 [==============================] - 0s 1ms/step - loss: 362593989670469632.0000 - val_loss: 895375062012526592.0000\n",
            "Epoch 232/500\n",
            "76/76 [==============================] - 0s 1ms/step - loss: 384095386228228096.0000 - val_loss: 6449475363012608.0000\n",
            "Epoch 233/500\n",
            "76/76 [==============================] - 0s 1ms/step - loss: 7617759080873984.0000 - val_loss: 5959873250459648.0000\n",
            "Epoch 234/500\n",
            "76/76 [==============================] - 0s 1ms/step - loss: 6751299894771712.0000 - val_loss: 4833459558154240.0000\n",
            "Epoch 235/500\n",
            "76/76 [==============================] - 0s 1ms/step - loss: 6632756649918464.0000 - val_loss: 11146444081725440.0000\n",
            "Epoch 236/500\n",
            "76/76 [==============================] - 0s 2ms/step - loss: 11770572623052800.0000 - val_loss: 27006043540160512.0000\n",
            "Epoch 237/500\n",
            "76/76 [==============================] - 0s 2ms/step - loss: 82191114106306560.0000 - val_loss: 528772356026400768.0000\n",
            "Epoch 238/500\n",
            "76/76 [==============================] - 0s 1ms/step - loss: 297907384146198528.0000 - val_loss: 32231036611985408.0000\n",
            "Epoch 239/500\n",
            "76/76 [==============================] - 0s 1ms/step - loss: 71362947502309376.0000 - val_loss: 1169432595843252224.0000\n",
            "Epoch 240/500\n",
            "76/76 [==============================] - 0s 1ms/step - loss: 1008224881038327808.0000 - val_loss: 58720397733920768.0000\n",
            "Epoch 241/500\n",
            "76/76 [==============================] - 0s 1ms/step - loss: 132929040242704384.0000 - val_loss: 703735751568785408.0000\n",
            "Epoch 242/500\n",
            "76/76 [==============================] - 0s 1ms/step - loss: 188232130067693568.0000 - val_loss: 32438264489050112.0000\n",
            "Epoch 243/500\n",
            "76/76 [==============================] - 0s 1ms/step - loss: 29582556058383024128.0000 - val_loss: 499961518317373489152.0000\n",
            "Epoch 244/500\n",
            "76/76 [==============================] - 0s 1ms/step - loss: 246388909757440196608.0000 - val_loss: 2496806047988341276672.0000\n",
            "Epoch 245/500\n",
            "76/76 [==============================] - 0s 1ms/step - loss: 6591234227438834679808.0000 - val_loss: 727990202372070572032.0000\n",
            "Epoch 246/500\n",
            "76/76 [==============================] - 0s 1ms/step - loss: 943729513021719969792.0000 - val_loss: 826742812832492945408.0000\n",
            "Epoch 247/500\n",
            "76/76 [==============================] - 0s 1ms/step - loss: 1546675442152500101120.0000 - val_loss: 340512488303995387904.0000\n",
            "Epoch 248/500\n",
            "76/76 [==============================] - 0s 1ms/step - loss: 258452663376468246528.0000 - val_loss: 39899214288177332224.0000\n",
            "Epoch 249/500\n",
            "76/76 [==============================] - 0s 1ms/step - loss: 17085853243243757568.0000 - val_loss: 1154522530975842304.0000\n",
            "Epoch 250/500\n",
            "76/76 [==============================] - 0s 1ms/step - loss: 5026734615482597376.0000 - val_loss: 49372795589095325696.0000\n",
            "Epoch 251/500\n",
            "76/76 [==============================] - 0s 1ms/step - loss: 20511842414951923712.0000 - val_loss: 397179505879285760.0000\n",
            "Epoch 252/500\n",
            "76/76 [==============================] - 0s 2ms/step - loss: 456715689701408768.0000 - val_loss: 13733386635968512.0000\n",
            "Epoch 253/500\n",
            "76/76 [==============================] - 0s 2ms/step - loss: 337801960969207808.0000 - val_loss: 52356579051175936.0000\n",
            "Epoch 254/500\n",
            "76/76 [==============================] - 0s 2ms/step - loss: 63903946518822912.0000 - val_loss: 13957479775862784.0000\n",
            "Epoch 255/500\n",
            "76/76 [==============================] - 0s 1ms/step - loss: 6154299440627712.0000 - val_loss: 11201765407981568.0000\n",
            "Epoch 256/500\n",
            "76/76 [==============================] - 0s 1ms/step - loss: 5486046015913984.0000 - val_loss: 7286438861209600.0000\n",
            "Epoch 257/500\n",
            "76/76 [==============================] - 0s 1ms/step - loss: 15257025210482688.0000 - val_loss: 116239991331356672.0000\n",
            "Epoch 258/500\n",
            "76/76 [==============================] - 0s 1ms/step - loss: 92514445959364608.0000 - val_loss: 1053758749920985088.0000\n",
            "Epoch 259/500\n",
            "76/76 [==============================] - 0s 1ms/step - loss: 82197513607577600.0000 - val_loss: 8144686069841920.0000\n",
            "Epoch 260/500\n",
            "76/76 [==============================] - 0s 1ms/step - loss: 11285718059974656.0000 - val_loss: 52717175915413504.0000\n",
            "Epoch 261/500\n",
            "76/76 [==============================] - 0s 1ms/step - loss: 71333544156200960.0000 - val_loss: 4377241421086720.0000\n",
            "Epoch 262/500\n",
            "76/76 [==============================] - 0s 1ms/step - loss: 8842824950743040.0000 - val_loss: 20972074050781184.0000\n",
            "Epoch 263/500\n",
            "76/76 [==============================] - 0s 1ms/step - loss: 6658437333123072.0000 - val_loss: 17864469791113216.0000\n",
            "Epoch 264/500\n",
            "76/76 [==============================] - 0s 1ms/step - loss: 9384344627970048.0000 - val_loss: 29043612532604928.0000\n",
            "Epoch 265/500\n",
            "76/76 [==============================] - 0s 2ms/step - loss: 1457934139050164224.0000 - val_loss: 218659018422353920.0000\n",
            "Epoch 266/500\n",
            "76/76 [==============================] - 0s 2ms/step - loss: 86712228060554330112.0000 - val_loss: 87444291698420613120.0000\n",
            "Epoch 267/500\n",
            "76/76 [==============================] - 0s 1ms/step - loss: 11766585312854147072.0000 - val_loss: 8973637212058943488.0000\n",
            "Epoch 268/500\n",
            "76/76 [==============================] - 0s 1ms/step - loss: 164618265184111165440.0000 - val_loss: 33388616712999403520.0000\n",
            "Epoch 269/500\n",
            "76/76 [==============================] - 0s 1ms/step - loss: 38549449415873003520.0000 - val_loss: 93916395371510104064.0000\n",
            "Epoch 270/500\n",
            "76/76 [==============================] - 0s 1ms/step - loss: 85030089619266338816.0000 - val_loss: 348431434930028806144.0000\n",
            "Epoch 271/500\n",
            "76/76 [==============================] - 0s 1ms/step - loss: 944075656874329899008.0000 - val_loss: 449120874705197203456.0000\n",
            "Epoch 272/500\n",
            "76/76 [==============================] - 0s 1ms/step - loss: 2050600233695075893248.0000 - val_loss: 5663245006221007126528.0000\n",
            "Epoch 273/500\n",
            "76/76 [==============================] - 0s 1ms/step - loss: 14695138623618778398720.0000 - val_loss: 29157321801112376836096.0000\n",
            "Epoch 274/500\n",
            "76/76 [==============================] - 0s 1ms/step - loss: 3270247211118532493312.0000 - val_loss: 542456112210730024960.0000\n",
            "Epoch 275/500\n",
            "76/76 [==============================] - 0s 1ms/step - loss: 656274037480892661760.0000 - val_loss: 157776857545484271616.0000\n",
            "Epoch 276/500\n",
            "76/76 [==============================] - 0s 1ms/step - loss: 102853111532864143360.0000 - val_loss: 94572276047711043584.0000\n",
            "Epoch 277/500\n",
            "76/76 [==============================] - 0s 1ms/step - loss: 58381389024580337664.0000 - val_loss: 11992002788734271488.0000\n",
            "Epoch 278/500\n",
            "76/76 [==============================] - 0s 1ms/step - loss: 13018146204612034560.0000 - val_loss: 6974734968366825472.0000\n",
            "Epoch 279/500\n",
            "76/76 [==============================] - 0s 2ms/step - loss: 46150492045944291328.0000 - val_loss: 2641083005010968576.0000\n",
            "Epoch 280/500\n",
            "76/76 [==============================] - 0s 1ms/step - loss: 2405811156166901760.0000 - val_loss: 82133063328333824.0000\n",
            "Epoch 281/500\n",
            "76/76 [==============================] - 0s 1ms/step - loss: 1227239969429389312.0000 - val_loss: 98920707508928512.0000\n",
            "Epoch 282/500\n",
            "76/76 [==============================] - 0s 1ms/step - loss: 134557975309189120.0000 - val_loss: 24921725976182784.0000\n",
            "Epoch 283/500\n",
            "76/76 [==============================] - 0s 1ms/step - loss: 82230309977849856.0000 - val_loss: 554734333819092992.0000\n",
            "Epoch 284/500\n",
            "76/76 [==============================] - 0s 1ms/step - loss: 98203447970496512.0000 - val_loss: 103759675362639872.0000\n",
            "Epoch 285/500\n",
            "76/76 [==============================] - 0s 1ms/step - loss: 19769083775942656.0000 - val_loss: 8223791314370560.0000\n",
            "Epoch 286/500\n",
            "76/76 [==============================] - 0s 1ms/step - loss: 15634391774527488.0000 - val_loss: 23630319504588800.0000\n",
            "Epoch 287/500\n",
            "76/76 [==============================] - 0s 1ms/step - loss: 36850780744974336.0000 - val_loss: 25979241413738496.0000\n",
            "Epoch 288/500\n",
            "76/76 [==============================] - 0s 1ms/step - loss: 7793791536726016.0000 - val_loss: 8991787838341120.0000\n",
            "Epoch 289/500\n",
            "76/76 [==============================] - 0s 1ms/step - loss: 4294560616284160.0000 - val_loss: 22099754221568000.0000\n",
            "Epoch 290/500\n",
            "76/76 [==============================] - 0s 1ms/step - loss: 11554736557785088.0000 - val_loss: 9304674058371072.0000\n",
            "Epoch 291/500\n",
            "76/76 [==============================] - 0s 1ms/step - loss: 14675364232036352.0000 - val_loss: 46167982149206016.0000\n",
            "Epoch 292/500\n",
            "76/76 [==============================] - 0s 1ms/step - loss: 16613427422167040.0000 - val_loss: 130686569097986048.0000\n",
            "Epoch 293/500\n",
            "76/76 [==============================] - 0s 1ms/step - loss: 29878736711057408.0000 - val_loss: 9393662559518720.0000\n",
            "Epoch 294/500\n",
            "76/76 [==============================] - 0s 1ms/step - loss: 5797216933380096.0000 - val_loss: 69581373593092096.0000\n",
            "Epoch 295/500\n",
            "76/76 [==============================] - 0s 1ms/step - loss: 32448651867455488.0000 - val_loss: 7046565474598912.0000\n",
            "Epoch 296/500\n",
            "76/76 [==============================] - 0s 1ms/step - loss: 530016212915060736.0000 - val_loss: 1940759793937416192.0000\n",
            "Epoch 297/500\n",
            "76/76 [==============================] - 0s 1ms/step - loss: 423684195739500544.0000 - val_loss: 205112674390900736.0000\n",
            "Epoch 298/500\n",
            "76/76 [==============================] - 0s 1ms/step - loss: 1123685559143759872.0000 - val_loss: 13294796524300009472.0000\n",
            "Epoch 299/500\n",
            "76/76 [==============================] - 0s 2ms/step - loss: 35088386922750410752.0000 - val_loss: 48954875617424179200.0000\n",
            "Epoch 300/500\n",
            "76/76 [==============================] - 0s 1ms/step - loss: 23481986160412065792.0000 - val_loss: 81798906420209385472.0000\n",
            "Epoch 301/500\n",
            "76/76 [==============================] - 0s 1ms/step - loss: 200604401151917424640.0000 - val_loss: 5623439575876632576.0000\n",
            "Epoch 302/500\n",
            "76/76 [==============================] - 0s 1ms/step - loss: 264458178295194714112.0000 - val_loss: 3041281323143528448.0000\n",
            "Epoch 303/500\n",
            "76/76 [==============================] - 0s 1ms/step - loss: 1628387205679138471936.0000 - val_loss: 8825779625051719467008.0000\n",
            "Epoch 304/500\n",
            "76/76 [==============================] - 0s 1ms/step - loss: 7998801639876184768512.0000 - val_loss: 1653101412321775845376.0000\n",
            "Epoch 305/500\n",
            "76/76 [==============================] - 0s 1ms/step - loss: 971913954283478843392.0000 - val_loss: 91041621065619996672.0000\n",
            "Epoch 306/500\n",
            "76/76 [==============================] - 0s 1ms/step - loss: 317606300989886824448.0000 - val_loss: 16186762794002022400.0000\n",
            "Epoch 307/500\n",
            "76/76 [==============================] - 0s 1ms/step - loss: 28641679769239289856.0000 - val_loss: 57231238289275486208.0000\n",
            "Epoch 308/500\n",
            "76/76 [==============================] - 0s 1ms/step - loss: 10155067403906580480.0000 - val_loss: 244178305345912832.0000\n",
            "Epoch 309/500\n",
            "76/76 [==============================] - 0s 1ms/step - loss: 165644742439206912.0000 - val_loss: 49410141291806720.0000\n",
            "Epoch 310/500\n",
            "76/76 [==============================] - 0s 1ms/step - loss: 26659587855745024.0000 - val_loss: 14403913708994560.0000\n",
            "Epoch 311/500\n",
            "76/76 [==============================] - 0s 2ms/step - loss: 9338782541152256.0000 - val_loss: 16023144296873984.0000\n",
            "Epoch 312/500\n",
            "76/76 [==============================] - 0s 1ms/step - loss: 10331753210183680.0000 - val_loss: 6377170662326272.0000\n",
            "Epoch 313/500\n",
            "76/76 [==============================] - 0s 1ms/step - loss: 5584122667859968.0000 - val_loss: 7537356756221952.0000\n",
            "Epoch 314/500\n",
            "76/76 [==============================] - 0s 1ms/step - loss: 11628593889148928.0000 - val_loss: 9340852715388928.0000\n",
            "Epoch 315/500\n",
            "76/76 [==============================] - 0s 1ms/step - loss: 8009037043990528.0000 - val_loss: 10589031414890496.0000\n",
            "Epoch 316/500\n",
            "76/76 [==============================] - 0s 1ms/step - loss: 19604376075108352.0000 - val_loss: 17982880965722112.0000\n",
            "Epoch 317/500\n",
            "76/76 [==============================] - 0s 1ms/step - loss: 21557475945742336.0000 - val_loss: 20766044469592064.0000\n",
            "Epoch 318/500\n",
            "76/76 [==============================] - 0s 1ms/step - loss: 10178509850804224.0000 - val_loss: 112883448619728896.0000\n",
            "Epoch 319/500\n",
            "76/76 [==============================] - 0s 1ms/step - loss: 10370384293527552.0000 - val_loss: 15523523636232192.0000\n",
            "Epoch 320/500\n",
            "76/76 [==============================] - 0s 1ms/step - loss: 6355746291712000.0000 - val_loss: 5262392573296640.0000\n",
            "Epoch 321/500\n",
            "76/76 [==============================] - 0s 2ms/step - loss: 6164434489704448.0000 - val_loss: 28438273399455744.0000\n",
            "Epoch 322/500\n",
            "76/76 [==============================] - 0s 2ms/step - loss: 10253993901031424.0000 - val_loss: 12331848612970496.0000\n",
            "Epoch 323/500\n",
            "76/76 [==============================] - 0s 1ms/step - loss: 95956312491294720.0000 - val_loss: 81118729491972096.0000\n",
            "Epoch 324/500\n",
            "76/76 [==============================] - 0s 1ms/step - loss: 42492181633564672.0000 - val_loss: 82920665841139712.0000\n",
            "Epoch 325/500\n",
            "76/76 [==============================] - 0s 1ms/step - loss: 18093726555439104.0000 - val_loss: 10079503338438656.0000\n",
            "Epoch 326/500\n",
            "76/76 [==============================] - 0s 1ms/step - loss: 5924657202987008.0000 - val_loss: 13495640868782080.0000\n",
            "Epoch 327/500\n",
            "76/76 [==============================] - 0s 1ms/step - loss: 17572655754379264.0000 - val_loss: 139725319182483456.0000\n",
            "Epoch 328/500\n",
            "76/76 [==============================] - 0s 1ms/step - loss: 130781444925554688.0000 - val_loss: 651690025070624768.0000\n",
            "Epoch 329/500\n",
            "76/76 [==============================] - 0s 1ms/step - loss: 226857818932641792.0000 - val_loss: 1060891556728274944.0000\n",
            "Epoch 330/500\n",
            "76/76 [==============================] - 0s 1ms/step - loss: 73021025708603867136.0000 - val_loss: 9567641222139346944.0000\n",
            "Epoch 331/500\n",
            "76/76 [==============================] - 0s 1ms/step - loss: 511228644975752249344.0000 - val_loss: 429481239680187891712.0000\n",
            "Epoch 332/500\n",
            "76/76 [==============================] - 0s 1ms/step - loss: 1143332426206500880384.0000 - val_loss: 191504790143885115392.0000\n",
            "Epoch 333/500\n",
            "76/76 [==============================] - 0s 1ms/step - loss: 3731451278808336826368.0000 - val_loss: 387480176974121402368.0000\n",
            "Epoch 334/500\n",
            "76/76 [==============================] - 0s 1ms/step - loss: 3804958187501347930112.0000 - val_loss: 12292947917349584896.0000\n",
            "Epoch 335/500\n",
            "76/76 [==============================] - 0s 2ms/step - loss: 423358455249289347072.0000 - val_loss: 1087865463175643136.0000\n",
            "Epoch 336/500\n",
            "76/76 [==============================] - 0s 1ms/step - loss: 9480327904266027008.0000 - val_loss: 59860632386171568128.0000\n",
            "Epoch 337/500\n",
            "76/76 [==============================] - 0s 1ms/step - loss: 139548933877888188416.0000 - val_loss: 263975202419531317248.0000\n",
            "Epoch 338/500\n",
            "76/76 [==============================] - 0s 1ms/step - loss: 120979194035449102336.0000 - val_loss: 37369396362339155968.0000\n",
            "Epoch 339/500\n",
            "76/76 [==============================] - 0s 1ms/step - loss: 7839340334914994176.0000 - val_loss: 2082072326874071040.0000\n",
            "Epoch 340/500\n",
            "76/76 [==============================] - 0s 1ms/step - loss: 1303446982911590400.0000 - val_loss: 1462164922354892800.0000\n",
            "Epoch 341/500\n",
            "76/76 [==============================] - 0s 1ms/step - loss: 429326099139264512.0000 - val_loss: 811517096868446208.0000\n",
            "Epoch 342/500\n",
            "76/76 [==============================] - 0s 1ms/step - loss: 409704523867619328.0000 - val_loss: 211832270984577024.0000\n",
            "Epoch 343/500\n",
            "76/76 [==============================] - 0s 1ms/step - loss: 1960161776121151488.0000 - val_loss: 1548850006771892224.0000\n",
            "Epoch 344/500\n",
            "76/76 [==============================] - 0s 1ms/step - loss: 338951569095524352.0000 - val_loss: 27782032461398016.0000\n",
            "Epoch 345/500\n",
            "76/76 [==============================] - 0s 1ms/step - loss: 24754954543562752.0000 - val_loss: 21442804613906432.0000\n",
            "Epoch 346/500\n",
            "76/76 [==============================] - 0s 1ms/step - loss: 38653382814072832.0000 - val_loss: 100465495576150016.0000\n",
            "Epoch 347/500\n",
            "76/76 [==============================] - 0s 1ms/step - loss: 40494686833475584.0000 - val_loss: 14456365997096960.0000\n",
            "Epoch 348/500\n",
            "76/76 [==============================] - 0s 2ms/step - loss: 34217998004781056.0000 - val_loss: 6568514139717632.0000\n",
            "Epoch 349/500\n",
            "76/76 [==============================] - 0s 1ms/step - loss: 28659588769251328.0000 - val_loss: 121082798885830656.0000\n",
            "Epoch 350/500\n",
            "76/76 [==============================] - 0s 1ms/step - loss: 764392234660397056.0000 - val_loss: 491955415328751616.0000\n",
            "Epoch 351/500\n",
            "76/76 [==============================] - 0s 2ms/step - loss: 1134556705485488128.0000 - val_loss: 302164796248162304.0000\n",
            "Epoch 352/500\n",
            "76/76 [==============================] - 0s 2ms/step - loss: 711578980326572032.0000 - val_loss: 100734669766524928.0000\n",
            "Epoch 353/500\n",
            "76/76 [==============================] - 0s 1ms/step - loss: 14658211833463177216.0000 - val_loss: 11089990937097535488.0000\n",
            "Epoch 354/500\n",
            "76/76 [==============================] - 0s 1ms/step - loss: 45783501452871729152.0000 - val_loss: 109664937910657351680.0000\n",
            "Epoch 355/500\n",
            "76/76 [==============================] - 0s 1ms/step - loss: 78631855535377350656.0000 - val_loss: 4545664468348043264.0000\n",
            "Epoch 356/500\n",
            "76/76 [==============================] - 0s 1ms/step - loss: 6477036632007507968.0000 - val_loss: 3006492775240695808.0000\n",
            "Epoch 357/500\n",
            "76/76 [==============================] - 0s 1ms/step - loss: 13664654643697811456.0000 - val_loss: 2643398851376971776.0000\n",
            "Epoch 358/500\n",
            "76/76 [==============================] - 0s 1ms/step - loss: 200878241119884804096.0000 - val_loss: 977794177653196980224.0000\n",
            "Epoch 359/500\n",
            "76/76 [==============================] - 0s 1ms/step - loss: 775855514742926868480.0000 - val_loss: 24940974318796406784.0000\n",
            "Epoch 360/500\n",
            "76/76 [==============================] - 0s 1ms/step - loss: 102190642582989570048.0000 - val_loss: 87110902180692885504.0000\n",
            "Epoch 361/500\n",
            "76/76 [==============================] - 0s 1ms/step - loss: 677171584176821895168.0000 - val_loss: 852164929041557618688.0000\n",
            "Epoch 362/500\n",
            "76/76 [==============================] - 0s 2ms/step - loss: 6433392067698753536000.0000 - val_loss: 1090409430716619161600.0000\n",
            "Epoch 363/500\n",
            "76/76 [==============================] - 0s 1ms/step - loss: 2304705146620341125120.0000 - val_loss: 79719738728177991680.0000\n",
            "Epoch 364/500\n",
            "76/76 [==============================] - 0s 1ms/step - loss: 668769837596985524224.0000 - val_loss: 35815559932896346112.0000\n",
            "Epoch 365/500\n",
            "76/76 [==============================] - 0s 1ms/step - loss: 54798810705379196928.0000 - val_loss: 18932503912814477312.0000\n",
            "Epoch 366/500\n",
            "76/76 [==============================] - 0s 1ms/step - loss: 24943267900051947520.0000 - val_loss: 120639040322187296768.0000\n",
            "Epoch 367/500\n",
            "76/76 [==============================] - 0s 1ms/step - loss: 250463506335931564032.0000 - val_loss: 103668887588022779904.0000\n",
            "Epoch 368/500\n",
            "76/76 [==============================] - 0s 1ms/step - loss: 181393100672717553664.0000 - val_loss: 3847115594163814400.0000\n",
            "Epoch 369/500\n",
            "76/76 [==============================] - 0s 1ms/step - loss: 53973543665849597952.0000 - val_loss: 151060266466842509312.0000\n",
            "Epoch 370/500\n",
            "76/76 [==============================] - 0s 1ms/step - loss: 25983784131927998464.0000 - val_loss: 372360917100265472.0000\n",
            "Epoch 371/500\n",
            "76/76 [==============================] - 0s 1ms/step - loss: 130012869117870080.0000 - val_loss: 16643511520591872.0000\n",
            "Epoch 372/500\n",
            "76/76 [==============================] - 0s 1ms/step - loss: 29219405544030208.0000 - val_loss: 16633365734096896.0000\n",
            "Epoch 373/500\n",
            "76/76 [==============================] - 0s 1ms/step - loss: 4997265852727296.0000 - val_loss: 6760218394361856.0000\n",
            "Epoch 374/500\n",
            "76/76 [==============================] - 0s 1ms/step - loss: 7981854732845056.0000 - val_loss: 9012841768026112.0000\n",
            "Epoch 375/500\n",
            "76/76 [==============================] - 0s 1ms/step - loss: 7812382302666752.0000 - val_loss: 5499291158183936.0000\n",
            "Epoch 376/500\n",
            "76/76 [==============================] - 0s 2ms/step - loss: 27062183057686528.0000 - val_loss: 27170736208609280.0000\n",
            "Epoch 377/500\n",
            "76/76 [==============================] - 0s 1ms/step - loss: 8683973974687744.0000 - val_loss: 36955337428828160.0000\n",
            "Epoch 378/500\n",
            "76/76 [==============================] - 0s 2ms/step - loss: 25032463117975552.0000 - val_loss: 11081726440767488.0000\n",
            "Epoch 379/500\n",
            "76/76 [==============================] - 0s 2ms/step - loss: 1211727509628911616.0000 - val_loss: 64081818294419456.0000\n",
            "Epoch 380/500\n",
            "76/76 [==============================] - 0s 2ms/step - loss: 269854950800226254848.0000 - val_loss: 492066637801848832000.0000\n",
            "Epoch 381/500\n",
            "76/76 [==============================] - 0s 1ms/step - loss: 35167384634182860800.0000 - val_loss: 788738514475810816.0000\n",
            "Epoch 382/500\n",
            "76/76 [==============================] - 0s 1ms/step - loss: 4986717889789689856.0000 - val_loss: 9758950747814232064.0000\n",
            "Epoch 383/500\n",
            "76/76 [==============================] - 0s 1ms/step - loss: 4480125054117478400.0000 - val_loss: 7932650938962018304.0000\n",
            "Epoch 384/500\n",
            "76/76 [==============================] - 0s 1ms/step - loss: 52164965785413877760.0000 - val_loss: 70108384222253154304.0000\n",
            "Epoch 385/500\n",
            "76/76 [==============================] - 0s 1ms/step - loss: 81482326236247097344.0000 - val_loss: 2647314762039296000.0000\n",
            "Epoch 386/500\n",
            "76/76 [==============================] - 0s 1ms/step - loss: 1550878426504743616512.0000 - val_loss: 324522387458272264192.0000\n",
            "Epoch 387/500\n",
            "76/76 [==============================] - 0s 1ms/step - loss: 3914847707259048296448.0000 - val_loss: 15141307986902559752192.0000\n",
            "Epoch 388/500\n",
            "76/76 [==============================] - 0s 1ms/step - loss: 22425262265125480431616.0000 - val_loss: 4284728907604940554240.0000\n",
            "Epoch 389/500\n",
            "76/76 [==============================] - 0s 1ms/step - loss: 1293700932733704863744.0000 - val_loss: 95328625698411642880.0000\n",
            "Epoch 390/500\n",
            "76/76 [==============================] - 0s 1ms/step - loss: 38181544029126131712.0000 - val_loss: 217385732417781760.0000\n",
            "Epoch 391/500\n",
            "76/76 [==============================] - 0s 1ms/step - loss: 7362970874867089408.0000 - val_loss: 513142351560966144.0000\n",
            "Epoch 392/500\n",
            "76/76 [==============================] - 0s 1ms/step - loss: 40403731795652116480.0000 - val_loss: 5580601503346851840.0000\n",
            "Epoch 393/500\n",
            "76/76 [==============================] - 0s 1ms/step - loss: 4018003890376015872.0000 - val_loss: 903016186789232640.0000\n",
            "Epoch 394/500\n",
            "76/76 [==============================] - 0s 1ms/step - loss: 3297988426048995328.0000 - val_loss: 12072504632073519104.0000\n",
            "Epoch 395/500\n",
            "76/76 [==============================] - 0s 1ms/step - loss: 9632858754340880384.0000 - val_loss: 417798200758370304.0000\n",
            "Epoch 396/500\n",
            "76/76 [==============================] - 0s 1ms/step - loss: 22526081746339889152.0000 - val_loss: 1589513107862978560.0000\n",
            "Epoch 397/500\n",
            "76/76 [==============================] - 0s 1ms/step - loss: 136924566748154298368.0000 - val_loss: 13403498641868455936.0000\n",
            "Epoch 398/500\n",
            "76/76 [==============================] - 0s 1ms/step - loss: 16777506202350256128.0000 - val_loss: 1734216534659694592.0000\n",
            "Epoch 399/500\n",
            "76/76 [==============================] - 0s 1ms/step - loss: 2675920206303330304.0000 - val_loss: 7587020558282260480.0000\n",
            "Epoch 400/500\n",
            "76/76 [==============================] - 0s 2ms/step - loss: 2351198963371081728.0000 - val_loss: 1205153804484345856.0000\n",
            "Epoch 401/500\n",
            "76/76 [==============================] - 0s 2ms/step - loss: 1976368302636662784.0000 - val_loss: 2000032953962332160.0000\n",
            "Epoch 402/500\n",
            "76/76 [==============================] - 0s 1ms/step - loss: 15730358815847088128.0000 - val_loss: 7094745013271134208.0000\n",
            "Epoch 403/500\n",
            "76/76 [==============================] - 0s 1ms/step - loss: 13160365834641604608.0000 - val_loss: 20273349546794287104.0000\n",
            "Epoch 404/500\n",
            "76/76 [==============================] - 0s 1ms/step - loss: 6530721936501112832.0000 - val_loss: 15573403530982064128.0000\n",
            "Epoch 405/500\n",
            "76/76 [==============================] - 0s 1ms/step - loss: 11681706313724723200.0000 - val_loss: 531870642354520064.0000\n",
            "Epoch 406/500\n",
            "76/76 [==============================] - 0s 1ms/step - loss: 81520624425265790976.0000 - val_loss: 45335243756366987264.0000\n",
            "Epoch 407/500\n",
            "76/76 [==============================] - 0s 2ms/step - loss: 76358329371927248896.0000 - val_loss: 527858397706050338816.0000\n",
            "Epoch 408/500\n",
            "76/76 [==============================] - 0s 1ms/step - loss: 116822257230176845824.0000 - val_loss: 182502639846538870784.0000\n",
            "Epoch 409/500\n",
            "76/76 [==============================] - 0s 2ms/step - loss: 431684133216669663232.0000 - val_loss: 1436048634977189888.0000\n",
            "Epoch 410/500\n",
            "76/76 [==============================] - 0s 1ms/step - loss: 310338863381822308352.0000 - val_loss: 980490919036317597696.0000\n",
            "Epoch 411/500\n",
            "76/76 [==============================] - 0s 1ms/step - loss: 1877157323370806640640.0000 - val_loss: 293913848512709132288.0000\n",
            "Epoch 412/500\n",
            "76/76 [==============================] - 0s 1ms/step - loss: 77801346024406515712.0000 - val_loss: 9613414990715289600.0000\n",
            "Epoch 413/500\n",
            "76/76 [==============================] - 0s 1ms/step - loss: 306287031092072415232.0000 - val_loss: 22053755740303130624.0000\n",
            "Epoch 414/500\n",
            "76/76 [==============================] - 0s 1ms/step - loss: 263529152542375149568.0000 - val_loss: 89921051591148830720.0000\n",
            "Epoch 415/500\n",
            "76/76 [==============================] - 0s 1ms/step - loss: 72560062055728545792.0000 - val_loss: 40148231681636040704.0000\n",
            "Epoch 416/500\n",
            "76/76 [==============================] - 0s 1ms/step - loss: 642220343737450496000.0000 - val_loss: 930398013699773169664.0000\n",
            "Epoch 417/500\n",
            "76/76 [==============================] - 0s 1ms/step - loss: 1166134291857366056960.0000 - val_loss: 33141578440470691840.0000\n",
            "Epoch 418/500\n",
            "76/76 [==============================] - 0s 2ms/step - loss: 11171651753653389230080.0000 - val_loss: 2318233678425985384448.0000\n",
            "Epoch 419/500\n",
            "76/76 [==============================] - 0s 1ms/step - loss: 1741210679856582361088.0000 - val_loss: 120804978617051250688.0000\n",
            "Epoch 420/500\n",
            "76/76 [==============================] - 0s 1ms/step - loss: 240317723208209924096.0000 - val_loss: 119923539727481831424.0000\n",
            "Epoch 421/500\n",
            "76/76 [==============================] - 0s 1ms/step - loss: 51544432209022681088.0000 - val_loss: 148131394814476288.0000\n",
            "Epoch 422/500\n",
            "76/76 [==============================] - 0s 2ms/step - loss: 17628115885388464128.0000 - val_loss: 1952076929683161088.0000\n",
            "Epoch 423/500\n",
            "76/76 [==============================] - 0s 2ms/step - loss: 2931992890999570432.0000 - val_loss: 22389834663472398336.0000\n",
            "Epoch 424/500\n",
            "76/76 [==============================] - 0s 2ms/step - loss: 6471894216124399616.0000 - val_loss: 17639496930247573504.0000\n",
            "Epoch 425/500\n",
            "76/76 [==============================] - 0s 1ms/step - loss: 13799482257053843456.0000 - val_loss: 663519189637529600.0000\n",
            "Epoch 426/500\n",
            "76/76 [==============================] - 0s 1ms/step - loss: 278047781787009024.0000 - val_loss: 9400810458841088.0000\n",
            "Epoch 427/500\n",
            "76/76 [==============================] - 0s 1ms/step - loss: 192728015933800448.0000 - val_loss: 4009422032470016.0000\n",
            "Epoch 428/500\n",
            "76/76 [==============================] - 0s 1ms/step - loss: 115408545792393216.0000 - val_loss: 28795286113484800.0000\n",
            "Epoch 429/500\n",
            "76/76 [==============================] - 0s 1ms/step - loss: 33446233183879168.0000 - val_loss: 139471194557513728.0000\n",
            "Epoch 430/500\n",
            "76/76 [==============================] - 0s 1ms/step - loss: 98806040472059904.0000 - val_loss: 130499325703749632.0000\n",
            "Epoch 431/500\n",
            "76/76 [==============================] - 0s 2ms/step - loss: 9381074010374144.0000 - val_loss: 8743414174580736.0000\n",
            "Epoch 432/500\n",
            "76/76 [==============================] - 0s 1ms/step - loss: 8569662883233792.0000 - val_loss: 35849340400435200.0000\n",
            "Epoch 433/500\n",
            "76/76 [==============================] - 0s 2ms/step - loss: 8728187441774592.0000 - val_loss: 6336575168315392.0000\n",
            "Epoch 434/500\n",
            "76/76 [==============================] - 0s 2ms/step - loss: 4818885123506176.0000 - val_loss: 5221025595785216.0000\n",
            "Epoch 435/500\n",
            "76/76 [==============================] - 0s 2ms/step - loss: 10924137648226304.0000 - val_loss: 12067745705230336.0000\n",
            "Epoch 436/500\n",
            "76/76 [==============================] - 0s 2ms/step - loss: 20019690822696960.0000 - val_loss: 6472699861794816.0000\n",
            "Epoch 437/500\n",
            "76/76 [==============================] - 0s 1ms/step - loss: 5710924597952512.0000 - val_loss: 20330768861495296.0000\n",
            "Epoch 438/500\n",
            "76/76 [==============================] - 0s 1ms/step - loss: 7099728579788800.0000 - val_loss: 25170550611509248.0000\n",
            "Epoch 439/500\n",
            "76/76 [==============================] - 0s 1ms/step - loss: 45671363670704128.0000 - val_loss: 34721864240594944.0000\n",
            "Epoch 440/500\n",
            "76/76 [==============================] - 0s 1ms/step - loss: 17346240110919680.0000 - val_loss: 5857329832525824.0000\n",
            "Epoch 441/500\n",
            "76/76 [==============================] - 0s 1ms/step - loss: 34609922360475648.0000 - val_loss: 6405916341567488.0000\n",
            "Epoch 442/500\n",
            "76/76 [==============================] - 0s 1ms/step - loss: 21905686124298240.0000 - val_loss: 65621551185133568.0000\n",
            "Epoch 443/500\n",
            "76/76 [==============================] - 0s 1ms/step - loss: 20801916036448256.0000 - val_loss: 5711823856730112.0000\n",
            "Epoch 444/500\n",
            "76/76 [==============================] - 0s 1ms/step - loss: 116183014295207936.0000 - val_loss: 1732065752476811264.0000\n",
            "Epoch 445/500\n",
            "76/76 [==============================] - 0s 1ms/step - loss: 946952740154638336.0000 - val_loss: 590422007355539456.0000\n",
            "Epoch 446/500\n",
            "76/76 [==============================] - 0s 1ms/step - loss: 430727735946510336.0000 - val_loss: 1324076432388784128.0000\n",
            "Epoch 447/500\n",
            "76/76 [==============================] - 0s 1ms/step - loss: 576334308466229248.0000 - val_loss: 8569130182735036416.0000\n",
            "Epoch 448/500\n",
            "76/76 [==============================] - 0s 1ms/step - loss: 20033515274450763776.0000 - val_loss: 118560435580109324288.0000\n",
            "Epoch 449/500\n",
            "76/76 [==============================] - 0s 1ms/step - loss: 234572396721080369152.0000 - val_loss: 28554114663203209216.0000\n",
            "Epoch 450/500\n",
            "76/76 [==============================] - 0s 1ms/step - loss: 233083464463025176576.0000 - val_loss: 58718143047889059840.0000\n",
            "Epoch 451/500\n",
            "76/76 [==============================] - 0s 1ms/step - loss: 111619403391912902656.0000 - val_loss: 143686862326139453440.0000\n",
            "Epoch 452/500\n",
            "76/76 [==============================] - 0s 1ms/step - loss: 184396491450778386432.0000 - val_loss: 152349404267991269376.0000\n",
            "Epoch 453/500\n",
            "76/76 [==============================] - 0s 2ms/step - loss: 42041823801131401216.0000 - val_loss: 1373031088103882752.0000\n",
            "Epoch 454/500\n",
            "76/76 [==============================] - 0s 2ms/step - loss: 3107741028606541824.0000 - val_loss: 42954607568185458688.0000\n",
            "Epoch 455/500\n",
            "76/76 [==============================] - 0s 1ms/step - loss: 17760441010279677952.0000 - val_loss: 14369699982334754816.0000\n",
            "Epoch 456/500\n",
            "76/76 [==============================] - 0s 1ms/step - loss: 6144854378047078400.0000 - val_loss: 1942248670120378368.0000\n",
            "Epoch 457/500\n",
            "76/76 [==============================] - 0s 1ms/step - loss: 1897705667372777472.0000 - val_loss: 11617599288267243520.0000\n",
            "Epoch 458/500\n",
            "76/76 [==============================] - 0s 1ms/step - loss: 530224617097768468480.0000 - val_loss: 3555357437153406615552.0000\n",
            "Epoch 459/500\n",
            "76/76 [==============================] - 0s 1ms/step - loss: 17391832155993355059200.0000 - val_loss: 22061826278796308774912.0000\n",
            "Epoch 460/500\n",
            "76/76 [==============================] - 0s 1ms/step - loss: 3831517603353812008960.0000 - val_loss: 90515649887264047104.0000\n",
            "Epoch 461/500\n",
            "76/76 [==============================] - 0s 1ms/step - loss: 10398212305761337344.0000 - val_loss: 797928163941285888.0000\n",
            "Epoch 462/500\n",
            "76/76 [==============================] - 0s 1ms/step - loss: 2491154424081154048.0000 - val_loss: 285210155149164544.0000\n",
            "Epoch 463/500\n",
            "76/76 [==============================] - 0s 1ms/step - loss: 20370748684829196288.0000 - val_loss: 5427277355632558080.0000\n",
            "Epoch 464/500\n",
            "76/76 [==============================] - 0s 1ms/step - loss: 2455510181254004736.0000 - val_loss: 3253086020438065152.0000\n",
            "Epoch 465/500\n",
            "76/76 [==============================] - 0s 1ms/step - loss: 288216632256364544.0000 - val_loss: 59033874511953920.0000\n",
            "Epoch 466/500\n",
            "76/76 [==============================] - 0s 1ms/step - loss: 233524020492894208.0000 - val_loss: 28932437304147968.0000\n",
            "Epoch 467/500\n",
            "76/76 [==============================] - 0s 1ms/step - loss: 149750923902582784.0000 - val_loss: 18512535258923008.0000\n",
            "Epoch 468/500\n",
            "76/76 [==============================] - 0s 2ms/step - loss: 9694975990169600.0000 - val_loss: 11799531440046080.0000\n",
            "Epoch 469/500\n",
            "76/76 [==============================] - 0s 1ms/step - loss: 19578591238946816.0000 - val_loss: 7991064216469504.0000\n",
            "Epoch 470/500\n",
            "76/76 [==============================] - 0s 1ms/step - loss: 17411653536579584.0000 - val_loss: 45728156023259136.0000\n",
            "Epoch 471/500\n",
            "76/76 [==============================] - 0s 1ms/step - loss: 66487004275146752.0000 - val_loss: 65023056082370560.0000\n",
            "Epoch 472/500\n",
            "76/76 [==============================] - 0s 1ms/step - loss: 1089931308085280768.0000 - val_loss: 303392297901359104.0000\n",
            "Epoch 473/500\n",
            "76/76 [==============================] - 0s 2ms/step - loss: 2170503435755978752.0000 - val_loss: 12598840848289890304.0000\n",
            "Epoch 474/500\n",
            "76/76 [==============================] - 0s 1ms/step - loss: 93405641434082574336.0000 - val_loss: 51785898156621824000.0000\n",
            "Epoch 475/500\n",
            "76/76 [==============================] - 0s 2ms/step - loss: 1165265167498027728896.0000 - val_loss: 729097102717985226752.0000\n",
            "Epoch 476/500\n",
            "76/76 [==============================] - 0s 1ms/step - loss: 4560610695053379108864.0000 - val_loss: 2834575457091175055360.0000\n",
            "Epoch 477/500\n",
            "76/76 [==============================] - 0s 1ms/step - loss: 8507047494523734196224.0000 - val_loss: 71597444023657168896.0000\n",
            "Epoch 478/500\n",
            "76/76 [==============================] - 0s 2ms/step - loss: 3061820901838802649088.0000 - val_loss: 1308505812821243592704.0000\n",
            "Epoch 479/500\n",
            "76/76 [==============================] - 0s 1ms/step - loss: 414287994493532635136.0000 - val_loss: 23650732607973359616.0000\n",
            "Epoch 480/500\n",
            "76/76 [==============================] - 0s 1ms/step - loss: 44509879959814144000.0000 - val_loss: 4073337912555470848.0000\n",
            "Epoch 481/500\n",
            "76/76 [==============================] - 0s 1ms/step - loss: 2793628973370703872.0000 - val_loss: 22376638324915830784.0000\n",
            "Epoch 482/500\n",
            "76/76 [==============================] - 0s 1ms/step - loss: 3588159440223731712.0000 - val_loss: 314239495505444864.0000\n",
            "Epoch 483/500\n",
            "76/76 [==============================] - 0s 1ms/step - loss: 912824723862192128.0000 - val_loss: 796929395066404864.0000\n",
            "Epoch 484/500\n",
            "76/76 [==============================] - 0s 1ms/step - loss: 384826011704885248.0000 - val_loss: 33715650039906304.0000\n",
            "Epoch 485/500\n",
            "76/76 [==============================] - 0s 1ms/step - loss: 28992352097927168.0000 - val_loss: 5174039190437888.0000\n",
            "Epoch 486/500\n",
            "76/76 [==============================] - 0s 2ms/step - loss: 11660283231600640.0000 - val_loss: 7067471227912192.0000\n",
            "Epoch 487/500\n",
            "76/76 [==============================] - 0s 1ms/step - loss: 8641310453923840.0000 - val_loss: 6932280689819648.0000\n",
            "Epoch 488/500\n",
            "76/76 [==============================] - 0s 1ms/step - loss: 8165339493826560.0000 - val_loss: 14552114776768512.0000\n",
            "Epoch 489/500\n",
            "76/76 [==============================] - 0s 2ms/step - loss: 6638433522941952.0000 - val_loss: 10468077619642368.0000\n",
            "Epoch 490/500\n",
            "76/76 [==============================] - 0s 1ms/step - loss: 5426513474224128.0000 - val_loss: 34705779588071424.0000\n",
            "Epoch 491/500\n",
            "76/76 [==============================] - 0s 1ms/step - loss: 5482533269536768.0000 - val_loss: 4859086554267648.0000\n",
            "Epoch 492/500\n",
            "76/76 [==============================] - 0s 1ms/step - loss: 5526878269997056.0000 - val_loss: 5091543606099968.0000\n",
            "Epoch 493/500\n",
            "76/76 [==============================] - 0s 1ms/step - loss: 23691265090519040.0000 - val_loss: 10202376984068096.0000\n",
            "Epoch 494/500\n",
            "76/76 [==============================] - 0s 1ms/step - loss: 15345648639410176.0000 - val_loss: 116511244285902848.0000\n",
            "Epoch 495/500\n",
            "76/76 [==============================] - 0s 1ms/step - loss: 240976441586483200.0000 - val_loss: 86472036859248640.0000\n",
            "Epoch 496/500\n",
            "76/76 [==============================] - 0s 1ms/step - loss: 54019787956682752.0000 - val_loss: 34302823608877056.0000\n",
            "Epoch 497/500\n",
            "76/76 [==============================] - 0s 1ms/step - loss: 19266454490710016.0000 - val_loss: 14511277153976320.0000\n",
            "Epoch 498/500\n",
            "76/76 [==============================] - 0s 1ms/step - loss: 6474719570165760.0000 - val_loss: 29451812666867712.0000\n",
            "Epoch 499/500\n",
            "76/76 [==============================] - 0s 1ms/step - loss: 5221746613420032.0000 - val_loss: 11689890588655616.0000\n",
            "Epoch 500/500\n",
            "76/76 [==============================] - 0s 1ms/step - loss: 25545724594749440.0000 - val_loss: 4879393159643136.0000\n",
            "Training Set R2 is:\t0.327\n",
            "TEsting Set R2 is:\t0.591\n",
            "Epoch 1/500\n",
            "76/76 [==============================] - 0s 3ms/step - loss: 2003690177026431385600.0000 - val_loss: 43935473095231406080.0000\n",
            "Epoch 2/500\n",
            "76/76 [==============================] - 0s 1ms/step - loss: 73048201237995978752.0000 - val_loss: 42214772582134054912.0000\n",
            "Epoch 3/500\n",
            "76/76 [==============================] - 0s 1ms/step - loss: 415189699581425221632.0000 - val_loss: 2733788275130343882752.0000\n",
            "Epoch 4/500\n",
            "76/76 [==============================] - 0s 1ms/step - loss: 634538610148039983104.0000 - val_loss: 823842565041210523648.0000\n",
            "Epoch 5/500\n",
            "76/76 [==============================] - 0s 1ms/step - loss: 173610950885365514240.0000 - val_loss: 3267773890498175959040.0000\n",
            "Epoch 6/500\n",
            "76/76 [==============================] - 0s 1ms/step - loss: 1248171510825826123776.0000 - val_loss: 869272555913566224384.0000\n",
            "Epoch 7/500\n",
            "76/76 [==============================] - 0s 1ms/step - loss: 940999768697580027904.0000 - val_loss: 186344315881802170368.0000\n",
            "Epoch 8/500\n",
            "76/76 [==============================] - 0s 2ms/step - loss: 36300240227504656220160.0000 - val_loss: 6882659344576212369408.0000\n",
            "Epoch 9/500\n",
            "76/76 [==============================] - 0s 1ms/step - loss: 3157276947740733997056.0000 - val_loss: 2423874474147726753792.0000\n",
            "Epoch 10/500\n",
            "76/76 [==============================] - 0s 1ms/step - loss: 439630171809211482112.0000 - val_loss: 20036998527287558144.0000\n",
            "Epoch 11/500\n",
            "76/76 [==============================] - 0s 1ms/step - loss: 6712769176223612928.0000 - val_loss: 264392895342051328.0000\n",
            "Epoch 12/500\n",
            "76/76 [==============================] - 0s 1ms/step - loss: 1290159522328870912.0000 - val_loss: 72184802379300864.0000\n",
            "Epoch 13/500\n",
            "76/76 [==============================] - 0s 1ms/step - loss: 7190982139314176.0000 - val_loss: 12302081268383744.0000\n",
            "Epoch 14/500\n",
            "76/76 [==============================] - 0s 1ms/step - loss: 5947130082492416.0000 - val_loss: 14715363262464000.0000\n",
            "Epoch 15/500\n",
            "76/76 [==============================] - 0s 1ms/step - loss: 5715440219193344.0000 - val_loss: 7030573163872256.0000\n",
            "Epoch 16/500\n",
            "76/76 [==============================] - 0s 1ms/step - loss: 5767278863843328.0000 - val_loss: 5376745003810816.0000\n",
            "Epoch 17/500\n",
            "76/76 [==============================] - 0s 2ms/step - loss: 4020370977849344.0000 - val_loss: 7310898699960320.0000\n",
            "Epoch 18/500\n",
            "76/76 [==============================] - 0s 1ms/step - loss: 3283909982814208.0000 - val_loss: 6534033068523520.0000\n",
            "Epoch 19/500\n",
            "76/76 [==============================] - 0s 1ms/step - loss: 5385798794870784.0000 - val_loss: 6421987035447296.0000\n",
            "Epoch 20/500\n",
            "76/76 [==============================] - 0s 1ms/step - loss: 4880466901467136.0000 - val_loss: 9595856734912512.0000\n",
            "Epoch 21/500\n",
            "76/76 [==============================] - 0s 1ms/step - loss: 5946631866286080.0000 - val_loss: 11605573938184192.0000\n",
            "Epoch 22/500\n",
            "76/76 [==============================] - 0s 1ms/step - loss: 4134948625711104.0000 - val_loss: 16807174470631424.0000\n",
            "Epoch 23/500\n",
            "76/76 [==============================] - 0s 1ms/step - loss: 4067109348835328.0000 - val_loss: 12125942512091136.0000\n",
            "Epoch 24/500\n",
            "76/76 [==============================] - 0s 1ms/step - loss: 5640473712525312.0000 - val_loss: 5031928923160576.0000\n",
            "Epoch 25/500\n",
            "76/76 [==============================] - 0s 1ms/step - loss: 3984917633433600.0000 - val_loss: 10348031136235520.0000\n",
            "Epoch 26/500\n",
            "76/76 [==============================] - 0s 2ms/step - loss: 3986482612142080.0000 - val_loss: 6128414209605632.0000\n",
            "Epoch 27/500\n",
            "76/76 [==============================] - 0s 1ms/step - loss: 6685782316154880.0000 - val_loss: 5085200476274688.0000\n",
            "Epoch 28/500\n",
            "76/76 [==============================] - 0s 1ms/step - loss: 14708411857895424.0000 - val_loss: 59952263073890304.0000\n",
            "Epoch 29/500\n",
            "76/76 [==============================] - 0s 1ms/step - loss: 21773424753901568.0000 - val_loss: 15469325443923968.0000\n",
            "Epoch 30/500\n",
            "76/76 [==============================] - 0s 1ms/step - loss: 1044487255558717440.0000 - val_loss: 534277267149291520.0000\n",
            "Epoch 31/500\n",
            "76/76 [==============================] - 0s 1ms/step - loss: 54834946979659776.0000 - val_loss: 5104112291020800.0000\n",
            "Epoch 32/500\n",
            "76/76 [==============================] - 0s 1ms/step - loss: 106474738938806272.0000 - val_loss: 134122053308514304.0000\n",
            "Epoch 33/500\n",
            "76/76 [==============================] - 0s 1ms/step - loss: 145383182680719360.0000 - val_loss: 117353573271994368.0000\n",
            "Epoch 34/500\n",
            "76/76 [==============================] - 0s 1ms/step - loss: 769604194653962240.0000 - val_loss: 511643579773353984.0000\n",
            "Epoch 35/500\n",
            "76/76 [==============================] - 0s 1ms/step - loss: 3569891879161954304.0000 - val_loss: 3758278902930210816.0000\n",
            "Epoch 36/500\n",
            "76/76 [==============================] - 0s 1ms/step - loss: 37285134189232914432.0000 - val_loss: 28428411896846090240.0000\n",
            "Epoch 37/500\n",
            "76/76 [==============================] - 0s 1ms/step - loss: 79191885185915289600.0000 - val_loss: 407218011581630644224.0000\n",
            "Epoch 38/500\n",
            "76/76 [==============================] - 0s 2ms/step - loss: 63101275783273906176.0000 - val_loss: 30971617476264067072.0000\n",
            "Epoch 39/500\n",
            "76/76 [==============================] - 0s 1ms/step - loss: 1584552403868546236416.0000 - val_loss: 271818133209666813952.0000\n",
            "Epoch 40/500\n",
            "76/76 [==============================] - 0s 1ms/step - loss: 324646095710536597504.0000 - val_loss: 292603336205516406784.0000\n",
            "Epoch 41/500\n",
            "76/76 [==============================] - 0s 1ms/step - loss: 1668551010843470331904.0000 - val_loss: 1008483535101448159232.0000\n",
            "Epoch 42/500\n",
            "76/76 [==============================] - 0s 2ms/step - loss: 341123077897224978432.0000 - val_loss: 531218540424905883648.0000\n",
            "Epoch 43/500\n",
            "76/76 [==============================] - 0s 2ms/step - loss: 13810046188851654819840.0000 - val_loss: 2547374153454317469696.0000\n",
            "Epoch 44/500\n",
            "76/76 [==============================] - 0s 1ms/step - loss: 3432227053016260280320.0000 - val_loss: 4850237750039529127936.0000\n",
            "Epoch 45/500\n",
            "76/76 [==============================] - 0s 1ms/step - loss: 1505601487650974334976.0000 - val_loss: 1315214909628630433792.0000\n",
            "Epoch 46/500\n",
            "76/76 [==============================] - 0s 1ms/step - loss: 970031660745470509056.0000 - val_loss: 14454758201859506176.0000\n",
            "Epoch 47/500\n",
            "76/76 [==============================] - 0s 1ms/step - loss: 9782627631206760448.0000 - val_loss: 3561501505930395648.0000\n",
            "Epoch 48/500\n",
            "76/76 [==============================] - 0s 1ms/step - loss: 16161117784795774976.0000 - val_loss: 682830255953543168.0000\n",
            "Epoch 49/500\n",
            "76/76 [==============================] - 0s 1ms/step - loss: 4392854892075548672.0000 - val_loss: 2628870179605446656.0000\n",
            "Epoch 50/500\n",
            "76/76 [==============================] - 0s 1ms/step - loss: 7099284347026407424.0000 - val_loss: 767844976049520640.0000\n",
            "Epoch 51/500\n",
            "76/76 [==============================] - 0s 1ms/step - loss: 1510139775770689536.0000 - val_loss: 367776606447468544.0000\n",
            "Epoch 52/500\n",
            "76/76 [==============================] - 0s 1ms/step - loss: 582388219488763904.0000 - val_loss: 452945395610288128.0000\n",
            "Epoch 53/500\n",
            "76/76 [==============================] - 0s 1ms/step - loss: 248924862683283456.0000 - val_loss: 243350957205749760.0000\n",
            "Epoch 54/500\n",
            "76/76 [==============================] - 0s 2ms/step - loss: 824280777599483904.0000 - val_loss: 324591809797816320.0000\n",
            "Epoch 55/500\n",
            "76/76 [==============================] - 0s 2ms/step - loss: 63790842850050048.0000 - val_loss: 177685150677598208.0000\n",
            "Epoch 56/500\n",
            "76/76 [==============================] - 0s 1ms/step - loss: 578157711061942272.0000 - val_loss: 525750657555103744.0000\n",
            "Epoch 57/500\n",
            "76/76 [==============================] - 0s 1ms/step - loss: 2050890589427204096.0000 - val_loss: 460085624121065472.0000\n",
            "Epoch 58/500\n",
            "76/76 [==============================] - 0s 1ms/step - loss: 3671567567673098240.0000 - val_loss: 602218598890471424.0000\n",
            "Epoch 59/500\n",
            "76/76 [==============================] - 0s 1ms/step - loss: 645658791475412992.0000 - val_loss: 2666198874246348800.0000\n",
            "Epoch 60/500\n",
            "76/76 [==============================] - 0s 2ms/step - loss: 1857924099729260544.0000 - val_loss: 3591471993880313856.0000\n",
            "Epoch 61/500\n",
            "76/76 [==============================] - 0s 1ms/step - loss: 13852599663791702016.0000 - val_loss: 10128395450839990272.0000\n",
            "Epoch 62/500\n",
            "76/76 [==============================] - 0s 1ms/step - loss: 161832419378675580928.0000 - val_loss: 332836419398491176960.0000\n",
            "Epoch 63/500\n",
            "76/76 [==============================] - 0s 1ms/step - loss: 83106964617448914944.0000 - val_loss: 284168322801870045184.0000\n",
            "Epoch 64/500\n",
            "76/76 [==============================] - 0s 1ms/step - loss: 27219061256478523392.0000 - val_loss: 7699723248908369920.0000\n",
            "Epoch 65/500\n",
            "76/76 [==============================] - 0s 1ms/step - loss: 255558977470580391936.0000 - val_loss: 270009638892114804736.0000\n",
            "Epoch 66/500\n",
            "76/76 [==============================] - 0s 1ms/step - loss: 599091973749657829376.0000 - val_loss: 1704558556501692645376.0000\n",
            "Epoch 67/500\n",
            "76/76 [==============================] - 0s 1ms/step - loss: 472030897115863449600.0000 - val_loss: 7178451827452232597504.0000\n",
            "Epoch 68/500\n",
            "76/76 [==============================] - 0s 1ms/step - loss: 4613726712008540160000.0000 - val_loss: 1792915381278516183040.0000\n",
            "Epoch 69/500\n",
            "76/76 [==============================] - 0s 1ms/step - loss: 6312418626308140957696.0000 - val_loss: 4697422733383500300288.0000\n",
            "Epoch 70/500\n",
            "76/76 [==============================] - 0s 1ms/step - loss: 1083198182550780510208.0000 - val_loss: 865349779900638167040.0000\n",
            "Epoch 71/500\n",
            "76/76 [==============================] - 0s 1ms/step - loss: 6196365367510430646272.0000 - val_loss: 7395779219920483516416.0000\n",
            "Epoch 72/500\n",
            "76/76 [==============================] - 0s 1ms/step - loss: 4431292646503202422784.0000 - val_loss: 38587021751295504547840.0000\n",
            "Epoch 73/500\n",
            "76/76 [==============================] - 0s 1ms/step - loss: 7974772121114396065792.0000 - val_loss: 99611865603389784064.0000\n",
            "Epoch 74/500\n",
            "76/76 [==============================] - 0s 1ms/step - loss: 3999694116863824887808.0000 - val_loss: 501488308959796264960.0000\n",
            "Epoch 75/500\n",
            "76/76 [==============================] - 0s 1ms/step - loss: 888231936288610058240.0000 - val_loss: 43895820307887292416.0000\n",
            "Epoch 76/500\n",
            "76/76 [==============================] - 0s 1ms/step - loss: 37566384865571504128.0000 - val_loss: 6052658678790619136.0000\n",
            "Epoch 77/500\n",
            "76/76 [==============================] - 0s 1ms/step - loss: 810911884436832256.0000 - val_loss: 1540782202764132352.0000\n",
            "Epoch 78/500\n",
            "76/76 [==============================] - 0s 1ms/step - loss: 400544904813477888.0000 - val_loss: 51627216294903808.0000\n",
            "Epoch 79/500\n",
            "76/76 [==============================] - 0s 1ms/step - loss: 18610570034937856.0000 - val_loss: 6740291356721152.0000\n",
            "Epoch 80/500\n",
            "76/76 [==============================] - 0s 1ms/step - loss: 5959779834920960.0000 - val_loss: 18116788382334976.0000\n",
            "Epoch 81/500\n",
            "76/76 [==============================] - 0s 1ms/step - loss: 4699291759149056.0000 - val_loss: 13228996414144512.0000\n",
            "Epoch 82/500\n",
            "76/76 [==============================] - 0s 1ms/step - loss: 3623620689526784.0000 - val_loss: 9192277985460224.0000\n",
            "Epoch 83/500\n",
            "76/76 [==============================] - 0s 1ms/step - loss: 4570032034021376.0000 - val_loss: 14420781119307776.0000\n",
            "Epoch 84/500\n",
            "76/76 [==============================] - 0s 1ms/step - loss: 6088473161236480.0000 - val_loss: 5885616487137280.0000\n",
            "Epoch 85/500\n",
            "76/76 [==============================] - 0s 1ms/step - loss: 17521630469160960.0000 - val_loss: 40121179297546240.0000\n",
            "Epoch 86/500\n",
            "76/76 [==============================] - 0s 1ms/step - loss: 6300354635366400.0000 - val_loss: 11622927753543680.0000\n",
            "Epoch 87/500\n",
            "76/76 [==============================] - 0s 1ms/step - loss: 5473697984937984.0000 - val_loss: 14355602843107328.0000\n",
            "Epoch 88/500\n",
            "76/76 [==============================] - 0s 1ms/step - loss: 4133286741803008.0000 - val_loss: 5247709690724352.0000\n",
            "Epoch 89/500\n",
            "76/76 [==============================] - 0s 1ms/step - loss: 7316626575720448.0000 - val_loss: 7821817808945152.0000\n",
            "Epoch 90/500\n",
            "76/76 [==============================] - 0s 1ms/step - loss: 5649641320218624.0000 - val_loss: 13811417601802240.0000\n",
            "Epoch 91/500\n",
            "76/76 [==============================] - 0s 1ms/step - loss: 4957064958836736.0000 - val_loss: 14370146676113408.0000\n",
            "Epoch 92/500\n",
            "76/76 [==============================] - 0s 1ms/step - loss: 7200973306986496.0000 - val_loss: 8859364869799936.0000\n",
            "Epoch 93/500\n",
            "76/76 [==============================] - 0s 1ms/step - loss: 3614494689329152.0000 - val_loss: 5570698747576320.0000\n",
            "Epoch 94/500\n",
            "76/76 [==============================] - 0s 1ms/step - loss: 10983835546157056.0000 - val_loss: 9619695950888960.0000\n",
            "Epoch 95/500\n",
            "76/76 [==============================] - 0s 1ms/step - loss: 18617199316959232.0000 - val_loss: 10721013612412928.0000\n",
            "Epoch 96/500\n",
            "76/76 [==============================] - 0s 1ms/step - loss: 14133701210275840.0000 - val_loss: 16133838488993792.0000\n",
            "Epoch 97/500\n",
            "76/76 [==============================] - 0s 1ms/step - loss: 1755513662572855296.0000 - val_loss: 574143222310240256.0000\n",
            "Epoch 98/500\n",
            "76/76 [==============================] - 0s 1ms/step - loss: 4949410910503436288.0000 - val_loss: 53095614073798656.0000\n",
            "Epoch 99/500\n",
            "76/76 [==============================] - 0s 1ms/step - loss: 8622277306351616.0000 - val_loss: 8564627570950144.0000\n",
            "Epoch 100/500\n",
            "76/76 [==============================] - 0s 1ms/step - loss: 17316411563048960.0000 - val_loss: 22022414745468928.0000\n",
            "Epoch 101/500\n",
            "76/76 [==============================] - 0s 1ms/step - loss: 143455189041414144.0000 - val_loss: 26233323089035264.0000\n",
            "Epoch 102/500\n",
            "76/76 [==============================] - 0s 2ms/step - loss: 312749279292686336.0000 - val_loss: 2870916944221962240.0000\n",
            "Epoch 103/500\n",
            "76/76 [==============================] - 0s 1ms/step - loss: 11326299075650781184.0000 - val_loss: 347748330345924132864.0000\n",
            "Epoch 104/500\n",
            "76/76 [==============================] - 0s 1ms/step - loss: 1307509672878664581120.0000 - val_loss: 16083159111851573248.0000\n",
            "Epoch 105/500\n",
            "76/76 [==============================] - 0s 1ms/step - loss: 216422397641568026624.0000 - val_loss: 227163940149683814400.0000\n",
            "Epoch 106/500\n",
            "76/76 [==============================] - 0s 1ms/step - loss: 1319243098020336631808.0000 - val_loss: 88061680671556370432.0000\n",
            "Epoch 107/500\n",
            "76/76 [==============================] - 0s 1ms/step - loss: 978144825105434279936.0000 - val_loss: 66908044523378573312.0000\n",
            "Epoch 108/500\n",
            "76/76 [==============================] - 0s 1ms/step - loss: 1247450090460516712448.0000 - val_loss: 3856094309470326226944.0000\n",
            "Epoch 109/500\n",
            "76/76 [==============================] - 0s 2ms/step - loss: 447399514485123186688.0000 - val_loss: 225248168681632956416.0000\n",
            "Epoch 110/500\n",
            "76/76 [==============================] - 0s 1ms/step - loss: 545802145996377948160.0000 - val_loss: 2509675646873505890304.0000\n",
            "Epoch 111/500\n",
            "76/76 [==============================] - 0s 1ms/step - loss: 2769860700770698002432.0000 - val_loss: 5698794169879656136704.0000\n",
            "Epoch 112/500\n",
            "76/76 [==============================] - 0s 1ms/step - loss: 2301526308970859331584.0000 - val_loss: 4886270487708167045120.0000\n",
            "Epoch 113/500\n",
            "76/76 [==============================] - 0s 1ms/step - loss: 4647098948197308956672.0000 - val_loss: 354447399607265656832.0000\n",
            "Epoch 114/500\n",
            "76/76 [==============================] - 0s 2ms/step - loss: 8829917870159319531520.0000 - val_loss: 149869820829402923008.0000\n",
            "Epoch 115/500\n",
            "76/76 [==============================] - 0s 1ms/step - loss: 786796024875205001216.0000 - val_loss: 438758901203175735296.0000\n",
            "Epoch 116/500\n",
            "76/76 [==============================] - 0s 1ms/step - loss: 179952845993447260160.0000 - val_loss: 10790089245016981504.0000\n",
            "Epoch 117/500\n",
            "76/76 [==============================] - 0s 1ms/step - loss: 67299558623797051392.0000 - val_loss: 69579501537106853888.0000\n",
            "Epoch 118/500\n",
            "76/76 [==============================] - 0s 1ms/step - loss: 105631577416254095360.0000 - val_loss: 22177481584753508352.0000\n",
            "Epoch 119/500\n",
            "76/76 [==============================] - 0s 1ms/step - loss: 4144231948413304832.0000 - val_loss: 1810482372013981696.0000\n",
            "Epoch 120/500\n",
            "76/76 [==============================] - 0s 1ms/step - loss: 479428335756115968.0000 - val_loss: 1093039283859619840.0000\n",
            "Epoch 121/500\n",
            "76/76 [==============================] - 0s 1ms/step - loss: 223916333270564864.0000 - val_loss: 82317377554874368.0000\n",
            "Epoch 122/500\n",
            "76/76 [==============================] - 0s 1ms/step - loss: 251139072943194112.0000 - val_loss: 203405905927077888.0000\n",
            "Epoch 123/500\n",
            "76/76 [==============================] - 0s 2ms/step - loss: 70659565003210752.0000 - val_loss: 12854930532466688.0000\n",
            "Epoch 124/500\n",
            "76/76 [==============================] - 0s 1ms/step - loss: 1128974416231792640.0000 - val_loss: 384155240892465152.0000\n",
            "Epoch 125/500\n",
            "76/76 [==============================] - 0s 1ms/step - loss: 1174409810104287232.0000 - val_loss: 2370635580171091968.0000\n",
            "Epoch 126/500\n",
            "76/76 [==============================] - 0s 1ms/step - loss: 436701142102048768.0000 - val_loss: 15346848009027584.0000\n",
            "Epoch 127/500\n",
            "76/76 [==============================] - 0s 1ms/step - loss: 6386240022642688.0000 - val_loss: 26163154060836864.0000\n",
            "Epoch 128/500\n",
            "76/76 [==============================] - 0s 1ms/step - loss: 206204626876235776.0000 - val_loss: 38564283717517312.0000\n",
            "Epoch 129/500\n",
            "76/76 [==============================] - 0s 1ms/step - loss: 1764837108859535360.0000 - val_loss: 1682178710901358592.0000\n",
            "Epoch 130/500\n",
            "76/76 [==============================] - 0s 2ms/step - loss: 2346191787418189824.0000 - val_loss: 1609516797785014272.0000\n",
            "Epoch 131/500\n",
            "76/76 [==============================] - 0s 1ms/step - loss: 332156106199531520.0000 - val_loss: 1398799929807208448.0000\n",
            "Epoch 132/500\n",
            "76/76 [==============================] - 0s 2ms/step - loss: 1554465487532851200.0000 - val_loss: 475279294268964864.0000\n",
            "Epoch 133/500\n",
            "76/76 [==============================] - 0s 2ms/step - loss: 553489858455142400.0000 - val_loss: 703658923193794560.0000\n",
            "Epoch 134/500\n",
            "76/76 [==============================] - 0s 1ms/step - loss: 1157972248707989504.0000 - val_loss: 277201707589435392.0000\n",
            "Epoch 135/500\n",
            "76/76 [==============================] - 0s 1ms/step - loss: 1447527124054310912.0000 - val_loss: 248021064125251584.0000\n",
            "Epoch 136/500\n",
            "76/76 [==============================] - 0s 2ms/step - loss: 3430381995539038208.0000 - val_loss: 53266328990771052544.0000\n",
            "Epoch 137/500\n",
            "76/76 [==============================] - 0s 1ms/step - loss: 395429874741360459776.0000 - val_loss: 652255067394673737728.0000\n",
            "Epoch 138/500\n",
            "76/76 [==============================] - 0s 1ms/step - loss: 20300139701758909743104.0000 - val_loss: 11978844299765978497024.0000\n",
            "Epoch 139/500\n",
            "76/76 [==============================] - 0s 1ms/step - loss: 11784736904026496434176.0000 - val_loss: 811913162947003678720.0000\n",
            "Epoch 140/500\n",
            "76/76 [==============================] - 0s 1ms/step - loss: 741644201648583606272.0000 - val_loss: 883153635127540580352.0000\n",
            "Epoch 141/500\n",
            "76/76 [==============================] - 0s 1ms/step - loss: 69615926158311817216.0000 - val_loss: 100146791204442341376.0000\n",
            "Epoch 142/500\n",
            "76/76 [==============================] - 0s 1ms/step - loss: 14950956804358537216.0000 - val_loss: 1078266314348298240.0000\n",
            "Epoch 143/500\n",
            "76/76 [==============================] - 0s 1ms/step - loss: 510084059968307200.0000 - val_loss: 24139996831154176.0000\n",
            "Epoch 144/500\n",
            "76/76 [==============================] - 0s 1ms/step - loss: 69699077171838976.0000 - val_loss: 545342855250444288.0000\n",
            "Epoch 145/500\n",
            "76/76 [==============================] - 0s 1ms/step - loss: 49997091522478080.0000 - val_loss: 9141677902004224.0000\n",
            "Epoch 146/500\n",
            "76/76 [==============================] - 0s 1ms/step - loss: 31532417231618048.0000 - val_loss: 5305374995382272.0000\n",
            "Epoch 147/500\n",
            "76/76 [==============================] - 0s 1ms/step - loss: 4515941215895552.0000 - val_loss: 12707313580244992.0000\n",
            "Epoch 148/500\n",
            "76/76 [==============================] - 0s 1ms/step - loss: 6087917499842560.0000 - val_loss: 9376846688813056.0000\n",
            "Epoch 149/500\n",
            "76/76 [==============================] - 0s 2ms/step - loss: 8120263275184128.0000 - val_loss: 14834802007998464.0000\n",
            "Epoch 150/500\n",
            "76/76 [==============================] - 0s 1ms/step - loss: 4993765454381056.0000 - val_loss: 4659851611340800.0000\n",
            "Epoch 151/500\n",
            "76/76 [==============================] - 0s 1ms/step - loss: 4681929353854976.0000 - val_loss: 6764893466263552.0000\n",
            "Epoch 152/500\n",
            "76/76 [==============================] - 0s 1ms/step - loss: 5010238801444864.0000 - val_loss: 10550451871154176.0000\n",
            "Epoch 153/500\n",
            "76/76 [==============================] - 0s 1ms/step - loss: 9436704574275584.0000 - val_loss: 22696939359305728.0000\n",
            "Epoch 154/500\n",
            "76/76 [==============================] - 0s 1ms/step - loss: 16132816286777344.0000 - val_loss: 5032097500626944.0000\n",
            "Epoch 155/500\n",
            "76/76 [==============================] - 0s 1ms/step - loss: 46603466063216640.0000 - val_loss: 249123152733405184.0000\n",
            "Epoch 156/500\n",
            "76/76 [==============================] - 0s 1ms/step - loss: 99392544026132480.0000 - val_loss: 11490298089701376.0000\n",
            "Epoch 157/500\n",
            "76/76 [==============================] - 0s 1ms/step - loss: 92358684675407872.0000 - val_loss: 22053095844347904.0000\n",
            "Epoch 158/500\n",
            "76/76 [==============================] - 0s 1ms/step - loss: 27471961592430592.0000 - val_loss: 7065558356852736.0000\n",
            "Epoch 159/500\n",
            "76/76 [==============================] - 0s 1ms/step - loss: 21658910188371968.0000 - val_loss: 6253130396205056.0000\n",
            "Epoch 160/500\n",
            "76/76 [==============================] - 0s 1ms/step - loss: 16660750445576192.0000 - val_loss: 4400228354490368.0000\n",
            "Epoch 161/500\n",
            "76/76 [==============================] - 0s 2ms/step - loss: 3660447931703492608.0000 - val_loss: 1163098171916681216.0000\n",
            "Epoch 162/500\n",
            "76/76 [==============================] - 0s 1ms/step - loss: 37745341378108325888.0000 - val_loss: 47753008253195255808.0000\n",
            "Epoch 163/500\n",
            "76/76 [==============================] - 0s 1ms/step - loss: 470597028400127279104.0000 - val_loss: 144537110269852123136.0000\n",
            "Epoch 164/500\n",
            "76/76 [==============================] - 0s 1ms/step - loss: 9453588168506607665152.0000 - val_loss: 44980124616727801626624.0000\n",
            "Epoch 165/500\n",
            "76/76 [==============================] - 0s 1ms/step - loss: 4595894146334013259776.0000 - val_loss: 68762208155901886464.0000\n",
            "Epoch 166/500\n",
            "76/76 [==============================] - 0s 1ms/step - loss: 22526044362944544768.0000 - val_loss: 3883470671258320896.0000\n",
            "Epoch 167/500\n",
            "76/76 [==============================] - 0s 2ms/step - loss: 106730684423751073792.0000 - val_loss: 44120415349069840384.0000\n",
            "Epoch 168/500\n",
            "76/76 [==============================] - 0s 1ms/step - loss: 270361728903607746560.0000 - val_loss: 12933960997319737344.0000\n",
            "Epoch 169/500\n",
            "76/76 [==============================] - 0s 1ms/step - loss: 83235238041991774208.0000 - val_loss: 27716185647768141824.0000\n",
            "Epoch 170/500\n",
            "76/76 [==============================] - 0s 1ms/step - loss: 438974159191615209472.0000 - val_loss: 390959876189334798336.0000\n",
            "Epoch 171/500\n",
            "76/76 [==============================] - 0s 1ms/step - loss: 401686500523684921344.0000 - val_loss: 126997753560127504384.0000\n",
            "Epoch 172/500\n",
            "76/76 [==============================] - 0s 1ms/step - loss: 213410017256438497280.0000 - val_loss: 781413449264311304192.0000\n",
            "Epoch 173/500\n",
            "76/76 [==============================] - 0s 1ms/step - loss: 751787152434352095232.0000 - val_loss: 461485050085305745408.0000\n",
            "Epoch 174/500\n",
            "76/76 [==============================] - 0s 1ms/step - loss: 1109178111794941526016.0000 - val_loss: 4061681380659975684096.0000\n",
            "Epoch 175/500\n",
            "76/76 [==============================] - 0s 1ms/step - loss: 266096784872115798016.0000 - val_loss: 43771738221669515264.0000\n",
            "Epoch 176/500\n",
            "76/76 [==============================] - 0s 1ms/step - loss: 11180349902179794944.0000 - val_loss: 413753544156381184.0000\n",
            "Epoch 177/500\n",
            "76/76 [==============================] - 0s 1ms/step - loss: 2094114590538334208.0000 - val_loss: 8514155151102050304.0000\n",
            "Epoch 178/500\n",
            "76/76 [==============================] - 0s 1ms/step - loss: 24296458194780160000.0000 - val_loss: 30222685131004444672.0000\n",
            "Epoch 179/500\n",
            "76/76 [==============================] - 0s 1ms/step - loss: 34051848723943653376.0000 - val_loss: 10451309921289895936.0000\n",
            "Epoch 180/500\n",
            "76/76 [==============================] - 0s 1ms/step - loss: 17380118838720331776.0000 - val_loss: 41175839647002001408.0000\n",
            "Epoch 181/500\n",
            "76/76 [==============================] - 0s 1ms/step - loss: 2239433632795930394624.0000 - val_loss: 525266259461149818880.0000\n",
            "Epoch 182/500\n",
            "76/76 [==============================] - 0s 1ms/step - loss: 465485618744922210304.0000 - val_loss: 684125212370226118656.0000\n",
            "Epoch 183/500\n",
            "76/76 [==============================] - 0s 1ms/step - loss: 1519882542806854533120.0000 - val_loss: 3258461009418727194624.0000\n",
            "Epoch 184/500\n",
            "76/76 [==============================] - 0s 1ms/step - loss: 942689322245285740544.0000 - val_loss: 109686576299491983360.0000\n",
            "Epoch 185/500\n",
            "76/76 [==============================] - 0s 2ms/step - loss: 224291857448258502656.0000 - val_loss: 1851076837191215742976.0000\n",
            "Epoch 186/500\n",
            "76/76 [==============================] - 0s 1ms/step - loss: 14835192690730652925952.0000 - val_loss: 5748146303446242295808.0000\n",
            "Epoch 187/500\n",
            "76/76 [==============================] - 0s 1ms/step - loss: 9188465199092980514816.0000 - val_loss: 1252874535474196119552.0000\n",
            "Epoch 188/500\n",
            "76/76 [==============================] - 0s 1ms/step - loss: 145749000782079852544.0000 - val_loss: 44113681939861340160.0000\n",
            "Epoch 189/500\n",
            "76/76 [==============================] - 0s 1ms/step - loss: 90644345524271972352.0000 - val_loss: 10379843864507711488.0000\n",
            "Epoch 190/500\n",
            "76/76 [==============================] - 0s 1ms/step - loss: 10656055479056203776.0000 - val_loss: 12300149718511517696.0000\n",
            "Epoch 191/500\n",
            "76/76 [==============================] - 0s 1ms/step - loss: 8226215595775885312.0000 - val_loss: 39237189541000380416.0000\n",
            "Epoch 192/500\n",
            "76/76 [==============================] - 0s 2ms/step - loss: 70605807680705527808.0000 - val_loss: 492179784420294656.0000\n",
            "Epoch 193/500\n",
            "76/76 [==============================] - 0s 1ms/step - loss: 43961610685646897152.0000 - val_loss: 104165532592242688000.0000\n",
            "Epoch 194/500\n",
            "76/76 [==============================] - 0s 2ms/step - loss: 58402209376763904000.0000 - val_loss: 5990869973600305152.0000\n",
            "Epoch 195/500\n",
            "76/76 [==============================] - 0s 2ms/step - loss: 12234401122193768448.0000 - val_loss: 26438458578292441088.0000\n",
            "Epoch 196/500\n",
            "76/76 [==============================] - 0s 1ms/step - loss: 11164920455507214336.0000 - val_loss: 204237961351397376.0000\n",
            "Epoch 197/500\n",
            "76/76 [==============================] - 0s 2ms/step - loss: 2894057265940135936.0000 - val_loss: 104622328133976064.0000\n",
            "Epoch 198/500\n",
            "76/76 [==============================] - 0s 1ms/step - loss: 740348664140005376.0000 - val_loss: 10028380342714368.0000\n",
            "Epoch 199/500\n",
            "76/76 [==============================] - 0s 1ms/step - loss: 169318760543420416.0000 - val_loss: 246863965575970816.0000\n",
            "Epoch 200/500\n",
            "76/76 [==============================] - 0s 2ms/step - loss: 49821371525496832.0000 - val_loss: 7192961045495808.0000\n",
            "Epoch 201/500\n",
            "76/76 [==============================] - 0s 1ms/step - loss: 41077930507370496.0000 - val_loss: 10025415741538304.0000\n",
            "Epoch 202/500\n",
            "76/76 [==============================] - 0s 2ms/step - loss: 12229478067470336.0000 - val_loss: 14539619643162624.0000\n",
            "Epoch 203/500\n",
            "76/76 [==============================] - 0s 1ms/step - loss: 28667152206659584.0000 - val_loss: 8965069383663616.0000\n",
            "Epoch 204/500\n",
            "76/76 [==============================] - 0s 1ms/step - loss: 57641965805633536.0000 - val_loss: 92927312575594496.0000\n",
            "Epoch 205/500\n",
            "76/76 [==============================] - 0s 1ms/step - loss: 108236998380093440.0000 - val_loss: 42888220567928832.0000\n",
            "Epoch 206/500\n",
            "76/76 [==============================] - 0s 2ms/step - loss: 15024778015047417856.0000 - val_loss: 37142364803389456384.0000\n",
            "Epoch 207/500\n",
            "76/76 [==============================] - 0s 1ms/step - loss: 7232505024138444800.0000 - val_loss: 173959540051835617280.0000\n",
            "Epoch 208/500\n",
            "76/76 [==============================] - 0s 1ms/step - loss: 277450095649926152192.0000 - val_loss: 939634615060533346304.0000\n",
            "Epoch 209/500\n",
            "76/76 [==============================] - 0s 1ms/step - loss: 2246711309056272760832.0000 - val_loss: 12428252877081746079744.0000\n",
            "Epoch 210/500\n",
            "76/76 [==============================] - 0s 1ms/step - loss: 1376082184492449529856.0000 - val_loss: 778101966532054614016.0000\n",
            "Epoch 211/500\n",
            "76/76 [==============================] - 0s 1ms/step - loss: 10231465658744735531008.0000 - val_loss: 9287324840413297115136.0000\n",
            "Epoch 212/500\n",
            "76/76 [==============================] - 0s 2ms/step - loss: 3299182557249411219456.0000 - val_loss: 1186390849662580948992.0000\n",
            "Epoch 213/500\n",
            "76/76 [==============================] - 0s 1ms/step - loss: 1477609223429564661760.0000 - val_loss: 2146709301542975963136.0000\n",
            "Epoch 214/500\n",
            "76/76 [==============================] - 0s 1ms/step - loss: 734678681137413357568.0000 - val_loss: 2423025827092944125952.0000\n",
            "Epoch 215/500\n",
            "76/76 [==============================] - 0s 1ms/step - loss: 441146512693123874816.0000 - val_loss: 10698902347679006720.0000\n",
            "Epoch 216/500\n",
            "76/76 [==============================] - 0s 1ms/step - loss: 200043421523333087232.0000 - val_loss: 323112549668672765952.0000\n",
            "Epoch 217/500\n",
            "76/76 [==============================] - 0s 1ms/step - loss: 39224479186583289856.0000 - val_loss: 34356003893936128.0000\n",
            "Epoch 218/500\n",
            "76/76 [==============================] - 0s 1ms/step - loss: 5273170355639287808.0000 - val_loss: 4243945008668868608.0000\n",
            "Epoch 219/500\n",
            "76/76 [==============================] - 0s 1ms/step - loss: 1960747678379802624.0000 - val_loss: 2858516377205997568.0000\n",
            "Epoch 220/500\n",
            "76/76 [==============================] - 0s 1ms/step - loss: 446956665011437568.0000 - val_loss: 123846301103161344.0000\n",
            "Epoch 221/500\n",
            "76/76 [==============================] - 0s 1ms/step - loss: 74469072145743872.0000 - val_loss: 13567402256105472.0000\n",
            "Epoch 222/500\n",
            "76/76 [==============================] - 0s 1ms/step - loss: 188341565834395648.0000 - val_loss: 91686633962733568.0000\n",
            "Epoch 223/500\n",
            "76/76 [==============================] - 0s 1ms/step - loss: 12927827938639872.0000 - val_loss: 109910360588288000.0000\n",
            "Epoch 224/500\n",
            "76/76 [==============================] - 0s 1ms/step - loss: 123488118010544128.0000 - val_loss: 1473991819179065344.0000\n",
            "Epoch 225/500\n",
            "76/76 [==============================] - 0s 1ms/step - loss: 1152134254281359360.0000 - val_loss: 9778877197044416512.0000\n",
            "Epoch 226/500\n",
            "76/76 [==============================] - 0s 1ms/step - loss: 900598635597660160.0000 - val_loss: 404043825690968064.0000\n",
            "Epoch 227/500\n",
            "76/76 [==============================] - 0s 1ms/step - loss: 2321102856217690112.0000 - val_loss: 254133043105628160.0000\n",
            "Epoch 228/500\n",
            "76/76 [==============================] - 0s 2ms/step - loss: 575270565326094336.0000 - val_loss: 394770338463875072.0000\n",
            "Epoch 229/500\n",
            "76/76 [==============================] - 0s 2ms/step - loss: 4754525773015023616.0000 - val_loss: 5036703887411642368.0000\n",
            "Epoch 230/500\n",
            "76/76 [==============================] - 0s 2ms/step - loss: 12847648235027693568.0000 - val_loss: 4426151677577396224.0000\n",
            "Epoch 231/500\n",
            "76/76 [==============================] - 0s 1ms/step - loss: 1646524297591652352.0000 - val_loss: 3594322477775323136.0000\n",
            "Epoch 232/500\n",
            "76/76 [==============================] - 0s 1ms/step - loss: 508702489248268288.0000 - val_loss: 60650886749224960.0000\n",
            "Epoch 233/500\n",
            "76/76 [==============================] - 0s 2ms/step - loss: 250248313905872896.0000 - val_loss: 1094219403433607168.0000\n",
            "Epoch 234/500\n",
            "76/76 [==============================] - 0s 1ms/step - loss: 7856837413203607552.0000 - val_loss: 96635153375465308160.0000\n",
            "Epoch 235/500\n",
            "76/76 [==============================] - 0s 2ms/step - loss: 30742408884291371008.0000 - val_loss: 30077886046696112128.0000\n",
            "Epoch 236/500\n",
            "76/76 [==============================] - 0s 1ms/step - loss: 19803928450478112768.0000 - val_loss: 252895045514432610304.0000\n",
            "Epoch 237/500\n",
            "76/76 [==============================] - 0s 2ms/step - loss: 9924695088827046297600.0000 - val_loss: 8200852822408394964992.0000\n",
            "Epoch 238/500\n",
            "76/76 [==============================] - 0s 1ms/step - loss: 12668563827298328903680.0000 - val_loss: 404456143925773598720.0000\n",
            "Epoch 239/500\n",
            "76/76 [==============================] - 0s 1ms/step - loss: 1370114492773718556672.0000 - val_loss: 512553547691129307136.0000\n",
            "Epoch 240/500\n",
            "76/76 [==============================] - 0s 1ms/step - loss: 54798419279239708672.0000 - val_loss: 203653584390251872256.0000\n",
            "Epoch 241/500\n",
            "76/76 [==============================] - 0s 1ms/step - loss: 17128815560587476992.0000 - val_loss: 458171408736845824.0000\n",
            "Epoch 242/500\n",
            "76/76 [==============================] - 0s 1ms/step - loss: 400938942293082112.0000 - val_loss: 4284102196972224512.0000\n",
            "Epoch 243/500\n",
            "76/76 [==============================] - 0s 1ms/step - loss: 793851243544969216.0000 - val_loss: 32229103876702208.0000\n",
            "Epoch 244/500\n",
            "76/76 [==============================] - 0s 1ms/step - loss: 217836875782553600.0000 - val_loss: 260819585630994432.0000\n",
            "Epoch 245/500\n",
            "76/76 [==============================] - 0s 1ms/step - loss: 38026528042254336.0000 - val_loss: 12212964991959040.0000\n",
            "Epoch 246/500\n",
            "76/76 [==============================] - 0s 1ms/step - loss: 5870070316138496.0000 - val_loss: 12131885673086976.0000\n",
            "Epoch 247/500\n",
            "76/76 [==============================] - 0s 1ms/step - loss: 4808282459865088.0000 - val_loss: 6139896804671488.0000\n",
            "Epoch 248/500\n",
            "76/76 [==============================] - 0s 1ms/step - loss: 6561849961086976.0000 - val_loss: 5860596692025344.0000\n",
            "Epoch 249/500\n",
            "76/76 [==============================] - 0s 1ms/step - loss: 4740901402312704.0000 - val_loss: 6631374744190976.0000\n",
            "Epoch 250/500\n",
            "76/76 [==============================] - 0s 1ms/step - loss: 5969065554214912.0000 - val_loss: 41571082947264512.0000\n",
            "Epoch 251/500\n",
            "76/76 [==============================] - 0s 1ms/step - loss: 9256504926404608.0000 - val_loss: 17044950302588928.0000\n",
            "Epoch 252/500\n",
            "76/76 [==============================] - 0s 1ms/step - loss: 35374583305469952.0000 - val_loss: 27270263485759488.0000\n",
            "Epoch 253/500\n",
            "76/76 [==============================] - 0s 1ms/step - loss: 321874332450029568.0000 - val_loss: 226782296227708928.0000\n",
            "Epoch 254/500\n",
            "76/76 [==============================] - 0s 1ms/step - loss: 461307250259001344.0000 - val_loss: 909267253990522880.0000\n",
            "Epoch 255/500\n",
            "76/76 [==============================] - 0s 2ms/step - loss: 419989938649876660224.0000 - val_loss: 2495644682234433110016.0000\n",
            "Epoch 256/500\n",
            "76/76 [==============================] - 0s 1ms/step - loss: 1630532889426603802624.0000 - val_loss: 6667096800211937263616.0000\n",
            "Epoch 257/500\n",
            "76/76 [==============================] - 0s 2ms/step - loss: 651515210418389778432.0000 - val_loss: 1095975735820025856.0000\n",
            "Epoch 258/500\n",
            "76/76 [==============================] - 0s 1ms/step - loss: 26061407453825728512.0000 - val_loss: 204629985900089049088.0000\n",
            "Epoch 259/500\n",
            "76/76 [==============================] - 0s 1ms/step - loss: 14072495392277135360.0000 - val_loss: 5026310203994275840.0000\n",
            "Epoch 260/500\n",
            "76/76 [==============================] - 0s 2ms/step - loss: 11731989179486175232.0000 - val_loss: 16650285010435178496.0000\n",
            "Epoch 261/500\n",
            "76/76 [==============================] - 0s 2ms/step - loss: 7712234591720833024.0000 - val_loss: 1534986951852032000.0000\n",
            "Epoch 262/500\n",
            "76/76 [==============================] - 0s 1ms/step - loss: 1307156322826846208.0000 - val_loss: 1530033102213087232.0000\n",
            "Epoch 263/500\n",
            "76/76 [==============================] - 0s 1ms/step - loss: 2464326890119233536.0000 - val_loss: 5695247580775055360.0000\n",
            "Epoch 264/500\n",
            "76/76 [==============================] - 0s 1ms/step - loss: 18413901661387882496.0000 - val_loss: 8072440648294203392.0000\n",
            "Epoch 265/500\n",
            "76/76 [==============================] - 0s 1ms/step - loss: 45328844598693330944.0000 - val_loss: 41420977963437916160.0000\n",
            "Epoch 266/500\n",
            "76/76 [==============================] - 0s 1ms/step - loss: 29154410628573560832.0000 - val_loss: 2514966547403898880.0000\n",
            "Epoch 267/500\n",
            "76/76 [==============================] - 0s 1ms/step - loss: 28354566496901398528.0000 - val_loss: 17649615735757996032.0000\n",
            "Epoch 268/500\n",
            "76/76 [==============================] - 0s 2ms/step - loss: 33007237910765764608.0000 - val_loss: 2083299519289622528.0000\n",
            "Epoch 269/500\n",
            "76/76 [==============================] - 0s 1ms/step - loss: 54617061433307824128.0000 - val_loss: 1198276771569467392.0000\n",
            "Epoch 270/500\n",
            "76/76 [==============================] - 0s 2ms/step - loss: 1760545989854232576.0000 - val_loss: 545310076060041216.0000\n",
            "Epoch 271/500\n",
            "76/76 [==============================] - 0s 1ms/step - loss: 3004635425223475200.0000 - val_loss: 1409117746922258432.0000\n",
            "Epoch 272/500\n",
            "76/76 [==============================] - 0s 2ms/step - loss: 15704829255361757184.0000 - val_loss: 17503740229566070784.0000\n",
            "Epoch 273/500\n",
            "76/76 [==============================] - 0s 1ms/step - loss: 3728014295619862528.0000 - val_loss: 106956797478174720.0000\n",
            "Epoch 274/500\n",
            "76/76 [==============================] - 0s 1ms/step - loss: 557098043300642816.0000 - val_loss: 53439426205843456.0000\n",
            "Epoch 275/500\n",
            "76/76 [==============================] - 0s 1ms/step - loss: 6197586405959401472.0000 - val_loss: 1514514869976563712.0000\n",
            "Epoch 276/500\n",
            "76/76 [==============================] - 0s 1ms/step - loss: 13734753884381368025088.0000 - val_loss: 951291619746028453888.0000\n",
            "Epoch 277/500\n",
            "76/76 [==============================] - 0s 1ms/step - loss: 3547201418228238647296.0000 - val_loss: 3264264179013570789376.0000\n",
            "Epoch 278/500\n",
            "76/76 [==============================] - 0s 1ms/step - loss: 210715932293410586624.0000 - val_loss: 289902372697745129472.0000\n",
            "Epoch 279/500\n",
            "76/76 [==============================] - 0s 1ms/step - loss: 675076917768885370880.0000 - val_loss: 290402377809499521024.0000\n",
            "Epoch 280/500\n",
            "76/76 [==============================] - 0s 1ms/step - loss: 18134423943151035088896.0000 - val_loss: 29814570375331385966592.0000\n",
            "Epoch 281/500\n",
            "76/76 [==============================] - 0s 2ms/step - loss: 4108589748478759927808.0000 - val_loss: 32146263131612512256.0000\n",
            "Epoch 282/500\n",
            "76/76 [==============================] - 0s 1ms/step - loss: 3429501812291747708928.0000 - val_loss: 792499833803269734400.0000\n",
            "Epoch 283/500\n",
            "76/76 [==============================] - 0s 1ms/step - loss: 354548554677021048832.0000 - val_loss: 705653685226452287488.0000\n",
            "Epoch 284/500\n",
            "76/76 [==============================] - 0s 1ms/step - loss: 2526366268567517659136.0000 - val_loss: 291269971648651984896.0000\n",
            "Epoch 285/500\n",
            "76/76 [==============================] - 0s 1ms/step - loss: 2532926887324689629184.0000 - val_loss: 145696584863760515072.0000\n",
            "Epoch 286/500\n",
            "76/76 [==============================] - 0s 1ms/step - loss: 359819982856486125568.0000 - val_loss: 14823124283978416128.0000\n",
            "Epoch 287/500\n",
            "76/76 [==============================] - 0s 2ms/step - loss: 683783944851685376.0000 - val_loss: 63439514525237248.0000\n",
            "Epoch 288/500\n",
            "76/76 [==============================] - 0s 1ms/step - loss: 51691950041989120.0000 - val_loss: 14331262189699072.0000\n",
            "Epoch 289/500\n",
            "76/76 [==============================] - 0s 1ms/step - loss: 5937366548086784.0000 - val_loss: 11331200689897472.0000\n",
            "Epoch 290/500\n",
            "76/76 [==============================] - 0s 1ms/step - loss: 5245803262115840.0000 - val_loss: 8187956791607296.0000\n",
            "Epoch 291/500\n",
            "76/76 [==============================] - 0s 1ms/step - loss: 6136833419247616.0000 - val_loss: 17719763752976384.0000\n",
            "Epoch 292/500\n",
            "76/76 [==============================] - 0s 1ms/step - loss: 4644985118916608.0000 - val_loss: 21753339339341824.0000\n",
            "Epoch 293/500\n",
            "76/76 [==============================] - 0s 1ms/step - loss: 5709730060173312.0000 - val_loss: 8171771207352320.0000\n",
            "Epoch 294/500\n",
            "76/76 [==============================] - 0s 1ms/step - loss: 5350078088740864.0000 - val_loss: 6119943460356096.0000\n",
            "Epoch 295/500\n",
            "76/76 [==============================] - 0s 1ms/step - loss: 10955874235318272.0000 - val_loss: 5858602216587264.0000\n",
            "Epoch 296/500\n",
            "76/76 [==============================] - 0s 1ms/step - loss: 12961265332781056.0000 - val_loss: 50027117638844416.0000\n",
            "Epoch 297/500\n",
            "76/76 [==============================] - 0s 2ms/step - loss: 12490375855865856.0000 - val_loss: 30117942767124480.0000\n",
            "Epoch 298/500\n",
            "76/76 [==============================] - 0s 2ms/step - loss: 26234564334583808.0000 - val_loss: 6190577955635200.0000\n",
            "Epoch 299/500\n",
            "76/76 [==============================] - 0s 2ms/step - loss: 235975312947544064.0000 - val_loss: 13852825381502976.0000\n",
            "Epoch 300/500\n",
            "76/76 [==============================] - 0s 2ms/step - loss: 16287880712290304.0000 - val_loss: 5052087352164352.0000\n",
            "Epoch 301/500\n",
            "76/76 [==============================] - 0s 2ms/step - loss: 132832686946385920.0000 - val_loss: 502824362647224320.0000\n",
            "Epoch 302/500\n",
            "76/76 [==============================] - 0s 1ms/step - loss: 1933187457356922880.0000 - val_loss: 551347700566589440.0000\n",
            "Epoch 303/500\n",
            "76/76 [==============================] - 0s 1ms/step - loss: 665779098349469696.0000 - val_loss: 2898503141207048192.0000\n",
            "Epoch 304/500\n",
            "76/76 [==============================] - 0s 1ms/step - loss: 1286359885021184000.0000 - val_loss: 245136838967164928.0000\n",
            "Epoch 305/500\n",
            "76/76 [==============================] - 0s 2ms/step - loss: 380832757271494656.0000 - val_loss: 449935654327943168.0000\n",
            "Epoch 306/500\n",
            "76/76 [==============================] - 0s 1ms/step - loss: 3648618011222343680.0000 - val_loss: 3267017932273614848.0000\n",
            "Epoch 307/500\n",
            "76/76 [==============================] - 0s 1ms/step - loss: 201651452880908976128.0000 - val_loss: 53337669703227670528.0000\n",
            "Epoch 308/500\n",
            "76/76 [==============================] - 0s 2ms/step - loss: 304495724340285800448.0000 - val_loss: 555365997201936351232.0000\n",
            "Epoch 309/500\n",
            "76/76 [==============================] - 0s 1ms/step - loss: 2562143145482325590016.0000 - val_loss: 68411419966176231424.0000\n",
            "Epoch 310/500\n",
            "76/76 [==============================] - 0s 1ms/step - loss: 752996791146766139392.0000 - val_loss: 2202668215762914639872.0000\n",
            "Epoch 311/500\n",
            "76/76 [==============================] - 0s 2ms/step - loss: 306946069565668327424.0000 - val_loss: 22519440696108122112.0000\n",
            "Epoch 312/500\n",
            "76/76 [==============================] - 0s 1ms/step - loss: 99853256784198238208.0000 - val_loss: 719154351009402191872.0000\n",
            "Epoch 313/500\n",
            "76/76 [==============================] - 0s 1ms/step - loss: 11396480454250979131392.0000 - val_loss: 1453655139961534414848.0000\n",
            "Epoch 314/500\n",
            "76/76 [==============================] - 0s 2ms/step - loss: 5427357716738408972288.0000 - val_loss: 37251563900213657600.0000\n",
            "Epoch 315/500\n",
            "76/76 [==============================] - 0s 2ms/step - loss: 8646495264535773970432.0000 - val_loss: 3391870578230369976320.0000\n",
            "Epoch 316/500\n",
            "76/76 [==============================] - 0s 2ms/step - loss: 2816375285097064038400.0000 - val_loss: 350336809416127414272.0000\n",
            "Epoch 317/500\n",
            "76/76 [==============================] - 0s 1ms/step - loss: 4776281888758664527872.0000 - val_loss: 1619138219419403026432.0000\n",
            "Epoch 318/500\n",
            "76/76 [==============================] - 0s 1ms/step - loss: 168952012255222824960.0000 - val_loss: 334387065045190180864.0000\n",
            "Epoch 319/500\n",
            "76/76 [==============================] - 0s 1ms/step - loss: 296352125498465189888.0000 - val_loss: 8182517705153183744.0000\n",
            "Epoch 320/500\n",
            "76/76 [==============================] - 0s 1ms/step - loss: 74315102515984596992.0000 - val_loss: 119891952957439082496.0000\n",
            "Epoch 321/500\n",
            "76/76 [==============================] - 0s 1ms/step - loss: 66732324973073924096.0000 - val_loss: 295329139879982399488.0000\n",
            "Epoch 322/500\n",
            "76/76 [==============================] - 0s 1ms/step - loss: 21687761304765333504.0000 - val_loss: 8879133088139968512.0000\n",
            "Epoch 323/500\n",
            "76/76 [==============================] - 0s 1ms/step - loss: 7554177046448963584.0000 - val_loss: 8147383910599229440.0000\n",
            "Epoch 324/500\n",
            "76/76 [==============================] - 0s 1ms/step - loss: 4126108698252673024.0000 - val_loss: 784177808963272704.0000\n",
            "Epoch 325/500\n",
            "76/76 [==============================] - 0s 1ms/step - loss: 1438432238747254784.0000 - val_loss: 2406487905573797888.0000\n",
            "Epoch 326/500\n",
            "76/76 [==============================] - 0s 1ms/step - loss: 489608335960571904.0000 - val_loss: 2064937400227856384.0000\n",
            "Epoch 327/500\n",
            "76/76 [==============================] - 0s 1ms/step - loss: 611841455937290240.0000 - val_loss: 1082294031599271936.0000\n",
            "Epoch 328/500\n",
            "76/76 [==============================] - 0s 1ms/step - loss: 303999468838060032.0000 - val_loss: 401979252091650048.0000\n",
            "Epoch 329/500\n",
            "76/76 [==============================] - 0s 1ms/step - loss: 430536730160922624.0000 - val_loss: 177400995641294848.0000\n",
            "Epoch 330/500\n",
            "76/76 [==============================] - 0s 1ms/step - loss: 328899765074919424.0000 - val_loss: 175158953993306112.0000\n",
            "Epoch 331/500\n",
            "76/76 [==============================] - 0s 1ms/step - loss: 181829725398761472.0000 - val_loss: 888910964433354752.0000\n",
            "Epoch 332/500\n",
            "76/76 [==============================] - 0s 1ms/step - loss: 2506758143346737152.0000 - val_loss: 1756860152000020480.0000\n",
            "Epoch 333/500\n",
            "76/76 [==============================] - 0s 1ms/step - loss: 1909720718124253184.0000 - val_loss: 472418468092706816.0000\n",
            "Epoch 334/500\n",
            "76/76 [==============================] - 0s 1ms/step - loss: 1177582725784141824.0000 - val_loss: 122480200855322624.0000\n",
            "Epoch 335/500\n",
            "76/76 [==============================] - 0s 1ms/step - loss: 391356011262246912.0000 - val_loss: 597671431114850304.0000\n",
            "Epoch 336/500\n",
            "76/76 [==============================] - 0s 1ms/step - loss: 334085749106278400.0000 - val_loss: 81621610032791552.0000\n",
            "Epoch 337/500\n",
            "76/76 [==============================] - 0s 1ms/step - loss: 71299416346066944.0000 - val_loss: 2170458905535053824.0000\n",
            "Epoch 338/500\n",
            "76/76 [==============================] - 0s 1ms/step - loss: 724921279051726848.0000 - val_loss: 439018569016016896.0000\n",
            "Epoch 339/500\n",
            "76/76 [==============================] - 0s 1ms/step - loss: 573899817923641344.0000 - val_loss: 27125207407788032.0000\n",
            "Epoch 340/500\n",
            "76/76 [==============================] - 0s 2ms/step - loss: 83436697571819520.0000 - val_loss: 16751305536045056.0000\n",
            "Epoch 341/500\n",
            "76/76 [==============================] - 0s 1ms/step - loss: 2087247040911245312.0000 - val_loss: 1104377997521059840.0000\n",
            "Epoch 342/500\n",
            "76/76 [==============================] - 0s 1ms/step - loss: 2252592973885734912.0000 - val_loss: 56003598990966784.0000\n",
            "Epoch 343/500\n",
            "76/76 [==============================] - 0s 1ms/step - loss: 52929429831927463936.0000 - val_loss: 362987209663178604544.0000\n",
            "Epoch 344/500\n",
            "76/76 [==============================] - 0s 1ms/step - loss: 343825941361089052672.0000 - val_loss: 321337392543674925056.0000\n",
            "Epoch 345/500\n",
            "76/76 [==============================] - 0s 1ms/step - loss: 2989421034229194555392.0000 - val_loss: 3758078248655211462656.0000\n",
            "Epoch 346/500\n",
            "76/76 [==============================] - 0s 1ms/step - loss: 1046858214945062912000.0000 - val_loss: 810787263040161054720.0000\n",
            "Epoch 347/500\n",
            "76/76 [==============================] - 0s 1ms/step - loss: 4029141184502363586560.0000 - val_loss: 3408888555322296238080.0000\n",
            "Epoch 348/500\n",
            "76/76 [==============================] - 0s 1ms/step - loss: 138216598463907364864.0000 - val_loss: 532079607563035869184.0000\n",
            "Epoch 349/500\n",
            "76/76 [==============================] - 0s 1ms/step - loss: 186711658318595620864.0000 - val_loss: 995139932355502800896.0000\n",
            "Epoch 350/500\n",
            "76/76 [==============================] - 0s 1ms/step - loss: 1525054082553959415808.0000 - val_loss: 698194457606131548160.0000\n",
            "Epoch 351/500\n",
            "76/76 [==============================] - 0s 1ms/step - loss: 1149812613489077780480.0000 - val_loss: 80847054805997191168.0000\n",
            "Epoch 352/500\n",
            "76/76 [==============================] - 0s 1ms/step - loss: 2427543781944126865408.0000 - val_loss: 12991958309340549480448.0000\n",
            "Epoch 353/500\n",
            "76/76 [==============================] - 0s 1ms/step - loss: 1112334853658751533056.0000 - val_loss: 425235682237716889600.0000\n",
            "Epoch 354/500\n",
            "76/76 [==============================] - 0s 1ms/step - loss: 125152192506579910656.0000 - val_loss: 530590816042469031936.0000\n",
            "Epoch 355/500\n",
            "76/76 [==============================] - 0s 1ms/step - loss: 12124812719088497328128.0000 - val_loss: 26427687762386747392.0000\n",
            "Epoch 356/500\n",
            "76/76 [==============================] - 0s 1ms/step - loss: 949764829103605678080.0000 - val_loss: 77214760969034530816.0000\n",
            "Epoch 357/500\n",
            "76/76 [==============================] - 0s 1ms/step - loss: 2747433337576346353664.0000 - val_loss: 482685886068640710656.0000\n",
            "Epoch 358/500\n",
            "76/76 [==============================] - 0s 1ms/step - loss: 856965766244334567424.0000 - val_loss: 18410138033086005248.0000\n",
            "Epoch 359/500\n",
            "76/76 [==============================] - 0s 1ms/step - loss: 95212921890797518848.0000 - val_loss: 245343969090773975040.0000\n",
            "Epoch 360/500\n",
            "76/76 [==============================] - 0s 1ms/step - loss: 73647681365738520576.0000 - val_loss: 101103607457251328.0000\n",
            "Epoch 361/500\n",
            "76/76 [==============================] - 0s 1ms/step - loss: 13606715878472155136.0000 - val_loss: 36724669132090376192.0000\n",
            "Epoch 362/500\n",
            "76/76 [==============================] - 0s 1ms/step - loss: 17562646565024169984.0000 - val_loss: 5613379044482482176.0000\n",
            "Epoch 363/500\n",
            "76/76 [==============================] - 0s 1ms/step - loss: 6014202709853339648.0000 - val_loss: 995463193172115456.0000\n",
            "Epoch 364/500\n",
            "76/76 [==============================] - 0s 1ms/step - loss: 4661425725444718592.0000 - val_loss: 2964442227914309632.0000\n",
            "Epoch 365/500\n",
            "76/76 [==============================] - 0s 1ms/step - loss: 4296701500714909696.0000 - val_loss: 944186987374444544.0000\n",
            "Epoch 366/500\n",
            "76/76 [==============================] - 0s 2ms/step - loss: 1521866754475687936.0000 - val_loss: 2704860451858022400.0000\n",
            "Epoch 367/500\n",
            "76/76 [==============================] - 0s 1ms/step - loss: 8940758515853557760.0000 - val_loss: 42311454838587654144.0000\n",
            "Epoch 368/500\n",
            "76/76 [==============================] - 0s 1ms/step - loss: 35383084626296700928.0000 - val_loss: 92899241562701037568.0000\n",
            "Epoch 369/500\n",
            "76/76 [==============================] - 0s 1ms/step - loss: 86845990247143047168.0000 - val_loss: 29813068671146262528.0000\n",
            "Epoch 370/500\n",
            "76/76 [==============================] - 0s 1ms/step - loss: 2438626355575783424.0000 - val_loss: 2518430009031393280.0000\n",
            "Epoch 371/500\n",
            "76/76 [==============================] - 0s 1ms/step - loss: 4472366075438170112.0000 - val_loss: 4403979475847479296.0000\n",
            "Epoch 372/500\n",
            "76/76 [==============================] - 0s 2ms/step - loss: 8682385927709917184.0000 - val_loss: 1537361622090121216.0000\n",
            "Epoch 373/500\n",
            "76/76 [==============================] - 0s 1ms/step - loss: 5824236237631782912.0000 - val_loss: 675682537019801600.0000\n",
            "Epoch 374/500\n",
            "76/76 [==============================] - 0s 1ms/step - loss: 93374749555388579840.0000 - val_loss: 19009628056433197056.0000\n",
            "Epoch 375/500\n",
            "76/76 [==============================] - 0s 2ms/step - loss: 5855593209744326656.0000 - val_loss: 1787596999554498560.0000\n",
            "Epoch 376/500\n",
            "76/76 [==============================] - 0s 1ms/step - loss: 12125365852602105856.0000 - val_loss: 82117870345380691968.0000\n",
            "Epoch 377/500\n",
            "76/76 [==============================] - 0s 1ms/step - loss: 435025628218318127104.0000 - val_loss: 1829896448825622528.0000\n",
            "Epoch 378/500\n",
            "76/76 [==============================] - 0s 1ms/step - loss: 1344603852684478382080.0000 - val_loss: 58195087774369972224.0000\n",
            "Epoch 379/500\n",
            "76/76 [==============================] - 0s 1ms/step - loss: 128694889340018360320.0000 - val_loss: 784894520670036164608.0000\n",
            "Epoch 380/500\n",
            "76/76 [==============================] - 0s 2ms/step - loss: 4588583396763907391488.0000 - val_loss: 15883399874501601656832.0000\n",
            "Epoch 381/500\n",
            "76/76 [==============================] - 0s 1ms/step - loss: 13034291019937925300224.0000 - val_loss: 44986663385989906432.0000\n",
            "Epoch 382/500\n",
            "76/76 [==============================] - 0s 1ms/step - loss: 100924647302582239232.0000 - val_loss: 719396645439012864.0000\n",
            "Epoch 383/500\n",
            "76/76 [==============================] - 0s 1ms/step - loss: 21476142699813797888.0000 - val_loss: 54266620689256546304.0000\n",
            "Epoch 384/500\n",
            "76/76 [==============================] - 0s 2ms/step - loss: 11853928317541416960.0000 - val_loss: 5363849828361043968.0000\n",
            "Epoch 385/500\n",
            "76/76 [==============================] - 0s 1ms/step - loss: 20014865358220427264.0000 - val_loss: 2208356185126469632.0000\n",
            "Epoch 386/500\n",
            "76/76 [==============================] - 0s 1ms/step - loss: 2301551065574670336.0000 - val_loss: 318818549118271488.0000\n",
            "Epoch 387/500\n",
            "76/76 [==============================] - 0s 1ms/step - loss: 1493418265496518656.0000 - val_loss: 134136261060329472.0000\n",
            "Epoch 388/500\n",
            "76/76 [==============================] - 0s 2ms/step - loss: 2061862203643920384.0000 - val_loss: 1527951726701707264.0000\n",
            "Epoch 389/500\n",
            "76/76 [==============================] - 0s 1ms/step - loss: 78526830184692187136.0000 - val_loss: 26950004164091969536.0000\n",
            "Epoch 390/500\n",
            "76/76 [==============================] - 0s 1ms/step - loss: 24839458609227104256.0000 - val_loss: 23459487953484513280.0000\n",
            "Epoch 391/500\n",
            "76/76 [==============================] - 0s 1ms/step - loss: 5254627641792659456.0000 - val_loss: 308624117823700992.0000\n",
            "Epoch 392/500\n",
            "76/76 [==============================] - 0s 1ms/step - loss: 48878514534875136.0000 - val_loss: 31986002285297664.0000\n",
            "Epoch 393/500\n",
            "76/76 [==============================] - 0s 1ms/step - loss: 99359421238345728.0000 - val_loss: 7807085534248960.0000\n",
            "Epoch 394/500\n",
            "76/76 [==============================] - 0s 1ms/step - loss: 76959448802787328.0000 - val_loss: 11099336880422912.0000\n",
            "Epoch 395/500\n",
            "76/76 [==============================] - 0s 1ms/step - loss: 1110430740312489984.0000 - val_loss: 1012490917434621952.0000\n",
            "Epoch 396/500\n",
            "76/76 [==============================] - 0s 1ms/step - loss: 291717133681819648.0000 - val_loss: 179760152457510912.0000\n",
            "Epoch 397/500\n",
            "76/76 [==============================] - 0s 1ms/step - loss: 5815334591493308416.0000 - val_loss: 1485495459584671744.0000\n",
            "Epoch 398/500\n",
            "76/76 [==============================] - 0s 1ms/step - loss: 6768014687717031936.0000 - val_loss: 242614277543192166400.0000\n",
            "Epoch 399/500\n",
            "76/76 [==============================] - 0s 1ms/step - loss: 1440198243537463017472.0000 - val_loss: 3950671590494966906880.0000\n",
            "Epoch 400/500\n",
            "76/76 [==============================] - 0s 1ms/step - loss: 9079978550619206057984.0000 - val_loss: 217865449478419382272.0000\n",
            "Epoch 401/500\n",
            "76/76 [==============================] - 0s 1ms/step - loss: 97723221286219415552.0000 - val_loss: 53154816521482010624.0000\n",
            "Epoch 402/500\n",
            "76/76 [==============================] - 0s 1ms/step - loss: 260402968305724293120.0000 - val_loss: 353097832647054327808.0000\n",
            "Epoch 403/500\n",
            "76/76 [==============================] - 0s 1ms/step - loss: 390079211355951333376.0000 - val_loss: 49023357599648579584.0000\n",
            "Epoch 404/500\n",
            "76/76 [==============================] - 0s 1ms/step - loss: 56014650663373897728.0000 - val_loss: 50627131648201719808.0000\n",
            "Epoch 405/500\n",
            "76/76 [==============================] - 0s 1ms/step - loss: 2988084872514749071360.0000 - val_loss: 52509544214940830662656.0000\n",
            "Epoch 406/500\n",
            "76/76 [==============================] - 0s 1ms/step - loss: 10201431152829801693184.0000 - val_loss: 52087463409795203072.0000\n",
            "Epoch 407/500\n",
            "76/76 [==============================] - 0s 1ms/step - loss: 54189047944893693952.0000 - val_loss: 10351975642790100992.0000\n",
            "Epoch 408/500\n",
            "76/76 [==============================] - 0s 1ms/step - loss: 215176606986832707584.0000 - val_loss: 224660308192772751360.0000\n",
            "Epoch 409/500\n",
            "76/76 [==============================] - 0s 1ms/step - loss: 50660979014151176192.0000 - val_loss: 2577431177367388160.0000\n",
            "Epoch 410/500\n",
            "76/76 [==============================] - 0s 1ms/step - loss: 15893749542269485056.0000 - val_loss: 571175159390535680.0000\n",
            "Epoch 411/500\n",
            "76/76 [==============================] - 0s 1ms/step - loss: 55295570058808393728.0000 - val_loss: 65641037692273688576.0000\n",
            "Epoch 412/500\n",
            "76/76 [==============================] - 0s 1ms/step - loss: 358893367233154646016.0000 - val_loss: 585878482811696971776.0000\n",
            "Epoch 413/500\n",
            "76/76 [==============================] - 0s 2ms/step - loss: 95829475235096166400.0000 - val_loss: 19684013513329606656.0000\n",
            "Epoch 414/500\n",
            "76/76 [==============================] - 0s 1ms/step - loss: 360034572341855911936.0000 - val_loss: 41499812947149455360.0000\n",
            "Epoch 415/500\n",
            "76/76 [==============================] - 0s 1ms/step - loss: 76878380779679252480.0000 - val_loss: 8042720848995418112.0000\n",
            "Epoch 416/500\n",
            "76/76 [==============================] - 0s 1ms/step - loss: 31323962574454652928.0000 - val_loss: 31727580098871689216.0000\n",
            "Epoch 417/500\n",
            "76/76 [==============================] - 0s 1ms/step - loss: 1303871608804679352320.0000 - val_loss: 807182975963381104640.0000\n",
            "Epoch 418/500\n",
            "76/76 [==============================] - 0s 1ms/step - loss: 2752283995850001088512.0000 - val_loss: 4299431190063468249088.0000\n",
            "Epoch 419/500\n",
            "76/76 [==============================] - 0s 1ms/step - loss: 1937343288053497593856.0000 - val_loss: 17509309255960756224.0000\n",
            "Epoch 420/500\n",
            "76/76 [==============================] - 0s 1ms/step - loss: 2139006598067800506368.0000 - val_loss: 7179810225689838223360.0000\n",
            "Epoch 421/500\n",
            "76/76 [==============================] - 0s 1ms/step - loss: 4466816477413947473920.0000 - val_loss: 136668881916184756224.0000\n",
            "Epoch 422/500\n",
            "76/76 [==============================] - 0s 1ms/step - loss: 595040915516093890560.0000 - val_loss: 557710718942308204544.0000\n",
            "Epoch 423/500\n",
            "76/76 [==============================] - 0s 2ms/step - loss: 2526131518436940972032.0000 - val_loss: 1357376653864468480.0000\n",
            "Epoch 424/500\n",
            "76/76 [==============================] - 0s 1ms/step - loss: 93913571825649975296.0000 - val_loss: 15082717879784701952.0000\n",
            "Epoch 425/500\n",
            "76/76 [==============================] - 0s 1ms/step - loss: 40479839990526771200.0000 - val_loss: 236899948487872872448.0000\n",
            "Epoch 426/500\n",
            "76/76 [==============================] - 0s 1ms/step - loss: 242581380155289108480.0000 - val_loss: 184627476853541568512.0000\n",
            "Epoch 427/500\n",
            "76/76 [==============================] - 0s 2ms/step - loss: 65698014384825040896.0000 - val_loss: 18455179526917849088.0000\n",
            "Epoch 428/500\n",
            "76/76 [==============================] - 0s 2ms/step - loss: 59707347271120060416.0000 - val_loss: 17857012216058871808.0000\n",
            "Epoch 429/500\n",
            "76/76 [==============================] - 0s 1ms/step - loss: 106597502779301822464.0000 - val_loss: 2379029526815440896.0000\n",
            "Epoch 430/500\n",
            "76/76 [==============================] - 0s 1ms/step - loss: 5248690279002669056.0000 - val_loss: 1157619992670240768.0000\n",
            "Epoch 431/500\n",
            "76/76 [==============================] - 0s 1ms/step - loss: 113289658311527890944.0000 - val_loss: 19093802268609216512.0000\n",
            "Epoch 432/500\n",
            "76/76 [==============================] - 0s 1ms/step - loss: 63132981300572454912.0000 - val_loss: 427116216557120782336.0000\n",
            "Epoch 433/500\n",
            "76/76 [==============================] - 0s 1ms/step - loss: 1071480801482780966912.0000 - val_loss: 2313236090214487687168.0000\n",
            "Epoch 434/500\n",
            "76/76 [==============================] - 0s 1ms/step - loss: 4669431172849532403712.0000 - val_loss: 39657072519159107026944.0000\n",
            "Epoch 435/500\n",
            "76/76 [==============================] - 0s 1ms/step - loss: 4658884868422137544704.0000 - val_loss: 102264098755818029056.0000\n",
            "Epoch 436/500\n",
            "76/76 [==============================] - 0s 1ms/step - loss: 14112834274876981248.0000 - val_loss: 429464362726457344.0000\n",
            "Epoch 437/500\n",
            "76/76 [==============================] - 0s 1ms/step - loss: 142492884438876160.0000 - val_loss: 42976048354164736.0000\n",
            "Epoch 438/500\n",
            "76/76 [==============================] - 0s 1ms/step - loss: 469178310404866048.0000 - val_loss: 68516019840221184.0000\n",
            "Epoch 439/500\n",
            "76/76 [==============================] - 0s 1ms/step - loss: 74308053821816832.0000 - val_loss: 66721977640943616.0000\n",
            "Epoch 440/500\n",
            "76/76 [==============================] - 0s 1ms/step - loss: 14066001788272640.0000 - val_loss: 12437622920052736.0000\n",
            "Epoch 441/500\n",
            "76/76 [==============================] - 0s 1ms/step - loss: 75059673098616832.0000 - val_loss: 29627103167119360.0000\n",
            "Epoch 442/500\n",
            "76/76 [==============================] - 0s 2ms/step - loss: 177348425241591808.0000 - val_loss: 5260322562268725248.0000\n",
            "Epoch 443/500\n",
            "76/76 [==============================] - 0s 1ms/step - loss: 4682653446686375936.0000 - val_loss: 1411952013020758016.0000\n",
            "Epoch 444/500\n",
            "76/76 [==============================] - 0s 1ms/step - loss: 6535003434779672576.0000 - val_loss: 33501962532028416.0000\n",
            "Epoch 445/500\n",
            "76/76 [==============================] - 0s 1ms/step - loss: 272588483216801792.0000 - val_loss: 924338534750355456.0000\n",
            "Epoch 446/500\n",
            "76/76 [==============================] - 0s 1ms/step - loss: 137717301712519168.0000 - val_loss: 21092717534642176.0000\n",
            "Epoch 447/500\n",
            "76/76 [==============================] - 0s 1ms/step - loss: 403850895760031744.0000 - val_loss: 40272941966950400.0000\n",
            "Epoch 448/500\n",
            "76/76 [==============================] - 0s 1ms/step - loss: 2790290856068775936.0000 - val_loss: 14403064662679617536.0000\n",
            "Epoch 449/500\n",
            "76/76 [==============================] - 0s 1ms/step - loss: 3139300860614410240.0000 - val_loss: 7277615787202838528.0000\n",
            "Epoch 450/500\n",
            "76/76 [==============================] - 0s 2ms/step - loss: 3618701399342186496.0000 - val_loss: 11582500678085378048.0000\n",
            "Epoch 451/500\n",
            "76/76 [==============================] - 0s 1ms/step - loss: 1506929889012350976.0000 - val_loss: 2043706243012362240.0000\n",
            "Epoch 452/500\n",
            "76/76 [==============================] - 0s 1ms/step - loss: 289155271589101568.0000 - val_loss: 1404849167905325056.0000\n",
            "Epoch 453/500\n",
            "76/76 [==============================] - 0s 1ms/step - loss: 365786056094101012480.0000 - val_loss: 310790173322605756416.0000\n",
            "Epoch 454/500\n",
            "76/76 [==============================] - 0s 1ms/step - loss: 482975946032141041664.0000 - val_loss: 62893965064879996928.0000\n",
            "Epoch 455/500\n",
            "76/76 [==============================] - 0s 1ms/step - loss: 119518083819623153664.0000 - val_loss: 27343323662603255808.0000\n",
            "Epoch 456/500\n",
            "76/76 [==============================] - 0s 1ms/step - loss: 7115000612302209679360.0000 - val_loss: 122512357412082095751168.0000\n",
            "Epoch 457/500\n",
            "76/76 [==============================] - 0s 2ms/step - loss: 6810764443074823192576.0000 - val_loss: 665674879490563506176.0000\n",
            "Epoch 458/500\n",
            "76/76 [==============================] - 0s 1ms/step - loss: 5647422171880194310144.0000 - val_loss: 28696718401022873042944.0000\n",
            "Epoch 459/500\n",
            "76/76 [==============================] - 0s 1ms/step - loss: 5039982283639996022784.0000 - val_loss: 51898452962933997568.0000\n",
            "Epoch 460/500\n",
            "76/76 [==============================] - 0s 1ms/step - loss: 403610663464478965760.0000 - val_loss: 4959044717036800311296.0000\n",
            "Epoch 461/500\n",
            "76/76 [==============================] - 0s 1ms/step - loss: 2084922870142708219904.0000 - val_loss: 29217441232147447808.0000\n",
            "Epoch 462/500\n",
            "76/76 [==============================] - 0s 1ms/step - loss: 614203661561811173376.0000 - val_loss: 486136593361252909056.0000\n",
            "Epoch 463/500\n",
            "76/76 [==============================] - 0s 1ms/step - loss: 110125052740556029952.0000 - val_loss: 39185807163611152384.0000\n",
            "Epoch 464/500\n",
            "76/76 [==============================] - 0s 1ms/step - loss: 125447301427474989056.0000 - val_loss: 1021969257421864960.0000\n",
            "Epoch 465/500\n",
            "76/76 [==============================] - 0s 1ms/step - loss: 281236409075707674624.0000 - val_loss: 38746996471012261888.0000\n",
            "Epoch 466/500\n",
            "76/76 [==============================] - 0s 1ms/step - loss: 22290700496088858624.0000 - val_loss: 202541986930663358464.0000\n",
            "Epoch 467/500\n",
            "76/76 [==============================] - 0s 2ms/step - loss: 35899336121863110656.0000 - val_loss: 204841558875308032.0000\n",
            "Epoch 468/500\n",
            "76/76 [==============================] - 0s 2ms/step - loss: 433744555334959104.0000 - val_loss: 237893101744553984.0000\n",
            "Epoch 469/500\n",
            "76/76 [==============================] - 0s 1ms/step - loss: 965540877575389184.0000 - val_loss: 1828497045401370624.0000\n",
            "Epoch 470/500\n",
            "76/76 [==============================] - 0s 1ms/step - loss: 810995241162113024.0000 - val_loss: 26629989088624640.0000\n",
            "Epoch 471/500\n",
            "76/76 [==============================] - 0s 2ms/step - loss: 271211636960788480.0000 - val_loss: 25792013051887616.0000\n",
            "Epoch 472/500\n",
            "76/76 [==============================] - 0s 2ms/step - loss: 267617213190504448.0000 - val_loss: 4937876118700032.0000\n",
            "Epoch 473/500\n",
            "76/76 [==============================] - 0s 1ms/step - loss: 879380535082745856.0000 - val_loss: 122960421148688384.0000\n",
            "Epoch 474/500\n",
            "76/76 [==============================] - 0s 1ms/step - loss: 547909940023394304.0000 - val_loss: 234284075085463552.0000\n",
            "Epoch 475/500\n",
            "76/76 [==============================] - 0s 1ms/step - loss: 6940829878056910848.0000 - val_loss: 1549175462213713920.0000\n",
            "Epoch 476/500\n",
            "76/76 [==============================] - 0s 1ms/step - loss: 12051524850703925248.0000 - val_loss: 3485154991910420480.0000\n",
            "Epoch 477/500\n",
            "76/76 [==============================] - 0s 1ms/step - loss: 17062619463037222912.0000 - val_loss: 406812292890492928.0000\n",
            "Epoch 478/500\n",
            "76/76 [==============================] - 0s 1ms/step - loss: 101029356062638080.0000 - val_loss: 57585207812816896.0000\n",
            "Epoch 479/500\n",
            "76/76 [==============================] - 0s 1ms/step - loss: 2900892929730019328.0000 - val_loss: 13673275914371203072.0000\n",
            "Epoch 480/500\n",
            "76/76 [==============================] - 0s 1ms/step - loss: 22300017757622632448.0000 - val_loss: 7500308123513520128.0000\n",
            "Epoch 481/500\n",
            "76/76 [==============================] - 0s 1ms/step - loss: 3259368629879177216.0000 - val_loss: 558277784917508096.0000\n",
            "Epoch 482/500\n",
            "76/76 [==============================] - 0s 1ms/step - loss: 3272830225615945728.0000 - val_loss: 1009132940203917312.0000\n",
            "Epoch 483/500\n",
            "76/76 [==============================] - 0s 1ms/step - loss: 101046037715615744.0000 - val_loss: 4346001976459264.0000\n",
            "Epoch 484/500\n",
            "76/76 [==============================] - 0s 1ms/step - loss: 461402495453757440.0000 - val_loss: 1632577130032267264.0000\n",
            "Epoch 485/500\n",
            "76/76 [==============================] - 0s 1ms/step - loss: 19999914199105929216.0000 - val_loss: 18763249490881150976.0000\n",
            "Epoch 486/500\n",
            "76/76 [==============================] - 0s 2ms/step - loss: 88018597407933595648.0000 - val_loss: 201138939724877004800.0000\n",
            "Epoch 487/500\n",
            "76/76 [==============================] - 0s 1ms/step - loss: 1724164273792008323072.0000 - val_loss: 235108641736086257664.0000\n",
            "Epoch 488/500\n",
            "76/76 [==============================] - 0s 1ms/step - loss: 248404499289107070976.0000 - val_loss: 245565542674003394560.0000\n",
            "Epoch 489/500\n",
            "76/76 [==============================] - 0s 1ms/step - loss: 653434869759556452352.0000 - val_loss: 20521054123369431040.0000\n",
            "Epoch 490/500\n",
            "76/76 [==============================] - 0s 2ms/step - loss: 6494677614377964666880.0000 - val_loss: 1665929352910387281920.0000\n",
            "Epoch 491/500\n",
            "76/76 [==============================] - 0s 2ms/step - loss: 192613713591194877952.0000 - val_loss: 15560352327960363008.0000\n",
            "Epoch 492/500\n",
            "76/76 [==============================] - 0s 1ms/step - loss: 19689818934724263936.0000 - val_loss: 157614648244305920.0000\n",
            "Epoch 493/500\n",
            "76/76 [==============================] - 0s 1ms/step - loss: 1397263499746344960.0000 - val_loss: 1640173518429618176.0000\n",
            "Epoch 494/500\n",
            "76/76 [==============================] - 0s 2ms/step - loss: 191867081149382656.0000 - val_loss: 31475826742525952.0000\n",
            "Epoch 495/500\n",
            "76/76 [==============================] - 0s 1ms/step - loss: 1593379540502052864.0000 - val_loss: 1564636794723500032.0000\n",
            "Epoch 496/500\n",
            "76/76 [==============================] - 0s 1ms/step - loss: 861654964533985280.0000 - val_loss: 3660553759697666048.0000\n",
            "Epoch 497/500\n",
            "76/76 [==============================] - 0s 1ms/step - loss: 336435096217190400.0000 - val_loss: 552217036307038208.0000\n",
            "Epoch 498/500\n",
            "76/76 [==============================] - 0s 1ms/step - loss: 3689739746101166080.0000 - val_loss: 158357399684949999616.0000\n",
            "Epoch 499/500\n",
            "76/76 [==============================] - 0s 2ms/step - loss: 17758553148814786560.0000 - val_loss: 25781951180463669248.0000\n",
            "Epoch 500/500\n",
            "76/76 [==============================] - 0s 1ms/step - loss: 56254168276368621568.0000 - val_loss: 166650356186287702016.0000\n",
            "Training Set R2 is:\t-21967.293\n",
            "TEsting Set R2 is:\t-10861.463\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iHbDtAV7QDzi"
      },
      "source": [
        "# I also decided to add an activation to the layer to see if it improved my model but there was minimal improvement between these models"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ITfU5btF6XKP",
        "colab": {
          "background_save": true
        }
      },
      "source": [
        "model = Sequential()\n",
        "model.add(Dense(1, input_shape=(3,), activation = 'relu'))\n",
        "model.compile(Adam(lr=15000), 'mean_squared_error')\n",
        "history = model.fit(x_train, y_train, epochs = 500, validation_split = 0.1)\n",
        "\n",
        "history_dict=history.history\n",
        "loss_values = history_dict['loss']\n",
        "val_loss_values=history_dict['val_loss']\n",
        "plt.plot(loss_values)\n",
        "plt.plot(val_loss_values)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2ttFadP17CJ6",
        "colab": {
          "background_save": true
        }
      },
      "source": [
        "y_train_pred = model.predict(x_train)\n",
        "y_test_pred = model.predict(x_test)\n",
        "\n",
        "# Calculates and prints r2 score of training and testing data\n",
        "print(\"Training set R2 is:\\t{:0.3f}\".format(r2_score(y_train, y_train_pred)))\n",
        "print(\"Test set R2 is is:\\t{:0.3f}\".format(r2_score(y_test, y_test_pred)))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8k4jZvQrlDuV"
      },
      "source": [
        "# Above you can see that we have a relativetly high R2 score which shows that the accuracy of our model is quiet good and represents our data well"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2oIXLqcE-GhP",
        "colab": {
          "background_save": true
        }
      },
      "source": [
        "plt.plot(y_train, y_train_pred,'*r')\n",
        "plt.plot(y_test, y_test_pred, '*g')\n",
        "plt.figure()\n",
        "\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EK8IizgDQZeT"
      },
      "source": [
        "# As we can see the model is preforming quiet well and that the relationship is quiet linear"
      ]
    }
  ]
}